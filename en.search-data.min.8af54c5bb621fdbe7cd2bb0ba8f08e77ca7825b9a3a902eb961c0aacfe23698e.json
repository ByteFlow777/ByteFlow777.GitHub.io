[{"id":0,"href":"/docs/JVM/ByteCode/ClassFile/","title":"Class 文件结构","section":"字节码","content":" Class 文件结构 # 前言 # 任何一个 class 文件都会对应一个类或接口，但并不是所有的类和接口都有对应的 class 文件（如：动态生成的类）。\n// Main.java public class Main { public static class InnerClass { } public static void main(String[] args) { } } 当执行 $javac Main.java 命令后，会生成 Main.class 和 Main$InnerClass.class 两个 class 文件。\nclass 文件由 8-bit 字节流组成。16-bit 和 32-bit 分别由 2 个和 4 个连续的 8-bit 组成。多字节数据使用大端（bit-endian）序保存。\n使用 u1、u2 和 u4 分别表示 1 字节、2 字节和 4 字节。\nNames # 二进制类和接口名称 # 在 Java 虚拟机中，类和接口的名称使用二进制名称格式表示。此格式与源代码中的类名表示略有不同。\n类名和接口名：二进制名称使用斜杠（/）而不是点（.）来分隔包和类的名称。例如，java.lang.Object 的二进制名称是 java/lang/Object。 内部类：对于内部类，二进制名称中使用美元符号（$）来分隔外部类和内部类的名称。例如，OuterClass.InnerClass 的二进制名称是 OuterClass$InnerClass。 二进制名称的使用场景 # 字节码指令：\n在字节码指令中，类和接口的引用通常使用二进制名称。例如，L 类型签名前缀后跟随二进制名称，如 Ljava/lang/Object; 表示 java.lang.Object。 类文件格式：\n在类文件的常量池中，类和接口的名称存储为二进制名称形式。例如，CONSTANT_Class_info 结构中引用的名称是二进制名称。 示例 # 普通类：\n源代码名称：com.example.MyClass 二进制名称：com/example/MyClass 内部类：\n源代码名称：com.example.OuterClass.InnerClass 二进制名称：com/example/OuterClass$InnerClass ClassFile # ClassFile { u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count]; } magic # magic 用于标识 class 文件的魔法数字，值为：0xCAFEBABE。\nminor_version, major_version # minor_version 和 major_version 分别表示 class 文件的次版本和主版本。使用主次版本一起表示 class 文件的版本，格式为：major_version.minor_version。\n每次发布新版本的 Java SE 都会有新的 major_version，反映重大变更和新特性引入。主版本内的 minor_version 通常用来指示类文件格式的次要更新和改进。\n高 major_version 的 JVM 可以支持低 major_version 的类文件。\nClass File Versions 可以查看所有 Java SE 对应的主版本。\nconstant_pool_count, constant_pool # 常量池是一个包含多种结构的表，用于表示类文件结构及其子结构中引用的各种字符串常量、类和接口名称、字段名称以及其他常量。\nconstant_pool_count 为常量池中条目（entry）的数量加 1。constant_pool 表的索引为：1 至 constant_pool_count - 1。\naccess_flags # 访问标志 (access_flags) 是用于表示类或接口的访问权限和属性的标志掩码。每个标志位表示特定的访问权限或属性。\n下表为 JDK 21 的类访问和属性修饰符：\nFlag Name Value Interpretation ACC_PUBLIC 0x0001 Declared public; may be accessed from outside its package. ACC_FINAL 0x0010 Declared final; no subclasses allowed. ACC_SUPER 0x0020 Treat superclass methods specially when invoked by the invokespecial instruction. ACC_INTERFACE 0x0200 Is an interface, not a class. ACC_ABSTRACT 0x0400 Declared abstract; must not be instantiated. ACC_SYNTHETIC 0x1000 Declared synthetic; not present in the source code. ACC_ANNOTATION 0x2000 Declared as an annotation interface. ACC_ENUM 0x4000 Declared as an enum class. ACC_MODULE 0x8000 Is a module, not a class or interface. this_class # this_class 项目必须是一个有效的常量池索引。该索引指向的常量池条目必须是一个 CONSTANT_Class_info 结构，表示由该类文件定义的类或接口。\nsuper_class # super_class 用于表示当前类或接口的父类，该索引指向常量池中的条目。\n对于类 # 如果 super_class 非 0，该索引指向的常量池条目必须是一个 CONSTANT_Class_info 结构，表示由该类文件定义的类或接口。 如果 super_class 为 0，表示该类为 Object。唯一一个没有直接父类的类。 对于接口 # 对于接口来说，super_class 始终为指向常量池条目的合法索引。所有接口的父类都为 Object 类。\n// Interface.java public interface Interface { } 使用 $javap -v Interface.class 反编译后的部分结果。\n// Interface.class public interface io.github.ileonli.Interface minor version: 0 major version: 65 flags: (0x0601) ACC_PUBLIC, ACC_INTERFACE, ACC_ABSTRACT this_class: #1 // io/github/ileonli/Interface super_class: #3 // java/lang/Object interfaces: 0, fields: 0, methods: 0, attributes: 1 Constant pool: #1 = Class #2 // io/github/ileonli/Interface #2 = Utf8 io/github/ileonli/Interface #3 = Class #4 // java/lang/Object #4 = Utf8 java/lang/Object #5 = Utf8 SourceFile #6 = Utf8 Interface.java // Interface.java public interface Interface extends Cloneable { } 使用 $javap -v Interface.class 反编译后的部分结果。\n// Interface.class public interface io.github.ileonli.Interface extends java.lang.Cloneable minor version: 0 major version: 65 flags: (0x0601) ACC_PUBLIC, ACC_INTERFACE, ACC_ABSTRACT this_class: #1 // io/github/ileonli/Interface super_class: #3 // java/lang/Object interfaces: 1, fields: 0, methods: 0, attributes: 1 Constant pool: #1 = Class #2 // io/github/ileonli/Interface #2 = Utf8 io/github/ileonli/Interface #3 = Class #4 // java/lang/Object #4 = Utf8 java/lang/Object #5 = Class #6 // java/lang/Cloneable #6 = Utf8 java/lang/Cloneable #7 = Utf8 SourceFile #8 = Utf8 Interface.java interfaces_count, interfaces[] # "},{"id":1,"href":"/docs/ProGit/Git-%E5%9F%BA%E7%A1%80/","title":"Git 基础","section":"Pro Git","content":" Git 基础 # 获取 Git 仓库 # 有两种取得 Git 项目仓库的方法：\n将现有项目或目录下导入所有文件到 Git 中，可以使用 $ git init 命令。 从服务器克隆一个现有的 Git 仓库，使用 $ git clone \u0026lt;project url\u0026gt; 命令。 Git 生命周期 # 工作目录下的所有文件都处于两种状态之一：已跟踪和未跟踪。\n已跟踪：是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改、已修改或已放入暂存区。 未跟踪：工作目录中除已跟踪文件以外的所有其它文件都属于未跟踪文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态。\n编辑已跟踪的文件后（如：修改代码），Git 会将这些修改的文件标记为已修改文件。随后我们会逐步将修改过的文件加入暂存区中，然后提交暂存区中的所有文件。\n如此反复，使用 Git 的生命周期如下图所示：\n检查当前文件状态 # 如果需要查看文件处于的状态，可以使用 $ git status 命令。\n当我们对 $ git init 后的仓库使用此命令，可以看到下边的输出：\n$ git status On branch main No commits yet nothing to commit (create/copy files and use \u0026#34;git add\u0026#34; to track) 我们可以从上边输出中得到以下信息：\n当前的分支名称为 “main”。 所有已跟踪的文件自上次提交后未进行任何修改。 当前目录下没有处于未跟踪的文件。 现在，使用 echo 命令在项目下创建一个新的 README 文件。使用 $ git status 命令后，可以看到一个新的未跟踪文件：\n$ echo \u0026#39;My Project\u0026#39; \u0026gt; README $ git status On branch main No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) README nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) 从输出中可以看到 README 文件处于 Untracked files 下。Git 不会自动将未跟踪文件纳入跟踪范围，除非明确告之“我需要跟踪该文件”，\n跟踪新文件 # 使用命令 $ git add 开始跟踪一个文件。 所以，要跟踪 README 文件，可以运行：\n$ git add README 此时再次运行 $ git status 命令，可以看到 README 文件已被跟踪，并处于暂存状态：\n$ git status On branch main No commits yet Changes to be committed: (use \u0026#34;git rm --cached \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: README 在 Changes to be committed 下的文件处于已暂存状态。如果此时提交，那么该文件当前的版本将被保留在历史记录中。\n暂存已修改文件 # 如果修改了一个名为 CONTRIBUTING.md 的已被跟踪的文件，然后运行 git status 命令，会看到下面内容：\n$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: README Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: CONTRIBUTING.md 文件 CONTRIBUTING.md 出现在 Changes not staged for commit 这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。要暂存这次更新，需要运行 $ git add 命令。\n现在运行 $ git add CONTRIBUTING.md 将 CONTRIBUTING.md 文件放到暂存区，然后再看看 $ git status 的输出：\n$ git add CONTRIBUTING.md $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: CONTRIBUTING.md new file: README 现在两个文件都已暂存，下次提交时就会一并记录到仓库。假设此时，你想要在 CONTRIBUTING.md 里再加条注释，重新编辑保存后，准备提交这两个文件。\n不过且慢，再次运行 $ git status 看看：\n$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: CONTRIBUTING.md new file: README Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: CONTRIBUTING.md 可以看到 CONTRIBUTING.md 文件同时出现在暂存区和非暂存区。这是为什么？\n实际上 Git 只不过暂存了你运行 $ git add 命令时的版本，如果现在提交，CONTRIBUTING.md 的版本是你最后一次运行 $ git add 命令时的那个版本，而不是运行 $ git commit 时，在工作目录中的版本。\n所以，运行了 $ git add 之后又作了修订的文件，需要重新运行 $ git add 把最新版本重新暂存起来：\n$ git add CONTRIBUTING.md $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: CONTRIBUTING.md new file: README 提交更新 # 使用 $ git commit 前，一定要确保所有的修改已经 $ git add 过。\n$ git commit 这种方式会启动文本编辑器以便输入本次提交的说明。退出编辑器时，Git 会丢掉注释行，用你输入提交附带信息生成一次提交。\n# Please enter the commit message for your changes. Lines starting # with \u0026#39;#\u0026#39; will be ignored, and an empty message aborts the commit. # # On branch main # Changes to be committed: # modified: CONTRIBUTING.md # new file: README # 另外，你也可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行，如下所示：\n$ git commit -m \u0026#34;add: CONTRIBUTING.md and README\u0026#34; [main 34ae990] add: CONTRIBUTING.md and README 2 files changed, 2 insertions(+) create mode 100644 README 每一次运行提交操作，都是保存一次项目快照，以后可以回到这个状态，或者进行比较。\n跳过暂存区域 # 尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。\nGit 提供了一个跳过使用暂存区域的方式，只要在提交的时候，给 $ git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 $ git add 步骤。\n移除文件 # 要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。可以用 $ git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。\n如果只是简单地从工作目录中手工删除文件，运行 $ git status 时就会在 Changes not staged for commit 部分（未暂存清单）看到：\n$ rm README $ git status On branch main Changes not staged for commit: (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) deleted: README no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 然后再运行 $ git rm 记录此次移除文件的操作：\n$ git rm README rm \u0026#39;README\u0026#39; $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) deleted: README 下一次提交时，该文件就不再纳入版本管理了。\n如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f。这是一种安全特性，用于防止误删还没有添加到快照的数据，这样的数据不能被 Git 恢复。\n另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。换句话说，仍然文件保留在磁盘，但是并不想让 Git 继续跟踪。\n当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。\n为达到这一目的，可以使用 --cached 选项：\n$ git rm --cached README 状态简览 # 使用 $ git status -s 命令或 $ git status --short 命令可以获得一种更为紧凑的格式输出。\n忽略文件 # 有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。我们可以创建一个名为 .gitignore 文件，列出要忽略的文件。\n可以在 A collection of useful .gitignore templates 查看常用的模板。\n查看提交历史 # 在提交了若干更新，又或者克隆了某个项目之后，如果想回顾下历史提交记录。完成这个任务最简单而又有效的工具是 $ git log 命令。\n$ git log commit 6c669101bea2a6b2400f070f72f35f0866ea714a (HEAD -\u0026gt; main) Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:06:10 2024 +0800 add: README 查看已暂存和未暂存的修改 # 如果 $ git status 命令的输出对于你来说过于模糊，你想知道具体修改了什么地方，可以用 $ git diff 命令。\n撤消操作 # 修正提交 # 有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。此时，可以运行带有 --amend 选项的提交命令尝试重新提交：\n$ git commit --amend 我们有 3 个处于 Changes to be committed 状态的文件。\n$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: 1.txt modified: 2.txt modified: 3.txt 我们使用 $ git commit 提交其中的两个文件。\n$ git commit -m \u0026#34;change: 1.txt, 2.txt\u0026#34; 1.txt 2.txt [main 787cfc9] change: 1.txt, 2.txt 2 files changed, 2 insertions(+) $ git log commit 787cfc91428a9be730e97e103b00e2bfe59e671c (HEAD -\u0026gt; main) Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:40:12 2024 +0800 change: 1.txt, 2.txt commit 984668dbca2b4d3dbf40aad117122bd737a735db Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:37:31 2024 +0800 add 1.txt, 2.txt and 3.txt 此时，发现 3.txt 忘记提交了，此时我们可以使用 $ git commit 再次提交，但此时会多出一次提交记录。\n我们可以使用 $ git commit --amend 提交暂存区中的文件，以及修改提交信息。\n$ git commit --amend [main 71cfcbd] change: 1.txt, 2.txt and 3.txt Date: Sun Aug 4 16:40:12 2024 +0800 3 files changed, 3 insertions(+) 通过查看 git log，此时只有一次修改的记录，上一个修改记录被覆盖掉了。\n$ git log commit 82911668c9d16c8c85e636ecc7d4cd717d0ab9f0 (HEAD -\u0026gt; main) Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:40:12 2024 +0800 change: 1.txt, 2.txt and 3.txt commit 984668dbca2b4d3dbf40aad117122bd737a735db Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:37:31 2024 +0800 add 1.txt, 2.txt and 3.txt 取消暂存的文件 # 已经修改了两个文件并且想要将它们作为两次独立的修改提交，但是却意外地输入了 $ git add * 暂存了它们两个。如何只取消暂存两个中的一个呢？\n$ git status On branch main Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: 1.txt modified: 2.txt no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 我们可以使用 $ git restore --staged 将文件从暂存区移除，但保留工作区中的更改。\n$ git restore --staged 2.txt (base) leon@Inspiron7590:~/Projects/demo$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: 1.txt Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: 2.txt 撤消对文件的修改 # 如果你并不想保留对文件的修改怎么办？你该如何方便地撤消修改,将它还原成上次提交时的样子（或者刚克隆完的样子，或者刚把它放入工作目录时的样子）？\n$ git status On branch main Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: README no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 我们可以直接使用 $ git restore 命令。可以看到 README 文件的修改已被撤销。\n$ git restore README $ git status On branch main nothing to commit, working tree clean "},{"id":2,"href":"/docs/MyBatis/SqlSession/","title":"SqlSession","section":"MyBatis","content":" SqlSession # SalSession 是用于操作数据库的接口，具体的操作都通过此接口。\nSqlSessionFactoryBuilder # 此类可以被实例化、使用和丢弃，一旦使用此类创建了 SqlSessionFactory，后续就不需要使用此类了。因此 SqlSessionFactoryBuilder 实例的最佳作用域是方法作用域（也就是局部方法变量）。\n可以重用 SqlSessionFactoryBuilder 来创建多个 SqlSessionFactory 实例，但最好还是不要一直保留着它，以保证 XML 资源可以被释放。\nSqlSessionFactory # SqlSessionFactory 一旦被创建就应该在应用的运行期间一直存在，没有任何理由丢弃它或重新创建另一个实例。使用 SqlSessionFactory 的最佳实践是在应用运行期间只创建一次。\nSqlSessionFactory 的作用是为了创建 SqlSession 实例。SqlSession 是 MyBatis 执行 SQL 命令的核心接口，通过此实例可以对数据库进行查询、插入、更新和删除操作。\nimport java.sql.Connection; /** * Creates an {@link SqlSession} out of a connection or a DataSource * * @author Clinton Begin */ public interface SqlSessionFactory { SqlSession openSession(); SqlSession openSession(boolean autoCommit); SqlSession openSession(Connection connection); SqlSession openSession(TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType); SqlSession openSession(ExecutorType execType, boolean autoCommit); SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType, Connection connection); Configuration getConfiguration(); } SqlSessionFactory 主要有两个具体的实现：\nDefaultSqlSessionFactory： SqlSessionManager： DefaultSqlSessionFactory # DefaultSqlSessionFactory 是用于获取 SqlSession 的工厂类。\n有下边两种创建 SqlSession 的具体实现：\nprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx = null; try { final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\u0026#34;Error opening session. Cause: \u0026#34; + e, e); } finally { ErrorContext.instance().reset(); } } private SqlSession openSessionFromConnection(ExecutorType execType, Connection connection) { try { boolean autoCommit; try { autoCommit = connection.getAutoCommit(); } catch (SQLException e) { // Failover to true, as most poor drivers // or databases won\u0026#39;t support transactions autoCommit = true; } final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); final Transaction tx = transactionFactory.newTransaction(connection); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { throw ExceptionFactory.wrapException(\u0026#34;Error opening session. Cause: \u0026#34; + e, e); } finally { ErrorContext.instance().reset(); } } SqlSessionManager # SqlSessionManager 内部保存了一个 ThreadLocal 用于保存 SqlSession。\npublic class SqlSessionManager implements SqlSessionFactory, SqlSession { private final SqlSessionFactory sqlSessionFactory; private final SqlSession sqlSessionProxy; private final ThreadLocal\u0026lt;SqlSession\u0026gt; localSqlSession = new ThreadLocal\u0026lt;\u0026gt;(); private SqlSessionManager(SqlSessionFactory sqlSessionFactory) { this.sqlSessionFactory = sqlSessionFactory; this.sqlSessionProxy = (SqlSession) Proxy.newProxyInstance(SqlSessionFactory.class.getClassLoader(), new Class[] { SqlSession.class }, new SqlSessionInterceptor()); } } sqlSessionProxy 是通过动态代理代理的类，当获取 SqlSession 时，会先从 localSqlSession 中获取，如果不存在才新建 SqlSession。\nprivate class SqlSessionInterceptor implements InvocationHandler { public SqlSessionInterceptor() { // Prevent Synthetic Access } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { final SqlSession sqlSession = SqlSessionManager.this.localSqlSession.get(); if (sqlSession != null) { try { return method.invoke(sqlSession, args); } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } } try (SqlSession autoSqlSession = openSession()) { try { final Object result = method.invoke(autoSqlSession, args); autoSqlSession.commit(); return result; } catch (Throwable t) { autoSqlSession.rollback(); throw ExceptionUtil.unwrapThrowable(t); } } } } 当使用 startManagedSession 方法时，会新建一个 SqlSession，并保存到 localSqlSession 中。\npublic void startManagedSession() { this.localSqlSession.set(openSession()); } 所有操作都会通过 sqlSessionProxy 进行代理，复用同一个 SqlSession。\n@Override public \u0026lt;T\u0026gt; T selectOne(String statement) { return sqlSessionProxy.selectOne(statement); } 下图中的操作和上边一样，同样会经过 sqlSessionProxy 进行代理。\nSqlSession # 每个线程都应该有自己的 SqlSession 实例，SqlSession 实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。\nSqlSession 继承了 Closeable 接口，下边是使用 SqlSession 的最佳实践：\ntry (SqlSession session = sqlSessionFactory.openSession()) { // 你的应用逻辑代码 } "},{"id":3,"href":"/docs/system-programming/network-byte-order/","title":"网络字节序","section":"Linux 网络编程","content":" 网络字节序 # 大小端 # 不同架构的 CPU 中，4 字节整数 1 在内存中存储的方式是不同的。\n大端序（big endian）：最高位有效字节存储在低内存地址，而最低位有效字节存储在高内存地址。 小端序（little endian）：最高位有效字节存储在高内存地址，而最低位有效字节存储在低内存地址。 对于一个 4 字节整数 0x01020304，大小端序存储方式分别如下：\n地址: 0 1 2 3 （大端序保存） 01 02 03 04 地址: 0 1 2 3 （小端序保存） 04 03 02 01 可以使用下边的方法判断机器的字节序：\n通过 endian.h 提供的 BYTE_ORDER 宏。 #include \u0026lt;endian.h\u0026gt; bool big_endian() { return BYTE_ORDER == BIG_ENDIAN; } bool little_endian() { return BYTE_ORDER == LITTLE_ENDIAN; } 将 uint16_t 类型的数字转为 char *，通过高字节和低字节进行判断。 bool big_endian() { uint16_t val = 0x0102; return ((char *) (\u0026amp;val))[0] == 0x01; } bool little_endian() { uint16_t val = 0x0102; return ((char *) (\u0026amp;val))[1] == 0x01; } 和方法 2 类似，利用的是 union 相同的内存位置存储不同的数据类型。 union endian { uint16_t val; char bytes[2]; }; bool big_endian() { union endian en{}; en.val = 0x0102; return en.bytes[0] == 0x01; } bool little_endian() { union endian en{}; en.val = 0x0102; return en.bytes[0] == 0x02; } 为什么有两种不同的字节序？\n大端序是人类最熟悉的读写方法，从左向右处理。\n小端序更利于计算机处理，因为计算都是从低位开始的，先处理低位字节，效率比较高。\n网络字节序 # 如果通信双方采用不同的架构，收发数据后进行解析时会发生问题。如：大端序机器 A 发送 0x01020304 到小端序机器 B 时，B 以小端序方式解析该数字为 0x04030201。\n为解决上边问题，网络传输数据时，通信双方需要约定统一方式，把此约定叫做网络字节序（network byte order）。\n网络字节序规定使用大端序，大多数网络协议（例如 TCP/IP 协议族）规定了网络字节序采用大端序。\n因此，小端序发送数据时，需要先转为大端序。\n字节序转换 # 下边函数用于字节序的相互转换：\n#include \u0026lt;arpa/inet.h\u0026gt; uint32_t htonl(uint32_t hostlong); uint16_t htons(uint16_t hostshort); uint32_t ntohl(uint32_t netlong); uint16_t ntohs(uint16_t netshort); 函数名中的 h 表示主机（host）字节序，n 表示网络（network）字节序；s 表示 short 类型，l 表示 long 类型。\n"},{"id":4,"href":"/docs/Netty/ByteBuf/","title":"ByteBuf","section":"Netty","content":" ByteBuf # 基本结构 # +-------------------+------------------+------------------+-------------+ | discardable bytes | readable bytes | writable bytes | ... | | | (CONTENT) | | | +-------------------+------------------+------------------+-------------+ | | | | | 0 \u0026lt;= readerIndex \u0026lt;= writerIndex \u0026lt;= capacity maxCapacity 相关操作 # 有些方法会返回 this，以支持链式调用。\n容量 # ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); int capacity = buf.capacity();// 获取当前的容量 int maxCapacity = buf.maxCapacity();// 支持的最大容量，通常为 Integer.MAX_VALUE int readableBytes = buf.readableBytes();// writerIndex - readerIndex int writableBytes = buf.writableBytes();// capacity - writerIndex boolean readable; readable = buf.isReadable(8);// isReadable(int), writerIndex - readerIndex \u0026gt;= size readable = buf.isReadable();// 相当于 isReadable(1) boolean writable; writable = buf.isWritable(8); // isWritable(int), capacity - writerIndex \u0026gt;= size writable = buf.isWritable(); // 相当于 isWritable(1) int maxWritableBytes = buf.maxWritableBytes();// maxCapacity - writerIndex 读写 # readType() 用于读取 Type 类型的数据，writeType() 用于写入 Type 类型的值。\n与 readType() 类似的有 getType()，与 writeType() 类似的有 setType()。唯一的区别是 getType() 和 setType() 不会改变读写指针，而 readType() 和 writeType()会改变读写指针。\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); boolean booleanV = true; buf.writeBoolean(booleanV); // 8-bit buf.readBoolean(); byte byteV = 0; buf.writeByte(byteV); // 8-bit buf.readByte(); short shortV = 0; buf.writeShort(shortV); // 16-bit buf.readShort(); int mediumV = 0; buf.writeMedium(mediumV); // 24-bit buf.readMedium(); int intV = 0; buf.writeInt(intV); // 32-bit buf.readInt(); long longV = 0; buf.writeLong(longV); // 64-bit buf.readLong(); char charV = 0; buf.writeChar(charV); // 8-bit buf.readChar(); float floatV = 0; buf.writeFloat(floatV); // 32-bit buf.readFloat(); double doubleV = 0.0; buf.writeDouble(doubleV); // 64-bit buf.readDouble(); byte[] bytes = new byte[]{0, 1, 2, 3, 4, 5, 6}; // 等价于 buf.writeBytes(bytes, 0, bytes.length) buf.writeBytes(bytes); // 从 `bytes` 的 `srcIndex` 处读取`length` 字节，写入到 `buf` buf.writeBytes(bytes, 1, 3); byte[] bytesDestination = new byte[8]; buf.readBytes(bytesDestination); ByteBuf originalBuf = ByteBufAllocator.DEFAULT.buffer(); // 等价于 buf.writeBytes(originalBuf, originalBuf.readableBytes()) buf.writeBytes(originalBuf); // 等价于 buf.writeBytes(originalBuf, originalBuf.readerIndex(), 3); buf.writeBytes(originalBuf, 3); // 从 `originalBuf` 的 `srcIndex` 处读取`length` 字节，写入到 `buf` buf.writeBytes(originalBuf, 1, 3); ByteBuf bufDestination = ByteBufAllocator.DEFAULT.buffer(); buf.readBytes(bufDestination); 派生 # duplicate() slice() slice(int, int) readSlice(int) retainedDuplicate() retainedSlice() retainedSlice(int, int) readRetainedSlice(int) 读写指针 # ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); int readerIndex = buf.readerIndex(); // 获取当前读指针位置 int writerIndex = buf.writerIndex(); // 获取当前写指针位置 buf.readerIndex(0); // readerIndex(int)，设置读指针位置 buf.writerIndex(0); // writerIndex(int)，设置写指针位置 buf.markReaderIndex(); // 记录当前读指针位置 // do something buf.resetReaderIndex(); // 恢复到之前 mark 的读指针位置 buf.markWriterIndex(); // 记录当前写指针位置 // do something buf.resetWriterIndex(); // 恢复到之前 mark 的写指针位置 丢弃字节 # ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); System.out.println(buf); // PooledUnsafeDirectByteBuf(ridx: 0, widx: 0, cap: 256) for (int i = 0; i \u0026lt; 16; i++) { buf.writeInt(i); } for (int i = 0; i \u0026lt; 8; i++) { buf.readInt(); } System.out.println(buf); // PooledUnsafeDirectByteBuf(ridx: 32, widx: 64, cap: 256) buf.discardReadBytes(); System.out.println(buf); // PooledUnsafeDirectByteBuf(ridx: 0, widx: 32, cap: 256) 调用 discardReadBytes() 丢弃 0 ~ readerIndex 之间的字节。将 readerIndex 和 writerIndex 之间的字节移动到第 0 个索引，并将 readerIndex 和 writerIndex 分别设置为 0 和 oldWriterIndex - oldReaderIndex。\nBEFORE discardReadBytes() +-------------------+------------------+------------------+ | discardable bytes | readable bytes | writable bytes | +-------------------+------------------+------------------+ | | | | 0 \u0026lt;= readerIndex \u0026lt;= writerIndex \u0026lt;= capacity AFTER discardReadBytes() +------------------+--------------------------------------+ | readable bytes | writable bytes (got more space) | +------------------+--------------------------------------+ | | | readerIndex (0) \u0026lt;= writerIndex (decreased) \u0026lt;= capacity 也可以调用 clear() 方法，当调用后会直接将 readerIndex 和 writerIndex 同时设为 0。\nBEFORE clear() +-------------------+------------------+------------------+ | discardable bytes | readable bytes | writable bytes | +-------------------+------------------+------------------+ | | | | 0 \u0026lt;= readerIndex \u0026lt;= writerIndex \u0026lt;= capacity AFTER clear() +---------------------------------------------------------+ | writable bytes (got more space) | +---------------------------------------------------------+ | | 0 = readerIndex = writerIndex \u0026lt;= capacity ByteBufHolder # ByteBufHolder 可用于封装 ByteBuf 数据，可用于存储消息对象。\n分类 # Heap 和 Direct # Heap 底层使用 byte[]。\nDirect 底层使用 java.nio.ByteBuffer。\nPooled 和 Unpooled # 池化和非池化的区别，Netty 维护者（Norman Maurer）的 回答：\nThe difference is that with unpooled Netty will allocate a new buffer everytime you call ByteBufAllocator.buffer which comes with some overhead, especially with direct buffers. When you use pooled Netty will try to pool the buffers and so minimize the overhead of allocation and releasing of buffers. Safe 和 Unsafe # Unsafe 的 ByteBuf 会使用 sun.misc.Unsafe 直接申请内存。\nAbstractByteBuf # AbstractByteBuf 是 buffer 的基本骨架，提供了基本的操作。\n类中共有 4 个 *Index 和 1 个指定最大容量的字段 maxCapacity。\nint readerIndex; int writerIndex; private int markedReaderIndex; private int markedWriterIndex; private int maxCapacity; readerIndex 和 writerIndex 分别指定当前读入和写入的位置，当调用 read* 和 write* 方法时会修改位置，而 get* 和 set* 方法不会。\nmarkedReaderIndex 和 markedWriterIndex 用于标注当前的位置，默认值为 0。调用 markReaderIndex() 和 markWriterIndex() 方法用于标记当前读入和写入的位置。\n当调用 resetReaderIndex() 和 resetWriterIndex() 方法时，会将当前的 readerIndex 和 writerIndex 设置为 markedReaderIndex 和 markedWriterIndex。\npublic ByteBuf resetReaderIndex() { readerIndex(markedReaderIndex); return this; } public ByteBuf resetWriterIndex() { writerIndex(markedWriterIndex); return this; } 可读可写只需要判断 writerIndex 和 readerIndex 的相对位置即可。\npublic boolean isReadable() { return writerIndex \u0026gt; readerIndex; } public boolean isWritable() { return capacity() \u0026gt; writerIndex; } public int readableBytes() { return writerIndex - readerIndex; } public int writableBytes() { return capacity() - writerIndex; } ByteBufAllocator # 继承关系 # 默认 Allocator # ByteBufAllocator 类中的 DEFAULT 指定 Netty 使用的 Allocator。\npublic interface ByteBufAllocator { ByteBufAllocator DEFAULT = ByteBufUtil.DEFAULT_ALLOCATOR; } ByteBufUtil 类通过获取系统变量确认默认的 ByteBufAllocator，默认使用 PooledByteBufAllocator 类。\n可以通过 java -Dio.netty.allocator.type: {unpooled|pooled} 指定。\npublic final class ByteBufUtil { ... static final ByteBufAllocator DEFAULT_ALLOCATOR; static { String allocType = SystemPropertyUtil.get( \u0026#34;io.netty.allocator.type\u0026#34;, PlatformDependent.isAndroid() ? \u0026#34;unpooled\u0026#34; : \u0026#34;pooled\u0026#34;); allocType = allocType.toLowerCase(Locale.US).trim(); ByteBufAllocator alloc; if (\u0026#34;unpooled\u0026#34;.equals(allocType)) { alloc = UnpooledByteBufAllocator.DEFAULT; logger.debug(\u0026#34;-Dio.netty.allocator.type: {}\u0026#34;, allocType); } else if (\u0026#34;pooled\u0026#34;.equals(allocType)) { alloc = PooledByteBufAllocator.DEFAULT; logger.debug(\u0026#34;-Dio.netty.allocator.type: {}\u0026#34;, allocType); } else { alloc = PooledByteBufAllocator.DEFAULT; logger.debug(\u0026#34;-Dio.netty.allocator.type: pooled (unknown: {})\u0026#34;, allocType); } DEFAULT_ALLOCATOR = alloc; } ... } 内存回收 # Netty 使用引用计数方法对 ByteBuf 进行回收。实现 ReferenceCounted 的实例开始时的引用计数为 1，只要引用计数大于 0，就能保证对象不会被释放。当引用计数减少到 0 时，该实例就会被释放。\nUnpooledHeapByteBuf 使用的是 JVM 内存，只需等 GC 回收即可。 UnpooledDirectByteBuf 使用了直接内存， 扩容逻辑 # 当向 ByteBuf 写入数据，而容量不足时（writerIndex \u0026gt; capacity()），会自动进行扩容。\n每次调用 write*() 时，方法内部会调用 ensureWritable0() 确保有足够的空间。\n调用 ensureWritable0() 时会传入 minWritableBytes 参数，确保有足够的字节数，调用 writeLong() 时，会被设为 8。\npublic abstract class AbstractByteBuf extends ByteBuf { ... public ByteBuf writeInt(int value) { ensureWritable0(4); _setInt(writerIndex, value); writerIndex += 4; return this; } ... } ensureWritable0 # ensureWritable0() 进行扩容的代码如下：\n获取当前的写入索引（writerIndex），并计算目标容量（targetCapacity），即当前写入索引加上要写入的最小字节数。 使用非短路逻辑与运算符（\u0026amp;）来检查目标容量是否在合理范围内。这里选择使用非短路逻辑与运算符是为了减少分支，因为该代码段通常是一个热点路径，并且目标容量很少会溢出。如果目标容量在合理范围内，则表示缓冲区已经有足够的空间，直接返回。 如果启用了边界检查（checkBounds），并且目标容量小于 0 或者大于最大容量（maxCapacity），则抛出索引越界异常。 如果目标容量不在合理范围内，需要增加缓冲区的容量。首先，调用 maxFastWritableBytes() 方法获取一个快速可写入的字节数，然后根据这个字节数和传入的最小可写入字节数来计算新的容量。如果快速可写入字节数大于等于传入的最小可写入字节数，则新容量直接设定为当前写入索引加上快速可写入字节数，否则通过调用 calculateNewCapacity 方法来计算新容量。 通过调用 capacity(newCapacity) 方法来调整缓冲区的容量，确保其足够可写入。 public abstract class AbstractByteBuf extends ByteBuf { ... final void ensureWritable0(int minWritableBytes) { final int writerIndex = writerIndex(); final int targetCapacity = writerIndex + minWritableBytes; // using non-short-circuit \u0026amp; to reduce branching - this is a hot path and targetCapacity should rarely overflow if (targetCapacity \u0026gt;= 0 \u0026amp; targetCapacity \u0026lt;= capacity()) { ensureAccessible(); return; } if (checkBounds \u0026amp;\u0026amp; (targetCapacity \u0026lt; 0 || targetCapacity \u0026gt; maxCapacity)) { ensureAccessible(); throw new IndexOutOfBoundsException(String.format( \u0026#34;writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s\u0026#34;, writerIndex, minWritableBytes, maxCapacity, this)); } // Normalize the target capacity to the power of 2. final int fastWritable = maxFastWritableBytes(); int newCapacity = fastWritable \u0026gt;= minWritableBytes ? writerIndex + fastWritable : alloc().calculateNewCapacity(targetCapacity, maxCapacity); // Adjust to the new capacity. capacity(newCapacity); } ... } calculateNewCapacity # calculateNewCapacity 计算新的容量时的思路总结如下：\nminNewCapacity 参数为最小申请的容量，检查传入的 minNewCapacity 参数是否为非负数，如果不是，则抛出异常。 检查 minNewCapacity 是否超过了最大容量 maxCapacity，如果超过了，则抛出异常。 设定一个阈值 threshold，表示页面大小为 4 MiB。 minNewCapacity 等于阈值 threshold，则直接返回阈值，不再需要进行容量的调整。 minNewCapacity 大于阈值 threshold，则按照阈值为单位递增容量。在这种情况下，新容量的计算方式不再是简单的翻倍增加，而是以阈值为单位递增。 minNewCapacity 小于等于阈值 threshold 时，则将 minNewCapacity 设置为大于等于 64 的最接近的 2 的幂，以确保足够的容量同时尽量减小内存的浪费。 返回新容量和最大容量中较小的一个值，以确保新容量不会超过最大容量限制。 public abstract class AbstractByteBufAllocator implements ByteBufAllocator { ... public int calculateNewCapacity(int minNewCapacity, int maxCapacity) { checkPositiveOrZero(minNewCapacity, \u0026#34;minNewCapacity\u0026#34;); if (minNewCapacity \u0026gt; maxCapacity) { throw new IllegalArgumentException(String.format( \u0026#34;minNewCapacity: %d (expected: not greater than maxCapacity(%d)\u0026#34;, minNewCapacity, maxCapacity)); } final int threshold = CALCULATE_THRESHOLD; // 4 MiB page if (minNewCapacity == threshold) { return threshold; } // If over threshold, do not double but just increase by threshold. if (minNewCapacity \u0026gt; threshold) { int newCapacity = minNewCapacity / threshold * threshold; if (newCapacity \u0026gt; maxCapacity - threshold) { newCapacity = maxCapacity; } else { newCapacity += threshold; } return newCapacity; } // 64 \u0026lt;= newCapacity is a power of 2 \u0026lt;= threshold final int newCapacity = MathUtil.findNextPositivePowerOfTwo(Math.max(minNewCapacity, 64)); return Math.min(newCapacity, maxCapacity); } ... } "},{"id":5,"href":"/docs/ProGit/Git-%E5%88%86%E6%94%AF/","title":"Git 分支","section":"Pro Git","content":" Git 分支 # 分支创建 # 使用 $ git branch 命令后，会在当前所在的提交对象上创建一个指针。此操作并不会直接切换到新创建的分支上。\n那么，Git 又是怎么知道当前在哪一个分支上呢？有一个名为 HEAD 的特殊指针，指向当前分支。\n$ git branch testing 分支切换 # 要切换到一个已存在的分支，需要使用 $ git switch 命令。\n$ git switch testing 这样 HEAD 就指向 testing 分支了。\n分支合并 # testing 分支提交 # $ touch 1.txt $ git commit -a -m \u0026#39;add: 1.txt\u0026#39; master 分支提交 # $ git switch master $ touch 2.txt $ git commit -a -m \u0026#39;add: 2.txt\u0026#39; 合并 # 使用 $ git merge 即可将 testing 分支中的内容合并到 master 分支中。\n$ git merge testing "},{"id":6,"href":"/docs/MyBatis/ResultSetHandler/","title":"ResultSetHandler","section":"MyBatis","content":" ResultSetHandler # ResultSetHandler\npublic interface ResultSetHandler { \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; handleResultSets(Statement stmt) throws SQLException; \u0026lt;E\u0026gt; Cursor\u0026lt;E\u0026gt; handleCursorResultSets(Statement stmt) throws SQLException; void handleOutputParameters(CallableStatement cs) throws SQLException; } "},{"id":7,"href":"/docs/MyBatis/StatementHandler/","title":"StatementHandler","section":"MyBatis","content":" StatementHandler # StatementHandler 接口中的功能很多，例如创建 Statement 对象，为 SQL 语句绑定实参，执行 select、insert、update、delete 等多种类型的 SQL 语句，批量执行 SQL 语句，将结果集映射成结果对象。\npublic interface StatementHandler { Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException; void parameterize(Statement statement) throws SQLException; void batch(Statement statement) throws SQLException; int update(Statement statement) throws SQLException; \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; query(Statement statement, ResultHandler resultHandler) throws SQLException; \u0026lt;E\u0026gt; Cursor\u0026lt;E\u0026gt; queryCursor(Statement statement) throws SQLException; BoundSql getBoundSql(); ParameterHandler getParameterHandler(); } prepare：从 Connection 中创建 Statement 对象。 parameterize：绑定 statement 执行时需要的参数。 batch：批量执行 SQL 语句。 update：执行 insert、update 和 delete 操作。 query 和 queryCursor：用于执行 select 操作。 getBoundSql：获取绑定的 SQL。 getParameterHandler：负责处理 SQL 语句中的参数的处理器。 BaseStatementHandler # prepare # BaseStatementHandler 中设计了模板方法 prepare，通过该方法可以获取 Statement 对象。\n@Override public Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException { ErrorContext.instance().sql(boundSql.getSql()); Statement statement = null; try { statement = instantiateStatement(connection); setStatementTimeout(statement, transactionTimeout); setFetchSize(statement); return statement; } catch (SQLException e) { closeStatement(statement); throw e; } catch (Exception e) { closeStatement(statement); throw new ExecutorException(\u0026#34;Error preparing statement. Cause: \u0026#34; + e, e); } } protected abstract Statement instantiateStatement(Connection connection) throws SQLException; 参数和结果处理组件 # BaseStatementHandler 依赖两个重要的组件，它们分别是 ParameterHandler 和 ResultSetHandler。\nParameterHandler：BoundSql 中记录的 SQL 语句可能包含 ? 占位符，每个 ? 都对应了 BoundSql 中 parameterMappings 集合中的一个元素，在该 ParameterMapping 对象中记录了对应的参数名称以及该参数的相关属性。ParameterHandler 负责调用 PreparedStatement 的一系列 set*() 方法为 SQL 语句绑定实参。 ResultSetHandler：用于将查询到的 ResultSet 进行处理，转为 model。 RoutingStatementHandler # RoutingStatementHandler 内部会根据 StatementType 创建不同的处理对象。\n后续该类的所有操作都会转发到 delegate 对象上进行处理。\nprivate final StatementHandler delegate; public RoutingStatementHandler(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) { switch (ms.getStatementType()) { case STATEMENT: delegate = new SimpleStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case PREPARED: delegate = new PreparedStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case CALLABLE: delegate = new CallableStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; default: throw new ExecutorException(\u0026#34;Unknown statement type: \u0026#34; + ms.getStatementType()); } } SimpleStatementHandler # SimpleStatementHandler 中重写的 instantiateStatement 方法会直接使用 connection.createStatement(); 创建一个 Statement 实例。\n@Override protected Statement instantiateStatement(Connection connection) throws SQLException { if (mappedStatement.getResultSetType() == ResultSetType.DEFAULT) { return connection.createStatement(); } return connection.createStatement(mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); } 该对象上的所有操作都会直接通过 java.sql.Statement 对象来完成数据库的所有操作。\n@Override public int update(Statement statement) throws SQLException { String sql = boundSql.getSql(); Object parameterObject = boundSql.getParameterObject(); KeyGenerator keyGenerator = mappedStatement.getKeyGenerator(); int rows; if (keyGenerator instanceof Jdbc3KeyGenerator) { statement.execute(sql, Statement.RETURN_GENERATED_KEYS); rows = statement.getUpdateCount(); keyGenerator.processAfter(executor, mappedStatement, statement, parameterObject); } else if (keyGenerator instanceof SelectKeyGenerator) { statement.execute(sql); rows = statement.getUpdateCount(); keyGenerator.processAfter(executor, mappedStatement, statement, parameterObject); } else { statement.execute(sql); rows = statement.getUpdateCount(); } return rows; } @Override public void batch(Statement statement) throws SQLException { String sql = boundSql.getSql(); statement.addBatch(sql); } @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; query(Statement statement, ResultHandler resultHandler) throws SQLException { String sql = boundSql.getSql(); statement.execute(sql); return resultSetHandler.handleResultSets(statement); } @Override public \u0026lt;E\u0026gt; Cursor\u0026lt;E\u0026gt; queryCursor(Statement statement) throws SQLException { String sql = boundSql.getSql(); statement.execute(sql); return resultSetHandler.handleCursorResultSets(statement); } PreparedStatementHandler # PreparedStatementHandler 依赖于 java.sql.PreparedStatement 对象完成对数据库的操作。\njava.sql.PreparedStatement 用于执行预编译的 SQL 语句，尤其适合于执行多次的 SQL 查询或更新操作。\n@Override protected Statement instantiateStatement(Connection connection) throws SQLException { String sql = boundSql.getSql(); if (mappedStatement.getKeyGenerator() instanceof Jdbc3KeyGenerator) { String[] keyColumnNames = mappedStatement.getKeyColumns(); if (keyColumnNames == null) { return connection.prepareStatement(sql, Statement.RETURN_GENERATED_KEYS); } else { return connection.prepareStatement(sql, keyColumnNames); } } if (mappedStatement.getResultSetType() == ResultSetType.DEFAULT) { return connection.prepareStatement(sql); } else { return connection.prepareStatement(sql, mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); } } CallableStatementHandler # CallableStatementHandler 依赖于 java.sql.CallableStatement 对象完成对数据库的操作。\njava.sql.CallableStatement 专门用于调用数据库中的存储过程或函数。\n@Override protected Statement instantiateStatement(Connection connection) throws SQLException { String sql = boundSql.getSql(); if (mappedStatement.getResultSetType() == ResultSetType.DEFAULT) { return connection.prepareCall(sql); } return connection.prepareCall(sql, mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); } "},{"id":8,"href":"/docs/JVM/ByteCode/constant_pool/","title":"常量池","section":"字节码","content":" 常量池 # 常量池是一个表，所有的表项都有以下的格式。tag 表示表项的类型，info 用于表示 tag 类型所需要存储的信息。\ncp_info { u1 tag; u1 info[]; } 常量池索引是从 1 开始的，不是直接从 0 开始。如果需要表达“不引用任何一个常量池项目”的含义，可以把索引值设置为 0 来表示。\n为什么设计常量池？ # 复用 # 常量池允许在类文件中共享常量数据。例如，字符串常量、类名、方法名和字段名等。可以避免了在类文件中多次存储相同的常量，从而减少类文件的大小。\n下边的代码，通过 $javac Main.java 编译后，使用 $javap -v Main.class 进行反编译。\npublic class Main { public static void main(String[] args) { String str = \u0026#34;Hello World!\u0026#34;; System.out.println(str); System.out.println(\u0026#34;Hello World!\u0026#34;); } } public class io.github.ileonli.Main minor version: 0 major version: 65 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #21 // io/github/ileonli/Main super_class: #2 // java/lang/Object interfaces: 0, fields: 0, methods: 2, attributes: 1 Constant pool: #1 = Methodref #2.#3 // java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #2 = Class #4 // java/lang/Object #3 = NameAndType #5:#6 // \u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #4 = Utf8 java/lang/Object #5 = Utf8 \u0026lt;init\u0026gt; #6 = Utf8 ()V #7 = String #8 // Hello World! #8 = Utf8 Hello World! #9 = Fieldref #10.#11 // java/lang/System.out:Ljava/io/PrintStream; #10 = Class #12 // java/lang/System #11 = NameAndType #13:#14 // out:Ljava/io/PrintStream; #12 = Utf8 java/lang/System #13 = Utf8 out #14 = Utf8 Ljava/io/PrintStream; #15 = Methodref #16.#17 // java/io/PrintStream.println:(Ljava/lang/String;)V #16 = Class #18 // java/io/PrintStream #17 = NameAndType #19:#20 // println:(Ljava/lang/String;)V #18 = Utf8 java/io/PrintStream #19 = Utf8 println #20 = Utf8 (Ljava/lang/String;)V #21 = Class #22 // io/github/ileonli/Main #22 = Utf8 io/github/ileonli/Main #23 = Utf8 Code #24 = Utf8 LineNumberTable #25 = Utf8 main #26 = Utf8 ([Ljava/lang/String;)V #27 = Utf8 SourceFile #28 = Utf8 Main.java { public io.github.ileonli.Main(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return LineNumberTable: line 3: 0 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: (0x0009) ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=2, args_size=1 0: ldc #7 // String Hello World! 2: astore_1 3: getstatic #9 // Field java/lang/System.out:Ljava/io/PrintStream; 6: aload_1 7: invokevirtual #15 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 10: getstatic #9 // Field java/lang/System.out:Ljava/io/PrintStream; 13: ldc #7 // String Hello World! 15: invokevirtual #15 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 18: return LineNumberTable: line 5: 0 line 6: 3 line 7: 10 line 8: 18 } 从 class 文件的反编译结果可以看出 main 方法中有大量的复用：\n0: ldc #7 和 13: ldc #7 使用 #7 来代替 Hello World! 字符串。 3: getstatic #9 和 10: getstatic #9 使用 #9 来代替 java/lang/System.out:Ljava/io/PrintStream; 变量。 7: invokevirtual #15 和 15: invokevirtual #15 使用 #15 来代替 java/io/PrintStream.println:(Ljava/lang/String;)V 方法。 符号引用 # JVM 中的指令并不依赖于运行时类、接口、类实例或数组的布局。相反，指令通过常量池表中的符号信息进行引用。\n这意味着 JVM 指令在运行时操作时，不需要直接处理类或对象的内存布局，而是通过常量池中的符号来找到所需的类、方法、字段等信息。\n如我们有个类 Example，其中有个方法为 printMesssage。在编译后的 class 文件中，常量池会有以下条目：\nCONSTANT_Class_info：表示 Example 类。 CONSTANT_NameAndType_info：表示 printMessage 方法的名字和类型。 CONSTANT_Methodref_info：表示 Example 类中的 printMessage 方法。 public class Example { public void printMessage() { System.out.println(\u0026#34;Hello, World!\u0026#34;); } } 使用 $javap -v Example.class 反编译得到的结果。\nJVM 指令例如 invokevirtual 会使用这些常量池条目来确定具体要调用的方法，而不是直接引用方法在内存中的地址。\npublic class io.github.ileonli.Example minor version: 0 major version: 65 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #21 // io/github/ileonli/Example super_class: #2 // java/lang/Object interfaces: 0, fields: 0, methods: 2, attributes: 1 Constant pool: #1 = Methodref #2.#3 // java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #2 = Class #4 // java/lang/Object #3 = NameAndType #5:#6 // \u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #4 = Utf8 java/lang/Object #5 = Utf8 \u0026lt;init\u0026gt; #6 = Utf8 ()V #7 = Fieldref #8.#9 // java/lang/System.out:Ljava/io/PrintStream; #8 = Class #10 // java/lang/System #9 = NameAndType #11:#12 // out:Ljava/io/PrintStream; #10 = Utf8 java/lang/System #11 = Utf8 out #12 = Utf8 Ljava/io/PrintStream; #13 = String #14 // Hello, World! #14 = Utf8 Hello, World! #15 = Methodref #16.#17 // java/io/PrintStream.println:(Ljava/lang/String;)V #16 = Class #18 // java/io/PrintStream #17 = NameAndType #19:#20 // println:(Ljava/lang/String;)V #18 = Utf8 java/io/PrintStream #19 = Utf8 println #20 = Utf8 (Ljava/lang/String;)V #21 = Class #22 // io/github/ileonli/Example #22 = Utf8 io/github/ileonli/Example #23 = Utf8 Code #24 = Utf8 LineNumberTable #25 = Utf8 printMessage #26 = Utf8 SourceFile #27 = Utf8 Example.java { public io.github.ileonli.Example(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return LineNumberTable: line 3: 0 public void printMessage(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #13 // String Hello, World! 5: invokevirtual #15 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 5: 0 line 6: 8 } 常量池项目类型 # 常量池中的表项共有下边几种：\nConstant Kind Tag Class File Format Java SE CONSTANT_Utf8 1 45.3 1.0.2 CONSTANT_Integer 3 45.3 1.0.2 CONSTANT_Float 4 45.3 1.0.2 CONSTANT_Long 5 45.3 1.0.2 CONSTANT_Double 6 45.3 1.0.2 CONSTANT_Class 7 45.3 1.0.2 CONSTANT_String 8 45.3 1.0.2 CONSTANT_Fieldref 9 45.3 1.0.2 CONSTANT_Methodref 10 45.3 1.0.2 CONSTANT_InterfaceMethodref 11 45.3 1.0.2 CONSTANT_NameAndType 12 45.3 1.0.2 CONSTANT_MethodHandle 15 51.0 7 CONSTANT_MethodType 16 51.0 7 CONSTANT_Dynamic 17 55.0 11 CONSTANT_InvokeDynamic 18 51.0 7 CONSTANT_Module 19 53.0 9 CONSTANT_Package 20 53.0 9 CONSTANT_Class_info # CONSTANT_Class_info 用于表示一个类，或者一个接口。\nname_index 为指向常量池表项的索引，该表项必须为 CONSTANT_Utf8_info。\nCONSTANT_Class_info { u1 tag; u2 name_index; } "},{"id":9,"href":"/docs/system-programming/address-families/","title":"网络地址族","section":"Linux 网络编程","content":" 网络地址族 # 网络地址 # 网络地址分为 IPv4 和 IPv6，分别使用 sockaddr_in 和 sockaddr_in6 结构体表示。\nsockaddr_in # struct sockaddr_in { sa_family_t sin_family; /* address family: AF_INET */ in_port_t sin_port; /* port in network byte order */ struct in_addr sin_addr; /* internet address */ /* Pad to size of `struct sockaddr\u0026#39;. */ unsigned char sin_zero[8]; }; /* Internet address */ struct in_addr { uint32_t s_addr; /* address in network byte order */ }; sin_family：在 IPv4 中设为 AF_INET。 sin_port：网络字节序保存的端口（0～65535）。 sin_addr：网络字节序保存的 32 位 IP 地址信息。 sin_zero：使 sockaddr_in 和 sockaddr 结构体大小保持一致而插入的填充位，需手动设为 0。 https://man7.org/linux/man-pages/man7/ip.7.html\nsockaddr_in6 # struct sockaddr_in6 { sa_family_t sin6_family; /* AF_INET6 */ in_port_t sin6_port; /* port number */ uint32_t sin6_flowinfo; /* IPv6 flow information */ struct in6_addr sin6_addr; /* IPv6 address */ uint32_t sin6_scope_id; /* Scope ID (new in Linux 2.4) */ }; struct in6_addr { unsigned char s6_addr[16]; /* IPv6 address */ }; sin6_family：在 IPv6 中总设为 AF_INET6。 sin6_port：网络字节序保存的端口（0～65535）。 sin6_flowinfo：IPv6 流信息（不广泛使用）。 sin6_addr：表示 IPv6 地址的结构体，定义为 struct in6_addr。 sin6_scope_id：范围标识符（用于链路本地和站点本地地址）。 https://man7.org/linux/man-pages/man7/ipv6.7.html\nin_addr 和 in6_addr # in_addr # 我们比较熟悉的 IPv4 地址表示方法为点分十进制表示法，如：201.123.235.213。\n而 in_addr 结构体使用 uint32_t 保存 IPv4 地址，我们需要将字符串形式的 IPv4 地址转为 32 位整数表示。\ninet_addr 函数可用于转换，该函数在转换的同时会进行网络字节序的转换。\ninet_ntoa 函数则相反，将 in_addr 结构体转为字符串。\n注意：inet_ntoa 函数返回的是一个指向静态缓冲区的指针，最好将返回值拷贝到其它地方，以免被覆盖。\n#include \u0026lt;arpa/inet.h\u0026gt; in_addr_t inet_addr(const char *cp); char *inet_ntoa(struct in_addr in); 也可以使用 inet_aton 函数，该函数将结果直接保存到传入的 inp 结构体中。\n#include \u0026lt;arpa/inet.h\u0026gt; int inet_aton(const char *cp, struct in_addr *inp); in6_addr # sockaddr_in5 结构体中的 in6_addr 结构体包含一个 unsigned char 类型的成员 s6_addr，用于存储 128 位的 IPv6 地址。\ninet_pton 函数中的 af 参数必须为 AF_INET 和 AF_INET6，分别处理 IPv4 和 IPv6 协议。\n#include \u0026lt;arpa/inet.h\u0026gt; int inet_pton(int af, const char *restrict src, void *restrict dst); const char *inet_ntop(int af, const void *restrict src, char dst[restrict .size], socklen_t size); 网络地址初始化 # IPv4 # #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; int main() { const char *address = \u0026#34;211.123.211.168\u0026#34;; // IP 地址 const char *port = \u0026#34;7890\u0026#34;; // 端口 struct sockaddr_in addr; memset(\u0026amp;addr, 0, sizeof(addr)); addr.sin_family = AF_INET; // IPv4; addr.sin_addr.s_addr = inet_addr(address); // 设置 IP 地址 addr.sin_port = htons(atoi(port)); // 以网络字节序设置端口 } IPv6 # #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; int main() { const char *address = \u0026#34;2001:0db8:85a3:0000:0000:8a2e:0370:7334\u0026#34;; // IPv6 地址 const char *port = \u0026#34;7890\u0026#34;; // 端口 struct sockaddr_in6 addr; memset(\u0026amp;addr, 0, sizeof(addr)); addr.sin6_family = AF_INET6; // IPv6 inet_pton(AF_INET6, address, \u0026amp;addr.sin6_addr); // 设置 IP 地址 addr.sin6_port = htons(atoi(port)); // 以网络字节序设置端口 } 思考 # 为什么 sockaddr_in 和 sockaddr_in6 分别表示 IPv4 和 IPv6 协议，还要额外使用 sa_family_t 指定协议版本呢？\n因为 connect、bind、和 accept 函数第二个参数都接收 sockaddr 结构体。因此，需要使用 sa_family 用于区分不同版本的协议。通过使用通用的 sockaddr 结构体，该函数不仅可以处理 IPv4 和 IPv6 协议，还可处理其它协议。这样，就不需要为每种协议都提供对应的函数。\nstruct sockaddr { sa_family_t sa_family; /* Address family */ char sa_data[]; /* Socket address */ }; "},{"id":10,"href":"/docs/Netty/EventLoop/","title":"EventLoop","section":"Netty","content":" EventLoop # 一旦注册，将处理 Channel 的所有 I/O 操作。一个 EventLoop 实例通常会处理多个 Channel，但这可能取决于实现细节和内部机制。\nEventLoop 本质是一个单线程执行器，同时维护了一个 Selector。\nEventLoop 由 Thread 驱动，且不会更改\ntry (EventLoop loop = new DefaultEventLoop()) { for (int i = 0; i \u0026lt; 3; i++) { loop.submit(() -\u0026gt; { for (int j = 0; j \u0026lt; 16; j++) { System.out.print(j + \u0026#34; \u0026#34;); } System.out.println(); }); } } 使用 EventLoop 的定时调度功能。\ntry (EventLoop loop = new DefaultEventLoop()) { ScheduledFuture\u0026lt;?\u0026gt; future = loop.schedule( () -\u0026gt; LocalDateTime.now(), 3, TimeUnit.SECONDS); System.out.println(future.get()); } 如果（当前）调用线程正是支撑 EventLoop 的线程，那么所提交的代码块将会被（直接）执行。否则，EventLoop 将调度该任务以便稍后执行，并将它放入到内部队列中。当\n如果必须要进行阻塞调用或者执行长时间运行的任务，我们建议使用一个专门的 EventExecutor。\n继承关系 # OrderedEventExecutor # 用于标记 EventExecutor 将以有序（ordered） / 串行（serial）的方式处理提交的任务。\npublic interface OrderedEventExecutor extends EventExecutor { } EventLoopGroup # next() 方法用于获取该 EventLoopGroup 中的下一个 EventLoop。 register() 将 Channel 注册到该 EventLoopGroup 中，只可以注册一次。 public interface EventLoopGroup extends EventExecutorGroup { @Override EventLoop next(); ChannelFuture register(Channel channel); ChannelFuture register(ChannelPromise promise); @Deprecated ChannelFuture register(Channel channel, ChannelPromise promise); } EventExecutor # EventExecutor 是一个特殊的 EventExecutorGroup，它提供了一些方便的方法来查看线程是否在事件循环中执行。除此之外，它还扩展了 EventExecutorGroup 以允许一种通用的方式来访问方法。\nnext() 返回自身。 parent() 返回所属的 EventExecutorGroup，没有则返回 null。 inEventLoop() 返回当前执行线程是否是 EventLoop 所绑定的线程。 public interface EventExecutor extends EventExecutorGroup { @Override EventExecutor next(); EventExecutorGroup parent(); boolean inEventLoop(); boolean inEventLoop(Thread thread); \u0026lt;V\u0026gt; Promise\u0026lt;V\u0026gt; newPromise(); \u0026lt;V\u0026gt; ProgressivePromise\u0026lt;V\u0026gt; newProgressivePromise(); \u0026lt;V\u0026gt; Future\u0026lt;V\u0026gt; newSucceededFuture(V result); \u0026lt;V\u0026gt; Future\u0026lt;V\u0026gt; newFailedFuture(Throwable cause); } EventExecutorGroup # EventExecutorGroup 负责通过它的 next() 方法提供 EventExecutor。除此之外，还负责处理生命周期，允许以全局方式关闭它们。\npublic interface EventExecutorGroup extends ScheduledExecutorService, Iterable\u0026lt;EventExecutor\u0026gt; { boolean isShuttingDown(); Future\u0026lt;?\u0026gt; shutdownGracefully(); Future\u0026lt;?\u0026gt; shutdownGracefully(long quietPeriod, long timeout, TimeUnit unit); Future\u0026lt;?\u0026gt; terminationFuture(); @Override @Deprecated void shutdown(); @Override @Deprecated List\u0026lt;Runnable\u0026gt; shutdownNow(); EventExecutor next(); @Override Iterator\u0026lt;EventExecutor\u0026gt; iterator(); @Override Future\u0026lt;?\u0026gt; submit(Runnable task); @Override \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Runnable task, T result); @Override \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task); @Override ScheduledFuture\u0026lt;?\u0026gt; schedule(Runnable command, long delay, TimeUnit unit); @Override \u0026lt;V\u0026gt; ScheduledFuture\u0026lt;V\u0026gt; schedule(Callable\u0026lt;V\u0026gt; callable, long delay, TimeUnit unit); @Override ScheduledFuture\u0026lt;?\u0026gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit); @Override ScheduledFuture\u0026lt;?\u0026gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit); } ScheduledExecutorService # 继承自 java.util.concurrent.ScheduledExecutorService 类。\nEventLoop 主要实现 # EventLoopGroup defaultGroup = new DefaultEventLoopGroup(); EventLoopGroup nioGroup = new NioEventLoopGroup(); # public abstract class SingleThreadEventExecutor extends AbstractScheduledEventExecutor implements OrderedEventExecutor { ... private void execute(Runnable task, boolean immediate) { boolean inEventLoop = inEventLoop(); addTask(task); if (!inEventLoop) { startThread(); if (isShutdown()) { boolean reject = false; try { if (removeTask(task)) { reject = true; } } catch (UnsupportedOperationException e) { // The task queue does not support removal so the best thing we can do is to just move on and // hope we will be able to pick-up the task before its completely terminated. // In worst case we will log on termination. } if (reject) { reject(); } } } if (!addTaskWakesUp \u0026amp;\u0026amp; immediate) { wakeup(inEventLoop); } } ... } 处理 I/O 事件 # "},{"id":11,"href":"/docs/MyBatis/Executor/","title":"Executor","section":"MyBatis","content":" Executor # SqlSession 中的具体操作都会通过 Executor 接口进行实现。\npublic class DefaultSqlSession implements SqlSession { ... private final Executor executor; ... } ExecutorType # Executor 一共有三种类型：\nSIMPLE： REUSE： BATCH： public enum ExecutorType { SIMPLE, REUSE, BATCH } BaseExecutor # BaseExecutor 是继承自 Executor 接口的抽象类。该类实现了 Executor 中的大部分方法。\n该类使用了模板方法模式，继承 BaseExecutor 的子类只需要实现下边的四个基本方法即可完成数据库的相关操作。\npublic abstract class BaseExecutor implements Executor { ... protected abstract int doUpdate(MappedStatement ms, Object parameter) throws SQLException; protected abstract List\u0026lt;BatchResult\u0026gt; doFlushStatements(boolean isRollback) throws SQLException; protected abstract \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException; protected abstract \u0026lt;E\u0026gt; Cursor\u0026lt;E\u0026gt; doQueryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds, BoundSql boundSql) throws SQLException; ... } SimpleExecutor # @Override public int doUpdate(MappedStatement ms, Object parameter) throws SQLException { Statement stmt = null; try { Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(this, ms, parameter, RowBounds.DEFAULT, null, null); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.update(stmt); } finally { closeStatement(stmt); } } @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException { Statement stmt = null; try { Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.query(stmt, resultHandler); } finally { closeStatement(stmt); } } @Override protected \u0026lt;E\u0026gt; Cursor\u0026lt;E\u0026gt; doQueryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds, BoundSql boundSql) throws SQLException { Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, null, boundSql); Statement stmt = prepareStatement(handler, ms.getStatementLog()); Cursor\u0026lt;E\u0026gt; cursor = handler.queryCursor(stmt); stmt.closeOnCompletion(); return cursor; } @Override public List\u0026lt;BatchResult\u0026gt; doFlushStatements(boolean isRollback) { return Collections.emptyList(); } "},{"id":12,"href":"/docs/MyBatis/Cache/","title":"Cache","section":"MyBatis","content":" 一级缓存和二级缓存 # MyBatis 提供了二层缓存架构，分别为：一级缓存和二级缓存。\n一级缓存 # 一级缓存是会话级别的，MyBatis 每创建一个 SqlSession，就表示开启了一次数据库会话。在一次会话内，可能会在短时间内反复执行完全相同的查询语句。\nExecutor 对象内会建立一个简单的缓存，在执行查询操作时，会先查询一级缓存，如果其中存在完全一样的查询语句，则直接从一级缓存中取出结果。\n一级缓存的生命周期与 SqlSession 相同，SqlSession 内部有 Executor 对象，当调用 SqlSession 的 close() 方法时，会调用 Executor 的 close() 方法。\n具体流程 # @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException { BoundSql boundSql = ms.getBoundSql(parameter); CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); return query(ms, parameter, rowBounds, resultHandler, key, boundSql); } @SuppressWarnings(\u0026#34;unchecked\u0026#34;) @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { ErrorContext.instance().resource(ms.getResource()).activity(\u0026#34;executing a query\u0026#34;).object(ms.getId()); if (closed) { throw new ExecutorException(\u0026#34;Executor was closed.\u0026#34;); } if (queryStack == 0 \u0026amp;\u0026amp; ms.isFlushCacheRequired()) { clearLocalCache(); } List\u0026lt;E\u0026gt; list; try { queryStack++; list = resultHandler == null ? (List\u0026lt;E\u0026gt;) localCache.getObject(key) : null; if (list != null) { handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); } else { list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); } } finally { queryStack--; } if (queryStack == 0) { for (DeferredLoad deferredLoad : deferredLoads) { deferredLoad.load(); } // issue #601 deferredLoads.clear(); if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) { // issue #482 clearLocalCache(); } } return list; } CacheKey # CacheKey 由 MappedStatement 的 id、对应的 offset 和 limit、SQL 语句（包含 ? 占位符）、用户传入的参数和 Environment 的 id 组成。\n下边为用于创建 CacheKey 的参数例子：\nms.getId()：io.github.ileonli.mapper.UserMapper.findById boundSql.getSql()：SELECT * FROM user WHERE id = ? parameterMappings：传入到 SQL 中的参数 public CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) { if (closed) { throw new ExecutorException(\u0026#34;Executor was closed.\u0026#34;); } CacheKey cacheKey = new CacheKey(); cacheKey.update(ms.getId()); cacheKey.update(rowBounds.getOffset()); cacheKey.update(rowBounds.getLimit()); cacheKey.update(boundSql.getSql()); List\u0026lt;ParameterMapping\u0026gt; parameterMappings = boundSql.getParameterMappings(); TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry(); // mimic DefaultParameterHandler logic MetaObject metaObject = null; for (ParameterMapping parameterMapping : parameterMappings) { if (parameterMapping.getMode() != ParameterMode.OUT) { Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) { value = boundSql.getAdditionalParameter(propertyName); } else if (parameterObject == null) { value = null; } else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) { value = parameterObject; } else { if (metaObject == null) { metaObject = configuration.newMetaObject(parameterObject); } value = metaObject.getValue(propertyName); } cacheKey.update(value); } } if (configuration.getEnvironment() != null) { // issue #176 cacheKey.update(configuration.getEnvironment().getId()); } return cacheKey; } 二级缓存 # "},{"id":13,"href":"/docs/Netty/EventLoopGroup/","title":"EventLoopGroup","section":"Netty","content":" EventLoopGroup # "},{"id":14,"href":"/docs/system-programming/block-and-nonblock-io/","title":"（非）阻塞 I/O","section":"Linux 网络编程","content":" （非）阻塞 I/O 和 epoll（翻译） # 原文：https://eklitzke.org/blocking-io-nonblocking-io-and-epoll\n在这篇文章中，我想解释使用非阻塞 I/O 时会发生什么。我特别想说明的是:\n使用 fcntl 函数设置文件描述符的 O_NONBLOCK 时的语义。 非阻塞（nonblocking） I/O 与异步（asynchronous） I/O 的区别。 为什么非阻塞 I/O 经常与诸如 select、epoll 和 kqueue 等 I/O 多路复用器一起使用。 非阻塞模式如何与 epoll 中的边缘触发轮询交互。 阻塞模式 # 默认情况下，Unix 系统所有的文件描述符都以“阻塞模式”启动。这意味着像 read、write 或 connect 这样的 I/O 系统调用可能会阻塞。一个很容易理解的方法是当你从一个普通的基于 TTY 的程序中的 stdin 读取数据时会发生什么。如果你在 stdin上调用 read，那么你的程序将会阻塞，直到数据实际上可用，比如当用户实际上在键盘上键入字符时。具体来说，内核会将进程置于“睡眠”状态，直到 stdin 上的数据可用。其他类型的文件描述符也是如此。例如，如果你尝试从 TCP 套接字中读取数据，那么 read 调用将会阻塞，直到连接的另一端实际上发送数据。\n阻塞对于应该并发运行的程序来说是一个问题，因为被阻塞的进程会被挂起。解决这个问题有两种不同但互补的方式：\n非阻塞模式。 I/O 多路复用系统调用，例如 select 和 epoll。 这两种解决方案经常一起使用，但它们是解决这个问题的独立策略，通常两者都会被使用。接下来我们将会看到它们之间的区别以及为什么它们通常都会被同时使用。\n非阻塞模式 # 通过 fcntl 函数在文件描述符的标志集中添加 O_NONBLOCK，可以将文件描述符设置为“非阻塞模式”：\n/* set O_NONBLOCK on fd */ int flags = fcntl(fd, F_GETFL, 0); fcntl(fd, F_SETFL, flags | O_NONBLOCK); 从这一点开始，文件描述符被视为非阻塞的。当发生这种情况时，像 read 和 write 这样的 I/O 系统调用将返回 -1，并且 errno 将被设置为 EWOULDBLOCK。\n这很有趣，但单独使用实际上并不是那么有用。仅仅使用这种基本方法是没有有效方式同时在多个文件描述符上进行 I/O 的。例如，假设我们有两个文件描述符，并希望同时读取它们。这可以通过循环检查每个文件描述符是否有数据，然后在再次检查之前短暂休眠来实现：\nstruct timespec sleep_interval{.tv_sec = 0, .tv_nsec = 1000}; ssize_t nbytes; for (;;) { /* try fd1 */ if ((nbytes = read(fd1, buf, sizeof(buf))) \u0026lt; 0) { if (errno != EWOULDBLOCK) { perror(\u0026#34;read/fd1\u0026#34;); } } else { handle_data(buf, nbytes); } /* try fd2 */ if ((nbytes = read(fd2, buf, sizeof(buf))) \u0026lt; 0) { if (errno != EWOULDBLOCK) { perror(\u0026#34;read/fd2\u0026#34;); } } else { handle_data(buf, nbytes); } /* sleep for a bit; real version needs error checking! */ nanosleep(sleep_interval, NULL); } 这种方法确实有效，但存在很多缺点：\n当数据传入速度很慢时，程序会频繁而不必要地唤醒，这会浪费 CPU 资源。 当数据到达时，如果程序正在睡眠，可能不会立即读取数据，因此程序的延迟会很高。 使用这种模式处理大量文件描述符会变得繁琐。 为了解决这些问题，我们需要 I/O 多路复用。\nI/O 多路复用（select, epoll, kqueue） # 有几种I/O多路复用系统调用。例如，POSIX 定义的 select，Linux 上的 epoll 系列，以及 BSD 上的 kqueue 系列都是 I/O 多路复用的例子。它们在基本原理上都是相同的：它们让内核知道一组文件描述符上感兴趣的事件（通常是读事件和写事件），然后它们会阻塞，直到发生感兴趣的事件。例如，你可以告诉内核你只对文件描述符 X 上的读事件感兴趣，对文件描述符 Y 上的读和写事件都感兴趣，以及对文件描述符 Z 上的写事件感兴趣。\n这些 I/O 多路复用系统调用通常不关心文件描述符是处于阻塞模式还是非阻塞模式。你可以将所有的文件描述符都保留在阻塞模式下，它们仍然可以与 select 或 epoll 一起正常工作。如果你只对 select 或 epoll 返回的文件描述符调用 read 和 write，那么即使这些文件描述符处于阻塞模式，这些调用也不会阻塞。但有一个重要的例外，文件描述符的阻塞或非阻塞状态对于边缘触发轮询是重要的，下面会进一步解释。\n并发的多路复用方法是我所谓的“异步 I/O”。有时人们也会将这种方法称为“非阻塞 I/O”，我认为这是对系统编程层面中“非阻塞”含义的混淆。我建议将术语“非阻塞”保留用于指代文件描述符是否实际处于非阻塞模式。\nO_NONBLOCK 与 I/O 多路复用的交互方式 # 假设我们正在使用带有阻塞文件描述符的 select 编写一个简单的套接字服务器。为简单起见，在此示例中，我们只有要从中读取的文件描述符，这些文件描述符存储在 read_fds 中。事件循环的核心部分将调用 select，然后针对每个具有数据的文件描述符调用一次 read：\nssize_t nbytes; for (;;) { /* select call happens here */ if (select(FD_SETSIZE, \u0026amp;read_fds, NULL, NULL, NULL) \u0026lt; 0) { perror(\u0026#34;select\u0026#34;); exit(EXIT_FAILURE); } for (int i = 0; i \u0026lt; FD_SETSIZE; i++) { if (FD_ISSET(i, \u0026amp;read_fds)) { /* read call happens here */ if ((nbytes = read(i, buf, sizeof(buf))) \u0026gt;= 0) { handle_read(nbytes, buf); } else { /* real version needs to handle EINTR correctly */ perror(\u0026#34;read\u0026#34;); exit(EXIT_FAILURE); } } } } 这样做是有效的，而且完全没问题。但是，如果 buf 很小，而且有大量数据同时传输会发生什么？具体来说，假设 buf 是一个 1024 字节的缓冲区，但一次传输了 64KB 的数据。为了处理这个请求，我们将调用 select，然后调用 64 次 read。总共需要 128 次系统调用，这是相当多的。\n如果缓冲区大小太小，就必须调用很多次 read，这是无法避免的。但也许我们可以减少调用 select 的次数？在这个例子中，理想情况下我们只会调用一次 select。\n事实上，这是可能的，而且可以通过将文件描述符设置为非阻塞模式来实现。基本思想是你可以在一个循环中不断调用 read，直到它返回 EWOULDBLOCK 为止。实现如下所示：\nssize_t nbytes; for (;;) { /* select call happens here */ if (select(FD_SETSIZE, \u0026amp;read_fds, NULL, NULL, NULL) \u0026lt; 0) { perror(\u0026#34;select\u0026#34;); exit(EXIT_FAILURE); } for (int i = 0; i \u0026lt; FD_SETSIZE; i++) { if (FD_ISSET(i, \u0026amp;read_fds)) { /* NEW: loop until EWOULDBLOCK is encountered */ for (;;) { /* read call happens here */ nbytes = read(i, buf, sizeof(buf)); if (nbytes \u0026gt;= 0) { handle_read(nbytes, buf); } else { if (errno != EWOULDBLOCK) { /* real version needs to handle EINTR correctly */ perror(\u0026#34;read\u0026#34;); exit(EXIT_FAILURE); } break; } } } } } 在这个例子中（1024 字节缓冲区，传入 64KB 的数据），我们将进行 66 次系统调用：select 将被调用一次，read 将被调用 64 次而不会出错，read 将被调用并返回 EWOULDBLOCK 一次。这要比之前的例子好得多！这几乎是前一个例子的一半，这将显著提高性能和可伸缩性。\n这种方法的缺点是由于新的循环，至少会有一次额外的 read 调用，因为它被调用直到返回 EWOULDBLOCK。假设通常情况下读取缓冲区足够大，可以在一个 read 调用中读取所有传入的数据。那么在循环中，通常情况下会有三次系统调用而不是只有两次：select 等待数据，read 实际读取数据，然后再次调用 read 以获取 EWOULDBLOCK。\n边缘触发轮询（Edge-Triggered Polling） # 边缘触发轮询是非阻塞 I/O 的另一个重要用途，特别是在 epoll 系统调用中。这个系统调用有两种模式：水平触发和边缘触发。水平触发是一种更简单的编程模型，类似于经典的 select 系统调用。为了解释它们之间的区别，我们需要了解 epoll 在内核中的工作方式。\n假设你告诉内核你有兴趣使用 epoll 来监视某个文件描述符上的读事件。内核为每个文件描述符维护这些兴趣的列表。当数据到达文件描述符时，内核遍历兴趣列表，并唤醒每个在 epoll_wait 中被阻塞的进程，其中包含了该文件描述符在事件列表中。\n上述内容无论 epoll 处于哪种触发模式都会发生。水平触发和边缘触发轮询的区别在于调用 epoll_wait 时内核的行为。在水平触发模式中，内核将遍历兴趣列表中的每个文件描述符，以查看它是否已满足兴趣条件。例如，如果你在文件描述符 8 上注册了一个读事件，调用 epoll_wait 时内核将首先检查：文件描述符 8 是否已经有数据准备好读取？如果任何文件描述符匹配兴趣条件，则 epoll_wait 可以立即返回而不阻塞。\n相比之下，在边缘触发模式中，内核跳过这个检查，并在调用 epoll_wait 时立即将进程置于睡眠状态。这使得程序员必须完全负责，需要完全读取和写入每个文件描述符的所有数据，然后才能等待。\n边缘触发模式使得 epoll 成为时间复杂度为 O(1) 的 I/O 多路复用器：epoll_wait 调用会立即挂起，由于事先为每个文件描述符维护了一个列表，当新数据到达时，内核会在 O(1) 时间知道必须要唤醒的进程。\n以下是边缘触发和水平触发模式之间差异的更详细示例。假设你的读取缓冲区是 100 字节，而文件描述符上传入了 200 字节的数据。然后假设你只调用了一次 read，然后再次调用了 epoll_wait。仍然有 100 字节的数据准备好读取。在水平触发模式中，内核会注意到这一点，并通知进程应该再次调用 read。相比之下，在边缘触发模式中，内核将立即进入睡眠状态。如果另一侧正在期待响应（例如，发送的数据是某种 RPC），那么两侧将会“死锁”，因为服务器将等待客户端发送更多数据，但客户端将等待服务器发送响应。\n要使用边缘触发轮询，你必须将文件描述符设置为非阻塞模式。然后你必须每次调用 read 或 write 直到它们返回 EWOULDBLOCK 为止。如果你未能满足这些条件，你将错过内核的通知。但这样做有一个很大的好处：每次调用 epoll_wait 都会更有效率，这对于具有极高并发性的程序来说非常重要。如果你想了解更多细节，我强烈建议你阅读 epoll(7) 手册页。\n"},{"id":15,"href":"/docs/Netty/Channel/","title":"Channel","section":"Netty","content":" Channel # "},{"id":16,"href":"/docs/system-programming/multiplexing/","title":"I/O 多路复用","section":"Linux 网络编程","content":" I/O 多路复用 # I/O 复用可以使程序同时监听多个文件描述符。\nselect # select 函数允许程序监视多个文件描述符，直到一个或多个文件描述符“准备好”进行某类 I/O 操作。\nselect 成功时返回就绪文件描述符的总数，如果超时时间内没有任何文件描述符就绪，则返回 0。失败时返回 -1 并设置 errno。\n#include \u0026lt;sys/select.h\u0026gt; int select(int nfds, fd_set* readfds, fd_set* writefds, fd_set* exceptfds, struct timeval * timeout); 函数参数 # nfds：指定被监听的文件描述符的总数。这个参数应该被设置为三个集合中编号最高的文件描述符，再加 1，因为文件描述符是从 0 开始的。\nreadfds、writefds 和 exceptfds：分别指向可读、可写和异常事件对应的文件描述符集合。如果没有文件描述符要监听，则可以将对应的 fd_set 参数设为 NULL。\nfd_set 结构体仅包含一个数组，数组每一位标记一个文件描述符，最大容纳长度由 FD_SETSIZE 指定。\n/* fd_set for select and pselect. */ typedef struct { /* XPG4.2 requires this member name. Otherwise avoid the name from the global namespace. */ #ifdef __USE_XOPEN __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;fds_bits) #else __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;__fds_bits) #endif } fd_set; 为方便对此结构体进行操作，提供了以下几个宏函数对其进行操作，宏函数如下：\n为方便展示，对宏函数中的所有参数加上了类型\nFD_SET(fd, fdsetp)：将文件描述符 fd 添加到 fdset 指向的集合中。 FD_CLR(fd, fdsetp)：将文件描述符 fd 从 fdset 指向的集合中移除。 FD_ISSET(fd, fdsetp)：如果文件描述符 fd 是 fdset 指向的集合中的成员，则返回 true。 FD_ZERO(fdsetp)：将 fdset 指向的集合初始化为空。 timeval：用来设置 select 函数的超时时间，采用指针作为参数是因为内核将修改以告诉应用程序 select 等待了多久。\n如果 timeval 结构体中的 tv_sec 和 tv_usec 成员都传递 0，则 select 函数立即返回。如果传递 NULL，则一直阻塞，直到某个文件描述符就绪。\n/* A time value that is accurate to the nearest microsecond but also has a range of years. */ struct timeval { #ifdef __USE_TIME_BITS64 __time64_t tv_sec;\t/* Seconds. */ __suseconds64_t tv_usec;\t/* Microseconds. */ #else __time_t tv_sec;\t/* Seconds. */ __suseconds_t tv_usec;\t/* Microseconds. */ #endif }; 就绪条件 # 在网络编程中，下边情况下 socket 可读：\n在网络编程中，下边情况下 socket 可写：\nselect 函数能处理的异常情况只有一种：socket 上接收到带外数据。\n循环中使用 # 由于这些结构体会在调用中被修改，如果要在循环中重复调用 select 函数，我们必须保证每次都要重新初始化它们。\npoll # poll 函数和 select 函数调用返回值一致。\n#include \u0026lt;poll.h\u0026gt; int poll(struct pollfd *fds, nfds_t nfds, int timeout); 函数参数 # fds：需要 poll 函数检查的文件描述符，该参数为 pollfd 结构体数组。\npollfd 结构体中 fd 指定文件描述符；events 告诉 poll 函数需要监听哪些事件；revents 由内核对其进行修改，以通知应用程序 fd 上实际发生了哪些事件。\n位掩码 events 返回到revents 描述 POLLIN ● ● 可读取非高优先级的数据 POLLRDNORM ● ● 等同于POLLIN POLLRDBAND ● ● 可读取优先级数据（Linux 中不使用） POLLPRI ● ● 可读取高优先级数据 POLLRDHUP ● ● 对端套接字关闭 POLLOUT ● ● 普通数据可写 POLLWRNORM ● ● 等同于POLLOUT POLLWRBAND ● ● 优先级数据可写入 POLLERR ● 有错误发生 POLLHUP ● 出现挂断 POLLNVAL ● 文件描述符未打开 POLLMSG Linux 中不使用 struct pollfd { int fd; /* file descriptor */ short events; /* requested events */ short revents; /* returned events */ }; nfds：用于指定数组 fds 中元素的个数。\n/* Type used for the number of file descriptors. */ typedef unsigned long int nfds_t; timeout：指定 poll 的超时值，单位为毫秒。\n当 timeout 为 -1 时，poll 调用将一直阻塞，直到某个事件发生； 当 timeout 为 0 时，poll 调用将立即返回。 epoll # epoll 是 Linux 特有的 I/O 复用函数。epoll 需要使用额外的文件描述符，标识内核中的这个事件表，需要使用 epoll_create 函数创建，返回文件描述符。\nsize 是想要通过 epoll 来检查的文件描述符个数。该参数并不是一个上限，而是告诉内核应该如何为内部数据结构划分初始大小（从 Linux 2.6.8 版以来，size 参数被忽略不用，因为内核实现做了修改意味着该参数提供的信息已经不再需要了）。\n#include \u0026lt;sys/epoll.h\u0026gt; int epoll_create (int size); int epoll_create1 (int flags); epoll_ctl # epoll_ctl 函数能够修改由文件描述符 epfd 所代表的兴趣列表。\nint epoll_ctl (int epfd, int op, int fd, struct epoll_event *event); epfd 是调用 epoll_create 函数的返回值。\nop 用于操作操作类型。\n/* Valid opcodes ( \u0026#34;op\u0026#34; parameter ) to issue to epoll_ctl(). */ #define EPOLL_CTL_ADD 1\t/* Add a file descriptor to the interface. */ #define EPOLL_CTL_DEL 2\t/* Remove a file descriptor from the interface. */ #define EPOLL_CTL_MOD 3\t/* Change file descriptor epoll_event structure. */ events 是一个位掩码，指定了待检查描述符 fd 上感兴趣的事件集合。\nstruct epoll_event { uint32_t events;\t/* Epoll events */ epoll_data_t data; /* User data variable */ } data 当描述符 fd 就绪时，传递给调用者的信息。\ntypedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t; epoll_wait # 返回 epoll 实例中处于就绪态的文件描述符信息。单个 epoll_wait 函数调用能返回多个就绪态文件描述符的信息。\n调用成功后，epoll_wait 函数返回数组 events 元素个数。\nint epoll_wait (int epfd, struct epoll_event *events, int maxevents, int timeout); events 所指向的结构体数组中返回的是有关就绪态文件描述符的信息。\n数组 events 的空间由调用者负责申请，所包含的元素个数由参数 maxevents 指定。\ntimeout：指定 epoll 的超时值，单位为毫秒。\n当 timeout 为 -1 时，epoll 调用将一直阻塞，直到某个事件发生； 当 timeout 为 0 时，epoll 执行一次非阻塞式的检查，看兴趣列表中的文件描述符上产生了哪个事件。 当 timeout 大于 0 时，epoll 阻塞至多 timeout 毫秒，直到文件描述符上有事件发生，或者直到捕获到一个信号为止。 水平触发和边缘触发 # epoll 默认工作模式为水平触发，当往 epoll 内核事件表中注册一个文件描述符上的 EPOLLET 事件时，将以边缘触发模式工作。\nLT 模式（水平）：缓冲区剩余未读尽的数据会导致 epoll_wait 返回。直到新的事件满足才会触发。支持阻塞和非阻塞。\nET 模式（边缘）：缓冲区剩余未读尽的数据不会导致 epoll_wait 返回。必须设置为非阻塞。\n"},{"id":17,"href":"/docs/Netty/ChannelHandler/","title":"ChannelHandler","section":"Netty","content":" ChannelHandler # ChannelHandler 共分为两类，ChannelInboundHandler 和 ChannelOutboundHandler。\nChannelInboundHandler： ChannelOutboundHandler： 常用 # ChannelHandlerAdapter ChannelInboundHandlerAdapter ChannelOutboundHandlerAdapter ChannelDuplexHandler Pipeline 执行顺序 # Inbound 是从 ChannelPipeline 头到尾部，Outbound 是从 ChannelPipeline 尾到头部。\n生命周期 # handlerAdded new ChannelHandler() { @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { } @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception { } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { } } ChannelInboundHandler # ChannelInboundHandlerAdapter # ChannelInboundHandlerAdapter 中的所有方法默认会调用 ctx.fireChannel*() 传递到下一个 Handler。\nChannelInboundHandlerAdapter 不会释放 ByteBuf。\nChannelOutboundHandler # 编码器和解码器 # "},{"id":18,"href":"/docs/system-programming/reactor-pattern/","title":"Reactor 模型","section":"Linux 网络编程","content":" Reactor 模型 # Reactor 模型中定义的三种角色：\nReactor：负责监听和分配事件，将I/O事件分派给对应的 Handler。新的事件包含连接建立就绪、读就绪、写就绪等。 Acceptor：处理客户端新连接，并分派请求到处理器链中。 Handler：将自身与事件绑定，执行非阻塞读/写任务，完成channel的读入，完成处理业务逻辑后，负责将结果写出channel。可用资源池来管理。 One Loop Per Thread # 参考文献 # https://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf https://gee.cs.oswego.edu/dl/cpjslides/nio.pdf "},{"id":19,"href":"/docs/system-programming/sockets/","title":"套接字（socket）","section":"Linux 网络编程","content":" 套接字（socket） # 网络编程即编写程序使两台联网的计算机相互交换数据。计算机之间会通过网线、路由器和交换机等设备连接在一起，我们无需直接操控硬件，而使用操作系统提供的套接字（socket）。\n基本函数 # socket # 为了使用套接字，可以使用 socket 函数，创建用于通信的端点（endpoint）。\n#include \u0026lt;sys/socket.h\u0026gt; int socket(int domain, int type, int protocol); 成功时会返回文件描述符，失败时会返回 -1。\nhttps://man7.org/linux/man-pages/man2/socket.2.html\nbind # 当使用 socket 函数创建套接字后，会存在于名称空间（地址族）中，但没有为其分配地址。bind 函数将 addr 指定的地址分配给文件描述符 sockfd 引用的套接字。\n服务器可以不先调用 bind() 而直接调用 listen()，此时会为该 socket 分配一个 INADDR_ANY IP 地址（0.0.0.0）和临时端口（可通过 getsockname() 获取 socket 的地址）。\n#include \u0026lt;sys/socket.h\u0026gt; int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 成功时返回 0，失败时返回 -1。\nhttps://man7.org/linux/man-pages/man2/bind.2.html\nlisten # listen 函数将文件描述符引用的 socket 标记为被动，该 socket 会被用来接受来自其它主动 socket 的连接。\n#include \u0026lt;sys/socket.h\u0026gt; int listen(int sockfd, int backlog); 成功时返回 0，失败时返回 -1。\nhttps://man7.org/linux/man-pages/man2/listen.2.html\naccept # 执行 accept 函数会创建一个新的 socket，此 socket 会与执行 connect 函数的 socket 进行连接。此函数调用返回值是已连接的 socket 的文件描述符。\n#include \u0026lt;sys/socket.h\u0026gt; int accept(int sockfd, struct sockaddr *_Nullable restrict addr, socklen_t *_Nullable restrict addrlen); 成功时会返回文件描述符，失败时会返回 -1。\nhttps://man7.org/linux/man-pages/man2/accept.2.html\nconnect # connect 函数将文件描述符 sockfd 引用的套接字连接到由 addr 指定的地址。\n#include \u0026lt;sys/socket.h\u0026gt; int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); https://man7.org/linux/man-pages/man2/connect.2.html\n套接字协议 # socket 函数（int socket(int domain, int type, int protocol)）有三个参数用于选择传输协议和方式。\n协议族（domain） # 所有的协议族可以点击 address_families 查看，主要的协议族分类如下：\n协议族 描述 AF_INET 使用 IPv4 地址 AF_INET6 使用 IPv6 地址 AF_UNIX 本地通信，用于同一台机器上的进程间通信 AF_PACKET 原始数据包捕获和注入，需要特殊权限 AF_NETLINK 用于 Linux 内核与用户空间进程之间的通信 AF_常量 和 PF_常量 的区别？\nAF 表示地址族（address family），PF 表示协议族（protocol family）。在一开始的时候，设计人员相信单个协议族可以支持多个地址族。但在实践中，没有哪一个协议族能够支持多个已经被定义的地址族，并且所有既有实现都将 PF_常量 定义成对应的 AF_常量 的同义词。\n数据传输方式（type） # 数据传输类型主要有以下两种：\n面向连接的套接字（SOCK_STREAM）：提供有序的、可靠的、双向的、基于连接的字节流。可以支持带外（ out-of-band）数据传输机制。 面向消息的套接字（SOCK_DGRAM）：支持数据报（无连接、最大长度固定的不可靠消息）。 协议（protocol） # 在给定的协议族中，通常只有一个协议存在以支持特定的套接字类型，在这种情况下，可以将 protocol 指定为 0。\n在大部分情况下，第三个参数传递 0 即可。然而，协议族下可能存在许多协议，在这种情况下，必须使用 protocol 指定一个特定的协议。\n"},{"id":20,"href":"/docs/system-programming/echo-server/","title":"echo 服务器","section":"Linux 网络编程","content":" echo 服务器 # 辅助函数 # panic 函数用于错误处理，当发生错误时，调用 exit 函数直接退出程序。\nvoid panic(const char *format, ...) { va_list args; va_start(args, format); vfprintf(stderr, format, args); va_end(args); exit(EXIT_FAILURE); } readn 和 writen 函数分别用于从 fd 处读和写 n 个字节。\nssize_t readn(int fd, const void *buf, size_t n) { ssize_t nread; while (nleft \u0026gt; 0) { if ((nread = read(fd, buf, nleft)) \u0026lt; 0) { if (nleft == n) { return -1; // error, return -1 } else { break; // error, return amount read so far } while (nleft \u0026gt; 0) { if ((nread = read(fd, buf, nleft)) \u0026lt; 0) { if (nleft == n) { return -1; // error, return -1 } else { } nleft -= nread; buf += nread; } return n - nleft; } ssize_t writen(int fd, const void *buf, size_t n) { size_t nleft = n; ssize_t nwritten; while (nleft \u0026gt; 0) { if ((nwritten = write(fd, buf, nleft)) \u0026lt; 0) { if (nleft == n) { return -1; } else { break; } } else if (nwritten == 0) { break; } nleft -= nwritten; buf += nwritten; } return n - nleft; } read_line 函数用于从用户处读取一行输入。\nchar *read_line() { char *line = NULL; size_t buf_size = 0; ssize_t n_bytes = getline(\u0026amp;line, \u0026amp;buf_size, stdin); if (n_bytes == -1) { fprintf(stderr, \u0026#34;error: reading input\\n\u0026#34;); } if (line[n_bytes - 1] == \u0026#39;\\n\u0026#39;) { line[n_bytes - 1] = \u0026#39;\\0\u0026#39;; } return line; } set_nonblocking 函数用于将 fd 设为非阻塞模式。\nint set_nonblocking(int fd) { int flags = fcntl(fd, F_GETFL, 0); if (flags == -1 || fcntl(fd, F_SETFL, flags | O_NONBLOCK) == -1) { return -1; } return 0; } create_sockaddr_in 函数用于创建 struct sockaddr_in 结构体。\nstruct sockaddr_in *create_sockaddr_in(const char *address, int port) { struct sockaddr_in *addr = malloc(sizeof(struct sockaddr_in)); addr-\u0026gt;sin_family = AF_INET; addr-\u0026gt;sin_addr.s_addr = inet_addr(address); addr-\u0026gt;sin_port = htons(port); return addr; } 对于 socket、bind、listen、accept 和 connect 函数，大部分使用都是一样的，对其进行封装。\nint Socket() { int fd = socket(AF_INET, SOCK_STREAM, 0); if (fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } return fd; } void Bind(int socket_fd, struct sockaddr_in *addr) { int ret = bind(socket_fd, (struct sockaddr *)(addr), sizeof(*addr)); if (ret == -1) { panic(\u0026#34;bind() error: %s\\n\u0026#34;, strerror(errno)); } } void Listen(int socket_fd) { int ret = listen(socket_fd, 16); if (ret == -1) { panic(\u0026#34;listen() error: %s\\n\u0026#34;, strerror(errno)); } } int Accept(int socket_fd, struct sockaddr_in *addr, socklen_t *addr_len) { int fd = accept(socket_fd, (struct sockaddr *)addr, addr_len); if (fd == -1) { panic(\u0026#34;accept() error: %s\\n\u0026#34;, strerror(errno)); } int ret = set_nonblocking(fd); if (ret == -1) { panic(\u0026#34;set_nonblocking error\\n\u0026#34;); } return fd; } void Connect(int socket_fd, struct sockaddr_in *addr) { int ret = connect(socket_fd, (struct sockaddr *)(addr), sizeof(*addr)); if (ret == -1) { panic(\u0026#34;connect() error: %s\\n\u0026#34;, strerror(errno)); } } 客户端 # 客户端读取一行用户的输入，将数据传给服务器，服务器将所有的字母大写后再传给客户端。\nvoid run_client(const char *remote_address, int remote_port) { int client_fd = Socket(); struct sockaddr_in *server_addr = create_sockaddr_in(remote_address, remote_port); Connect(client_fd, server_addr); for (;;) { char *input = read_line(); size_t input_len = strlen(input); char buf[input_len + 1]; if (input_len == 0) { goto out; } ssize_t sent_bytes = send(client_fd, input, input_len, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } ssize_t recv_bytes = recv(client_fd, buf, input_len, 0); if (recv_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } printf(\u0026#34;%s\\n\u0026#34;, buf); out: free(input); } } 为什么多路复用需要搭配非阻塞 # On Linux, select() may report a socket file descriptor as \u0026#34;ready for reading\u0026#34;, while nevertheless a subsequent read blocks. This could for example happen when data has arrived but upon examination has the wrong checksum and is discarded. There may be other circumstances in which a file descriptor is spuriously reported as ready. Thus it may be safer to use O_NONBLOCK on sockets that should not block. 参考链接： select\n普通版本 # #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; int used_for_cleanup_fd = -1; void panic(const char *format, ...) { va_list args; va_start(args, format); vfprintf(stderr, format, args); va_end(args); exit(EXIT_FAILURE); } void cleanup() { if (used_for_cleanup_fd != -1) close(used_for_cleanup_fd); } void run_client(const char *remote_address, int remote_port) { int ret; char buf[512]; int client_fd = socket(AF_INET, SOCK_STREAM, 0); if (client_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = client_fd; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(remote_address); server_addr.sin_port = htons(remote_port); ret = connect(client_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;connect() error: %s\\n\u0026#34;, strerror(errno)); } for (;;) { fgets(buf, sizeof(buf), stdin); buf[strcspn(buf, \u0026#34;\\n\u0026#34;)] = \u0026#39;\\0\u0026#39;; size_t buf_len = strlen(buf); if (buf_len == 0) { continue; } if (buf_len \u0026gt;= sizeof(buf) - 1) { panic(\u0026#34;input too long\\n\u0026#34;); } ssize_t sent_bytes = send(client_fd, buf, buf_len, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } ssize_t recv_bytes = recv(client_fd, buf, sizeof(buf), 0); if (recv_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } printf(\u0026#34;%s\\n\u0026#34;, buf); } } void run_server(const char *address, int port) { int ret; char buf[512]; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(address); server_addr.sin_port = htons(port); int server_fd = socket(AF_INET, SOCK_STREAM, 0); if (server_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = server_fd; ret = bind(server_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;bind() error: %s\\n\u0026#34;, strerror(errno)); } ret = listen(server_fd, 16); if (ret == -1) { panic(\u0026#34;listen() error: %s\\n\u0026#34;, strerror(errno)); } struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); for (;;) { int client_fd = accept(server_fd, (struct sockaddr *)(\u0026amp;client_addr), \u0026amp;client_addr_len); if (client_fd == -1) { panic(\u0026#34;accept() error: %s\\n\u0026#34;, strerror(errno)); } for (;;) { ssize_t read_bytes = recv(client_fd, buf, sizeof(buf), 0); if (read_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } if (read_bytes == 0) { close(client_fd); break; } for (ssize_t i = 0; i \u0026lt; read_bytes; i++) { buf[i] = (char)toupper((unsigned char)buf[i]); } ssize_t sent_bytes = send(client_fd, buf, read_bytes, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } } } } int main(int argc, char *argv[]) { if (argc \u0026lt; 4) { panic(\u0026#34;usage: \u0026lt;mode\u0026gt; \u0026lt;IP\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); } char *mode = argv[1]; char *address = argv[2]; int port = atoi(argv[3]); if (strncmp(mode, \u0026#34;client\u0026#34;, 6) == 0) run_client(address, port); if (strncmp(mode, \u0026#34;server\u0026#34;, 6) == 0) run_server(address, port); return 0; } select 版本 # #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;sys/select.h\u0026gt; #define MAX(a, b) a \u0026lt; b ? b : a int used_for_cleanup_fd = -1; void panic(const char *format, ...) { va_list args; va_start(args, format); vfprintf(stderr, format, args); va_end(args); exit(EXIT_FAILURE); } void cleanup() { if (used_for_cleanup_fd != -1) close(used_for_cleanup_fd); } void run_client(const char *remote_address, int remote_port) { int ret; char buf[512]; int client_fd = socket(AF_INET, SOCK_STREAM, 0); if (client_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = client_fd; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(remote_address); server_addr.sin_port = htons(remote_port); ret = connect(client_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;connect() error: %s\\n\u0026#34;, strerror(errno)); } for (;;) { fgets(buf, sizeof(buf), stdin); buf[strcspn(buf, \u0026#34;\\n\u0026#34;)] = \u0026#39;\\0\u0026#39;; size_t buf_len = strlen(buf); if (buf_len == 0) { continue; } if (buf_len \u0026gt;= sizeof(buf) - 1) { panic(\u0026#34;input too long\\n\u0026#34;); } ssize_t sent_bytes = send(client_fd, buf, buf_len, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } ssize_t recv_bytes = recv(client_fd, buf, sizeof(buf), 0); if (recv_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } printf(\u0026#34;%s\\n\u0026#34;, buf); } } void run_server(const char *address, int port) { int ret; char buf[512]; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(address); server_addr.sin_port = htons(port); int server_fd = socket(AF_INET, SOCK_STREAM, 0); if (server_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = server_fd; ret = bind(server_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;bind() error: %s\\n\u0026#34;, strerror(errno)); } ret = listen(server_fd, 16); if (ret == -1) { panic(\u0026#34;listen() error: %s\\n\u0026#34;, strerror(errno)); } struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); fd_set fds; FD_ZERO(\u0026amp;fds); FD_SET(server_fd, \u0026amp;fds); int max_fd = server_fd; for (;;) { fd_set rfds = fds; int retval = select(max_fd + 1, \u0026amp;rfds, NULL, NULL, NULL); if (retval == -1) { panic(\u0026#34;select() error: %s\\n\u0026#34;, strerror(errno)); } if (FD_ISSET(server_fd, \u0026amp;rfds)) { // new connection int client_fd = accept(server_fd, (struct sockaddr *)(\u0026amp;client_addr), \u0026amp;client_addr_len); if (client_fd == -1) { panic(\u0026#34;accept() error: %s\\n\u0026#34;, strerror(errno)); } FD_SET(client_fd, \u0026amp;fds); max_fd = MAX(max_fd, client_fd); if (retval == 1) continue; } for (int fd = server_fd + 1; fd \u0026lt;= max_fd; fd++) { if (FD_ISSET(fd, \u0026amp;rfds)) { ssize_t read_bytes = recv(fd, buf, sizeof(buf), 0); if (read_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } if (read_bytes == 0) { FD_CLR(fd, \u0026amp;fds); close(fd); break; } for (ssize_t i = 0; i \u0026lt; read_bytes; i++) { buf[i] = (char)toupper((unsigned char)buf[i]); } ssize_t sent_bytes = send(fd, buf, read_bytes, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } } } } } int main(int argc, char *argv[]) { if (argc \u0026lt; 4) { panic(\u0026#34;usage: \u0026lt;mode\u0026gt; \u0026lt;IP\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); } char *mode = argv[1]; char *address = argv[2]; int port = atoi(argv[3]); if (strncmp(mode, \u0026#34;client\u0026#34;, 6) == 0) run_client(address, port); if (strncmp(mode, \u0026#34;server\u0026#34;, 6) == 0) run_server(address, port); return 0; } "},{"id":21,"href":"/docs/Java/Agent/","title":"Agent","section":"Java","content":" https://www.cnblogs.com/crazymakercircle/p/16635330.html\nhttps://docs.oracle.com/javase/8/docs/platform/jvmti/jvmti.html#whatIs\n"},{"id":22,"href":"/docs/JVM/AsmTools/","title":"AsmTools","section":"JVM","content":" AsmTools # AsmTools 官网： AsmTools\n编译 AsmTools # GitHub: AsmTools\nHow To Build AsmTools\n使用 # java -jar asmtools.jar jdis [option] [filename.class]\n参数 -g 可打印出更详细的信息。 "},{"id":23,"href":"/docs/Java/Cleaner/","title":"Cleaner 类","section":"Java","content":" 参考文献 # https://openjdk.org/jeps/421 https://inside.java/2022/05/25/clean-cleaner/ https://docs.oracle.com/javase/9/docs/api/java/lang/ref/Cleaner.html "},{"id":24,"href":"/docs/Java/JDBC/","title":"JDBC","section":"Java","content":" JDBC # 本教程使用 MySQL 数据库。\n主要参考：https://docs.oracle.com/javase/tutorial/jdbc/basics/index.html\n建立连接 # 数据源可以是数据库管理系统 (DBMS)、传统文件系统或其他带有相应 JDBC 驱动的数据源。通常，JDBC 使用以下两种类之一来连接目标数据源：\nDriverManager：用于将应用程序连接到通过数据库 URL 指定的数据源。当此类首次尝试建立连接时，它会自动加载类路径中找到的任何 JDBC 4.0 驱动程序。必须手动加载任何 4.0 版本之前的 JDBC 驱动程序。 DataSource：相比于 DriverManager，更推荐使用此接口，因为它允许应用程序对底层数据源的细节保持透明。DataSource 对象的属性被设置为表示特定的数据源。 使用 DriverManager 类 # String url = \u0026#34;jdbc:mysql://localhost:3306/db\u0026#34;; String username = \u0026#34;root\u0026#34;, password = \u0026#34;0987654321\u0026#34;; Connection conn = DriverManager.getConnection(url, username, password); 使用 JDBC 处理 SQL 语句 # 新建一个 user 表，如下图所示：\n使用 conn 对象创建 Statement，使用 stmt 执行 SQL 语句。\nResultSet 保存了执行 SQL 语句的结果，可以遍历保存的结果。\nString query = \u0026#34;SELECT * FROM `user`;\u0026#34;; try (Statement stmt = conn.createStatement()) { ResultSet rs = stmt.executeQuery(query); while (rs.next()) { int id = rs.getInt(1); String name = rs.getString(2); int age = rs.getInt(3); String email = rs.getString(4); System.out.printf(\u0026#34;id: %d, name: %s, age: %d, email: %s.\\n\u0026#34;, id, name, age, email); } } 使用 PreparedStatements # 如果需要多次执行一个 Statement 对象，使用 PreparedStatement 对象可以减少执行时间。\nPreparedStatement 对象的主要特点是，与 Statement 对象不同，它在创建时就指定了一个SQL语句。这样做的优势在于，在大多数情况下，这个 SQL 语句会立即发送到 DBMS（数据库管理系统），并在那儿编译。\n因此，PreparedStatement 对象不仅包含一个 SQL 语句，还包含一个已经预编译的 SQL 语句。这意味着，当执行 PreparedStatement 时，DBMS 可以直接运行预编译的 SQL 语句，而无需先编译它。\n可以将 PreparedStatement 对象用于没有参数的 SQL 语句，但更可能用于处理带参数的 SQL 语句。使用带参数的 SQL 语句的优势在于，可以使用相同的语句并在每次执行时为其提供不同的值。\n然而，PreparedStatement 最重要的优势是，它有助于防止 SQL 注入攻击。PreparedStatement 始终将客户端提供的数据视为参数的内容，而不是 SQL 语句的一部分。\nString query = \u0026#34;INSERT INTO `user` (name, age, email) VALUES (?, ?, ?)\u0026#34;; try (PreparedStatement ps = conn.prepareStatement(query)) { ps.setString(1, \u0026#34;Ile\u0026#34;); ps.setInt(2, 20); ps.setString(3, \u0026#34;ile@baomidou.com\u0026#34;); ps.executeUpdate(); } 事务处理 # 使用之前，需要通过 conn.setAutoCommit(false); 关闭事务自动提交。\n使用 commit() 提交事务，rollback() 回滚事务。\nString url = \u0026#34;jdbc:mysql://localhost:3306/db\u0026#34;; String username = \u0026#34;root\u0026#34;, password = \u0026#34;0987654321\u0026#34;; Connection conn = DriverManager.getConnection(url, username, password); conn.setAutoCommit(false); String query = \u0026#34;INSERT INTO `user` (name, age, email) VALUES (?, ?, ?)\u0026#34;; try (PreparedStatement ps = conn.prepareStatement(query)) { ps.setString(1, \u0026#34;Ile\u0026#34;); ps.setInt(2, 20); ps.setString(3, \u0026#34;ile@baomidou.com\u0026#34;); ps.executeUpdate(); conn.commit(); } catch (SQLException e) { conn.rollback(); } "},{"id":25,"href":"/docs/JVM/loading-linking-initializing/","title":"JVM 加载-链接-初始化","section":"JVM","content":" JVM 加载-链接-初始化 # 类加载过程 # 加载（loads） # 加载（loads）是查找具有特定名称的类或接口类型的二进制表示，并从该二进制表示创建类或接口的过程。加载过程如下：\n通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区（Method Area）的运行时数据结构。 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口。 类加载链接的目的就是在 JVM 中创建相应的类结构\n启动类加载器之外，其他的类加载器都是 java.lang.ClassLoader 的子类\n-verbose:class 参数可用于打印类加载的先后顺序\n链接（links） # 链接（links）是获取类或接口，并将其组合到 Java 虚拟机的运行时状态以便执行的过程。\n初始化（initializes） # 类或接口的初始化（initializes）包括执行类或接口初始化方法 \u0026lt;clinit\u0026gt;。\n类加载器（class loader） # 启动类加载器（bootstrap class loader）由 C++ 实现，\n除了启动类加载器之外，其它的类加载器都是 java.lang.ClassLoader 的子类，因此有对应的 Java 对象。这些类加载器需要先由另一个类加载器，比如说启动类加载器，加载至 Java 虚拟机中，方能执行类加载。\n双亲委派模型 # JDK 9 前 # 启动类加载器（Bootstrap Class Loader）：用于加载 扩展类加载器（Extension Class Loader）: 应用程序类加载器（Application Class Loader）: 可输出 BootstrapClassLoader 可加载的类。\nURLClassPath bootstrapClassPath = Launcher.getBootstrapClassPath(); for (URL url : bootstrapClassPath.getURLs()) { System.out.println(url.getFile()); } ${JAVA_HOME}/lib/resources.jar ${JAVA_HOME}/lib/rt.jar ${JAVA_HOME}/lib/sunrsasign.jar ${JAVA_HOME}/lib/jsse.jar ${JAVA_HOME}/lib/jce.jar ${JAVA_HOME}/lib/charsets.jar ${JAVA_HOME}/lib/jfr.jar ${JAVA_HOME}/classes JDK 9 后 # "},{"id":26,"href":"/docs/Java/MethodHandles/","title":"MethodHandles","section":"Java","content":" MethodHandles # 翻译自： https://dev.java/learn/introduction_to_method_handles/\n什么是方法句柄（What are method handles） # 方法句柄是一种用于方法查找和调用的低级机制。与反射相比，反射和方法句柄都提供了调用方法、调用构造函数以及访问字段的手段。\n那么，方法句柄究竟什么是呢？它是对底层方法、构造函数或字段的可调用引用。方法句柄允许在一个简单的指向方法的指针之上进行一系列操作，这些操作包括插入或重新排列参数、转换返回值等。\n让我们深入探讨一下方法句柄能够提供什么功能以及我们如何有效地使用它们。\n访问检查（Access checking） # 方法句柄调用的访问检查与反射的执行方式是不同的。使用反射时，每次调用都会对调用者进行访问检查。而对于方法句柄，访问检查只在方法句柄创建时进行。\n需要注意的是，如果在能够访问非公共成员的上下文中创建了方法句柄，那么当该方法句柄被传递到外部时，它仍然可以访问这些非公共成员。\n因此，非公共成员可能会从不应有访问权限的代码中被访问。开发者有责任将此类方法句柄限制在其创建的上下文内。或者，可以使用适当的查找对象在创建方法句柄时立即设置访问限制。\n方法句柄查找（Method handle lookup） # 要创建方法句柄，我们首先需要创建一个 LookUp 对象，此为创建方法句柄的工厂。根据 Lookup 对象本身或方法句柄的使用方式，我们可以决定是否需要限制其访问级别。\n例如，如果我们创建了一个指向私有方法的方法句柄，并且该方法句柄可以从外部访问，那么该私有方法也就可以被外部访问（译者注：现在，外部代码可以直接调用原本受保护的私有方法，从而破坏了方法的私有性）。通常我们希望避免这种情况。一个办法是将 Lookup 对象和方法句柄也设为私有。另一种方法是使用 MethodHandles.publicLookup 方法创建 Lookup 对象，这样它只能查找在无条件导出的包中公共类的公共成员（译者注：未导出的包，或受保护或私有的类和成员不会被搜索到）：\nMethodHandles.Lookup publicLookup = MethodHandles.publicLookup(); 如果我们打算将 Lookup 对象和方法句柄设为私有，那么允许它们访问任何成员，包括私有和受保护的成员，是安全的：\nMethodHandles.Lookup lookup = MethodHandles.lookup(); 方法类型（Method type） # 要查找方法句柄，我们还需要提供方法或字段的类型信息。方法的类型信息被表示为 MethodType 类。为了实例化一个 MethodType 对象，需要提供函数返回类型作为第一个形参，后跟函数所有实参类型:\nMethodType methodType = MethodType.methodType(int.class /* the method returns integer */, String.class /* and accepts a single String argument*/); 有了 Lookup 和 MethodType 实例后，我们就可以查找方法句柄了。对于实例方法，我们应该使用 Lookup.findVirtual，对于静态方法，我们应该使用 Lookup.findStatic。这两种方法都接受以下参数：方法所在的 Class，表示方法名称的 String，以及一个 MethodType 实例。\n在下面的示例中，我们使用 Lookup.findVirtual 方法查找一个实例方法 String.replace，该方法接受两个 char 参数并返回一个 String：\nMethodHandles.Lookup lookup = MethodHandles.lookup(); MethodType replaceMethodType = MethodType.methodType(String.class, char.class, char.class); MethodHandle replaceMethodHandle = lookup.findVirtual(String.class, \u0026#34;replace\u0026#34;, replaceMethodType); 在下一个示例中，我们使用 Lookup.findStatic 来查找一个静态方法 String.valueOf，该方法接受一个 Object 参数并返回一个 String：\nMethodType valueOfMethodType = MethodType.methodType(String.class, Object.class); MethodHandle valueOfMethodHandle = lookup.findStatic(String.class, \u0026#34;valueOf\u0026#34;, valueOfMethodType); 类似地，我们可以使用 Lookup.findConstructor 方法来查找指向任何构造函数的方法句柄。\n最后，当我们获得了一个方法句柄时，我们可以用此调用底层的方法。\n调用方法句柄（Method handle invocation） # 调用还可以以其它方式进行。\n所有调用的方法最终都会汇集到一个方法上： MethodHandle.invokeExact。正如方法名称所示，提供给 invokeExact 方法的参数必须严格匹配方法句柄的类型。\n例如，如果我们调用 String.replace 方法，参数必须严格对应于：返回类型为 String 和两个 char 参数：\nMethodType replaceMethodType = MethodType.methodType(String.class, char.class, char.class); MethodHandle replaceMethodHandle = lookup.findVirtual(String.class, \u0026#34;replace\u0026#34;, replaceMethodType); String result = (String) replaceMethodHandle.invokeExact(\u0026#34;dummy\u0026#34;, \u0026#39;d\u0026#39;, \u0026#39;m\u0026#39;); MethodHandle.invoke 更为宽松。它尝试获取一个具有调整类型的新方法句柄，使其严格匹配提供的参数的类型。然后，可以使用 invokeExact 调用已调整的方法句柄。\nString result = (String) replaceMethodHandle.invoke((Object)\u0026#34;dummy\u0026#34;, (Object)\u0026#39;d\u0026#39;, (Object)\u0026#39;m\u0026#39;); // would fail with `invokeExact` 另一种调用方法句柄的替代方法是使用 MethodHandle.invokeWithArguments。这种方法调用的结果等同于 invoke，区别在于此方法允许你将所有参数打包成一个 Object 类型的数组或 List，然后传递给方法。。\n该方法的一个有趣特性是，如果提供的参数数量超过了实际的数量，所有多出的参数将被压缩到最后一个参数中，并将其视为一个数组。\n访问属性（Accessing fields） # 这段代码示例演示了如何创建对字段的读取或写入访问权限的方法句柄。对于实例字段（Instance Fields），可以使用 findGetter 和 findSetter 方法，对于静态字段（Static Fields），可以使用 findStaticGetter 和 findStaticSetter 方法。在这种情况下，不需要提供 MethodType 实例；相反，应提供一个单一类型，即字段的类型。\n静态字段 # 例如，假设我们在 Example 类中有一个静态字段 magic：\nprivate static String magic = \u0026#34;initial value static field\u0026#34;; 假设我们已经创建了一个 Lookup 对象：\nMethodHandles.Lookup lookup = MethodHandles.lookup(); 我们可以简单地创建 setter 和 getter 方法句柄，并分别调用它们：\nMethodHandle setterStaticMethodHandle = lookup.findStaticSetter(Example.class, \u0026#34;magic\u0026#34;, String.class); MethodHandle getterStaticMethodHandle = lookup.findStaticGetter(Example.class, \u0026#34;magic\u0026#34;, String.class); setterStaticMethodHandle.invoke(\u0026#34;new value static field\u0026#34;); String staticFieldResult = (String) getterStaticMethodHandle.invoke(); // staticFieldResult == `new value static field` 实例字段 # 在 Example 类中有一个名为 abc 的实例字段：\nprivate String abc = \u0026#34;initial value\u0026#34;; 我们可以类似地为读取和写入实例字段创建方法句柄：\nMethodHandle setterMethodHandle = lookup.findSetter(Example.class, \u0026#34;abc\u0026#34;, String.class); MethodHandle getterMethodHandle = lookup.findGetter(Example.class, \u0026#34;abc\u0026#34;, String.class); 要使用实例字段的 setter 和 getter 方法句柄，必须获取字段所属类的实例：\nExample example = new Example(); 然后，为我们的 setter 和 getter 的调用提供 Example 的实例：\nsetterMethodHandle.invoke(example, \u0026#34;new value\u0026#34;); String result = (String) getterMethodHandle.invoke(example); // result == `new value` 虽然可以使用方法句柄读取和写入字段值，但这并不常见。对于字段，更适合使用 VarHandle，可以使用 findVarHandle 和 findStaticVarHandle 方法创建。\n使用数组（Working with arrays） # MethodHandles 类包含一些提供预设方法句柄的方法。其中包括允许数组操作的方法句柄。创建这些方法句柄不需要访问检查，因此不需要查找对象。\n我们使用 arrayConstructor 创建一个包含 5 个元素的 String 数组：\nMethodHandle arrayConstructor = MethodHandles.arrayConstructor(String[].class); String[] arr = (String[]) arrayConstructor.invoke(5); 要修改单个元素，我们可以使用 arrayElementSetter，需要提供目标数组、元素的索引和新值：\nMethodHandle elementSetter = MethodHandles.arrayElementSetter(String[].class); elementSetter.invoke(arr, 4, \u0026#34;test\u0026#34;); 要读取单个元素的值，我们应该使用 arrayElementGetter 方法句柄，需要提供目标数组和元素索引：\nMethodHandle elementGetter = MethodHandles.arrayElementGetter(String[].class); String element = (String) elementGetter.invoke(arr, 4); // element == \u0026#34;test\u0026#34; 还可以使用 arrayLength 提供的方法句柄获取数组的长度：\nMethodHandle arrayLength = MethodHandles.arrayLength(String[].class); int length = (int) arrayLength.invoke(arr); // length == 5 异常处理（Exception handling） # invokeExact 和 invoke 都会抛出 Throwable，因此对底层方法可以抛出的异常没有限制。调用方法句柄的方法必须明确抛出 Throwable 或捕获它。\nMethodHandles 中有一些方法可以使异常处理变得更加简单。让我们看几个示例。\ncatch wrapper # MethodHandles.catchException 方法可以将给定的方法句柄包装在提供的异常处理方法句柄中。\n假设我们有一个执行某些业务逻辑的方法 problematicMethod，以及一个处理 IllegalArgumentException 异常的方法 exceptionHandler。异常处理程序方法必须返回与原始方法相同的类型。接受的第一个参数是我们感兴趣的 Throwable，第二个参数是我们最初接受的其余参数：\npublic static int problematicMethod(String argument) throws IllegalArgumentException { if (\u0026#34;invalid\u0026#34;.equals(argument)) { throw new IllegalArgumentException(); } return 1; } public static int exceptionHandler(IllegalArgumentException e, String argument) { // log exception return 0; } 我们可以查找这两个方法的方法句柄，并将 problematicMethod 包装在 exceptionHandler 内。MethodHandle 在调用时正确处理 IllegalArgumentException，如果出现其他异常，则会继续抛出。\nMethodHandles.Lookup lookup = MethodHandles.lookup(); MethodHandle methodHandle = lookup.findStatic(Example.class, \u0026#34;problematicMethod\u0026#34;, MethodType.methodType(int.class, String.class)); MethodHandle handler = lookup.findStatic(Example.class, \u0026#34;exceptionHandler\u0026#34;, MethodType.methodType(int.class, IllegalArgumentException.class, String.class)); MethodHandle wrapped = MethodHandles.catchException(methodHandle, IllegalArgumentException.class, handler); System.out.println(wrapped.invoke(\u0026#34;valid\u0026#34;)); // outputs \u0026#34;1\u0026#34; System.out.println(wrapped.invoke(\u0026#34;invalid\u0026#34;)); // outputs \u0026#34;0\u0026#34; finally wrapper # MethodHandles.tryFinally 方法的工作方式与上边类似，但它不是一个异常处理程序，而是在目标方法周围添加了一个 try-finally 块。\n假设我们有一个包含清理逻辑的方法 cleanupMethod。该方法的返回类型必须与目标方法的返回类型相同。它必须接受一个 Throwable，然后是来自目标方法的结果值，然后是所有参数。\npublic static int cleanupMethod(Throwable e, int result, String argument) { System.out.println(\u0026#34;inside finally block\u0026#34;); return result; } 我们可以将前面示例中的方法句柄包装在 try-finally 块中，如下所示：\nMethodHandle cleanupMethod = lookup.findStatic(Example.class, \u0026#34;cleanupMethod\u0026#34;, MethodType.methodType(int.class, Throwable.class, int.class, String.class)); MethodHandle wrappedWithFinally = MethodHandles.tryFinally(methodHandle, cleanupMethod); System.out.println(wrappedWithFinally.invoke(\u0026#34;valid\u0026#34;)); // outputs \u0026#34;inside finally block\u0026#34; and \u0026#34;1\u0026#34; System.out.println(wrappedWithFinally.invoke(\u0026#34;invalid\u0026#34;)); // outputs \u0026#34;inside finally block\u0026#34; and throws java.lang.IllegalArgumentException 方法句柄转换（Method handle transformations） # 正如前面的例子所示，方法句柄可以封装比简单指向底层方法更多的行为。我们可以获取适配器*方法句柄，包装目标方法句柄以添加某些行为，如参数重排序、预先插入或过滤返回值。\n让我们来看一些这样的转换。\n类型转换（Type transformation） # 方法句柄的类型可以使用 asType 方法适应为新类型。如果不可能转换为此类型，将收到 WrongMethodTypeException 异常。请记住，当我们使用转换时，我们实际上有两个方法句柄，其中原始方法句柄被包装到一些额外逻辑中。在这种情况下，包装器将接收参数并尝试将其转换以匹配原始方法句柄的参数。一旦原始方法句柄完成其工作并返回结果，包装器将尝试将此结果转换为给定类型。\n假设我们有一个 test 方法，接受一个 Object 并返回一个 String。我们可以将这样一个方法适应为接受更具体的参数类型，如 String：\nMethodHandle targetMethodHandle = lookup.findStatic(Example.class, \u0026#34;test\u0026#34;, MethodType.methodType(String.class, Object.class)); MethodHandle adapter = targetMethodHandle.asType( MethodType.methodType(String.class, String.class)); String originalResult = (String) targetMethodHandle.invoke(111); // works String adapterResult = (String) adapter.invoke(\u0026#34;aaaaaa\u0026#34;); // works adapterResult = (String) adapter.invoke(111); // fails 实际上，每次我们在 MethodHandle 上使用 invoke 时，首先是调用 asType 方法。invoke 接受并返回 Object，然后尝试将其转换为更具体的类型。这些具体类型是从我们的代码中派生的，即我们作为参数传递的确切值和我们将返回值转换为的类型。成功类型转换后，就会为这些具体类型调用 invokeExact 方法。\n重新排列参数（Permute arguments） # 要获取一个带有重新排列参数的适配器方法句柄，我们可以使用 MethodHandles.permuteArguments。\n例如，让我们创建一个接受不同类型参数的 test 方法：\npublic static void test(int v1, String v2, long v3, boolean v4) { System.out.println(v1 + v2 + v3 + v4); } 并查找一个指向它的方法句柄：\nMethodHandle targetMethodHandle = lookup.findStatic(Example.class, \u0026#34;test\u0026#34;, MethodType.methodType(void.class, int.class, String.class, long.class, boolean.class)); permuteArguments 方法接收：\n目标方法句柄，在我们的例子中指向 test 方法; 新的 MethodType，其中所有参数以所需方式重新排序; 一个指定参数新顺序的索引数组。 MethodHandle reversedArguments = MethodHandles.permuteArguments(targetMethodHandle, MethodType.methodType(void.class, boolean.class, long.class, String.class, int.class), 3, 2, 1, 0); reversedArguments.invoke(false, 1L, \u0026#34;str\u0026#34;, 123); // outputs: \u0026#34;123str1false\u0026#34; 插入参数 # MethodHandles.insertArguments 方法提供了一个带有一个或多个绑定参数的 MethodHandle。\n例如，让我们再次查看前面示例中的方法句柄：\nMethodHandle targetMethodHandle = lookup.findStatic(Example.class, \u0026#34;test\u0026#34;, MethodType.methodType(void.class, int.class, String.class, long.class, boolean.class)); 我们可以轻松地获取一个带有 String 和 long 参数预先绑定的适配器 MethodHandle：\nMethodHandle boundArguments = MethodHandles.insertArguments(targetMethodHandle, 1, \u0026#34;new\u0026#34;, 3L); 要调用生成的适配器方法句柄，我们只需要提供未预先填充的参数：\nboundArguments.invoke(1, true); // outputs: \u0026#34;1new3true\u0026#34; 如果我们尝试传递已经预填充的参数，我们将收到 WrongMethodTypeException 异常。\n过滤参数 # 我们可以使用 MethodHandles.filterArguments 来在调用目标方法句柄之前对参数应用转换。为了使其工作，我们必须提供：\n目标方法句柄； 要转换的第一个参数的位置； 用于每个参数转换的方法句柄。 如果某些参数不需要转换，我们可以通过传递 null 来跳过它们。如果我们只需要转换其中的一部分参数，也可以完全跳过其余参数。\n让我们重用上一节中的方法句柄，并在调用之前过滤其中的一些参数。\nMethodHandle targetMethodHandle = lookup.findStatic(Example.class, \u0026#34;test\u0026#34;, MethodType.methodType(void.class, int.class, String.class, long.class, boolean.class)); 然后我们创建一个方法，通过对其取反来转换任何布尔值：\nprivate static boolean negate(boolean original) { return !original; } 额外构造一个方法，通过增加给定的整数值来转换：\nprivate static int increment(int original) { return ++original; } 我们可以为这些转换方法获取方法句柄：\nMethodHandle negate = lookup.findStatic(Example.class, \u0026#34;negate\u0026#34;, MethodType.methodType(boolean.class, boolean.class)); MethodHandle increment = lookup.findStatic(Example.class, \u0026#34;increment\u0026#34;, MethodType.methodType(int.class, int.class)); 并使用它们来获得一个新的方法句柄，已经过滤了参数：\n// applies filter \u0026#39;increment\u0026#39; to argument at index 0, \u0026#39;negate\u0026#39; to the last argument, // and passes the result to \u0026#39;targetMethodHandle\u0026#39; MethodHandle withFilters = MethodHandles.filterArguments(targetMethodHandle, 0, increment, null, null, negate); withFilters.invoke(3, \u0026#34;abc\u0026#34;, 5L, false); // outputs \u0026#34;4abc5true\u0026#34; 折叠参数 # 当我们想要在调用 MethodHandle 之前对一个或多个参数进行预处理时，我们可以使用 MethodHandles.foldArguments，并提供一个组合方法的方法句柄，该方法将接受从任意首选位置开始的参数。\n假设我们有一个 target 方法：\nprivate static void target(int ignored, int sum, int a, int b) { System.out.printf(\u0026#34;%d + %d equals %d and %d is ignored%n\u0026#34;, a, b, sum, ignored); } 使用 foldArguments，我们可以预处理其参数的一个子集，并将结果值插入为另一个参数，然后继续执行 target 方法。\n在我们的示例中，我们有参数 int a，int b 在最后。我们可以预处理任意数量的参数，但它们都必须在最后。假设我们想要计算 a 和 b 这两个值的和，因此让我们创建一个用于此目的的方法：\nprivate static int sum(int a, int b) { return a + b; } 结果值将被插入到目标方法的一个参数中。它必须是我们将要折叠的参数之前的参数，所以在我们的示例中是参数 int sum。用于折叠结果的参数不能位于其他位置。如果目标方法需要接受与此折叠逻辑无关的更多参数，则它们必须全部放在最前面。\n让我们创建方法句柄并看看如何将它们组合在一起：\nMethodHandle targetMethodHandle = lookup.findStatic(Example.class, \u0026#34;target\u0026#34;, MethodType.methodType(void.class, int.class, int.class, int.class, int.class)); MethodHandle combinerMethodHandle = lookup.findStatic(Example.class, \u0026#34;sum\u0026#34;, MethodType.methodType(int.class, int.class, int.class)); MethodHandle preProcessedArguments = MethodHandles.foldArguments(targetMethodHandle, 1, combinerMethodHandle); foldArguments 方法接受：\nMethodHandle target: 目标方法句柄，在我们的例子中指向 target 方法的句柄。 int pos: 一个整数，指定与折叠相关的参数的起始位置。在我们的例子中，sum 参数位于位置1，因此我们传递了1。如果跳过此参数，pos 将默认为0。 MethodHandle combiner: 组合方法句柄，在我们的例子中指向 sum 方法的句柄。 最后，我们可以调用生成的方法句柄，并传递除 sum 之外的所有参数，sum 将被预先计算：\npreProcessedArguments.invokeExact(10000, 1, 2); // outputs: \u0026#34;1 + 2 equals 3 and 10000 is ignored\u0026#34; 有可能组合方法处理值但不返回任何内容。在这种情况下，目标方法参数列表中不需要结果占位符。\n过滤返回值 # 与参数类似，我们可以使用一个适配器来对返回值进行转换。\n假设我们有一个返回 String 的方法，并且我们想将该方法返回的任何值传递到另一个方法中，该方法将字符 d 替换为 m 并将结果值大写。\n这是 getSomeString 方法的方法句柄，它始终返回值 \u0026quot;dummy\u0026quot;:\nMethodHandle getSomeString = lookup.findStatic(Example.class, \u0026#34;getSomeString\u0026#34;, MethodType.methodType(String.class)); 这是执行转换的 resultTransform 方法：\nprivate static String resultTransform(String value) { return value.replace(\u0026#39;d\u0026#39;, \u0026#39;m\u0026#39;).toUpperCase(); } 这是我们转换方法的方法句柄：\nMethodHandle resultTransform = lookup.findStatic(Example.class, \u0026#34;resultTransform\u0026#34;, MethodType.methodType(String.class, String.class)); 最后，这是两个方法句柄的组合，其中由 getSomeString 方法返回的结果然后提供给 resultTransform 方法并相应地进行修改：\nMethodHandle getSomeUppercaseString = MethodHandles.filterReturnValue(getSomeString, resultTransform); System.out.println(getSomeUppercaseString.invoke()); // 输出: \u0026#34;MUMMY\u0026#34; 方法句柄与反射（Method Handles vs Reflection API） # 方法句柄是在 JDK7 中引入的，作为协助编译器和语言运行时开发人员的工具。它们从未旨在取代反射。\n反射 提供了一些方法句柄无法做到的功能，即列出类成员并检查它们的属性。另一方面，方法句柄可以以无法通过反射实现的方式进行转换和操作。\n当涉及方法调用时，与访问检查和安全性考虑有关的差异。反射API在每次调用时针对每个调用者执行访问检查，而对于方法句柄，仅在构建过程中进行访问检查。这使得通过方法句柄进行调用比通过反射更快。然而，必须采取某些预防措施，以确保方法句柄不被传递到不应访问的代码中。\n您可以在 本教程 中了解更多关于反射的信息。\n反射和方法句柄之间的转换（Conversion between Reflection API and method handles） # Lookup 对象可以用于将反射对象转换为行为上等效的方法句柄，从而提供对底层类成员更直接和高效的访问。\n要创建指向给定 Method 的方法句柄（假设查找类具有执行此操作的权限），可以使用 unreflect。\n假设我们在 Example 类中有一个接受 String 参数并返回 String 的测试方法。使用反射，我们可以获得一个 Method 对象：\nMethod method = Example.class.getMethod(\u0026#34;test\u0026#34;, String.class); 借助查找对象的帮助，我们可以 unreflect Method 对象以获取 MethodHandle：\nMethodHandles.Lookup lookup = MethodHandles.lookup(); MethodHandle methodHandle = lookup.unreflect(method); String result = (String) methodHandle.invoke(\u0026#34;something\u0026#34;); 类似地，给定一个 Field 对象，我们可以获得 getter 和 setter 方法句柄：\nField field = Example.class.getField(\u0026#34;magic\u0026#34;); MethodHandle setterMethodHandle = lookup.unreflectSetter(field); MethodHandle getterMethodHandle = lookup.unreflectGetter(field); setterMethodHandle.invoke(\u0026#34;something\u0026#34;); String result = (String) getterMethodHandle.invoke(); // result == \u0026#34;something\u0026#34; 还可以将 MethodHandle 转换为 Member，条件是没有对给定的 MethodHandle 执行任何转换。\n假设我们有一个直接指向方法的方法句柄。我们可以使用 MethodHandles.reflectAs 方法获取 Method 对象：\nMethod method = MethodHandles.reflectAs(Method.class, methodHandle); 对于 Field 对象也是类似的：\nField field = MethodHandles.reflectAs(Field.class, getterMethodHandle); // same result is achieved by reflecting `setterMethodHandle` 结论（Conclusion） # 在本教程中，我们深入了解了方法句柄机制，学会了如何高效地使用它。我们现在知道，方法句柄提供了一种高效的方法调用方式，但这种机制并不旨在取代反射。\n由于方法句柄采用不同的访问检查方法，方法句柄在方法调用方面具有性能优势。然而，由于访问仅在方法句柄创建时进行检查，因此应谨慎传递方法句柄。\n与反射API不同，方法句柄不提供列出类成员和检查其属性的工具。另一方面，方法句柄API允许我们将直接指向方法和字段的指针包装成更复杂的逻辑，如参数和返回值的操作。\n"},{"id":27,"href":"/docs/Java/DynamicProxy/","title":"动态代理","section":"Java","content":" 动态代理 # 在 Java 动态代理机制中，InvocationHandler 接口和 Proxy 类是核心。\nProxy # Proxy 类主要使用 newProxyInstance() 静态方法生成代理对象。\npublic static Object newProxyInstance(ClassLoader loader, Class\u0026lt;?\u0026gt;[] interfaces, InvocationHandler h) { ... } 该方法主要有三个参数：\nloader：定义代理类的类加载器。 interfaces：代理类要实现的接口列表。 h：用于分发方法调用的调用处理器。 InvocationHandler # 当动态代理对象调用一个方法时，此方法的调用就会被转发到实现 InvocationHandler 接口类的 invoke 方法来调用。\npublic interface InvocationHandler { public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; } 该方法主要有三个参数：\nproxy：动态生成的代理类的实例。 method：代理类对象调用的方法。 args：调用 method 方法的参数。 通过 Proxy 类的 newProxyInstance() 创建的代理对象在调用方法的时候，实际会调用到实现 InvocationHandler 接口的类的 invoke() 方法。\n具体步骤 # TargetClass 类继承自 InterfaceA 和 InterfaceB 接口。\n如果想在 targetA() 和 targetB() 方法调用前后进行一些额外操作。\ninterface InterfaceA { void targetA(); } interface InterfaceB { void targetB(); } class TargetClass implements InterfaceA, InterfaceB { @Override public void targetA() { System.out.println(\u0026#34;Target A\u0026#34;); } @Override public void targetB() { System.out.println(\u0026#34;Target B\u0026#34;); } } 在 InvocationHandler 中的 invoke 方法中定义额外的操作。\nclass SimpleInvocationHandler implements InvocationHandler { private final Object target; public SimpleInvocationHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.printf(\u0026#34;Before invocation method %s\\n\u0026#34;, method.getName()); Object result = method.invoke(target, args); System.out.printf(\u0026#34;After invocation method %s\\n\u0026#34;, method.getName()); return result; } } 通过 Proxy.newProxyInstance 方法生成代理对象。\npublic static void main(String[] args) { System.setProperty(\u0026#34;jdk.proxy.ProxyGenerator.saveGeneratedFiles\u0026#34;, \u0026#34;true\u0026#34;); TargetClass target = new TargetClass(); SimpleInvocationHandler handler = new SimpleInvocationHandler(target); Object o = Proxy.newProxyInstance( TargetClass.class.getClassLoader(), new Class[]{InterfaceA.class, InterfaceB.class}, handler ); ((InterfaceA) o).targetA(); ((InterfaceB) o).targetB(); } 原理 # 生成的类会继承自 Proxy 类，实现调用 newInstance() 方法时传入的 interfaces 中的所有接口。\n被代理的类中的所有方法会被收集为 Method 方法。当通过代理对象调用方法时，会转发到传入的 InvocationHandler 中。\n传入到 h.invoke 中的参数分别为：\nthis：被代理对象实例。 m*：调用的具体方法。 args：调用方法传入的参数。 // // Source code recreated from a .class file by IntelliJ IDEA // (powered by FernFlower decompiler) // import java.lang.invoke.MethodHandles; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; final class $Proxy0 extends Proxy implements InterfaceA, InterfaceB { private static final Method m0; private static final Method m1; private static final Method m2; private static final Method m3; private static final Method m4; public $Proxy0(InvocationHandler var1) { super(var1); } public final int hashCode() { try { return (Integer)super.h.invoke(this, m0, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final boolean equals(Object var1) { try { return (Boolean)super.h.invoke(this, m1, new Object[]{var1}); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetA() { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetB() { try { super.h.invoke(this, m4, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { ClassLoader var0 = $Proxy0.class.getClassLoader(); try { m0 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;hashCode\u0026#34;); m1 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;equals\u0026#34;, Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0)); m2 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;toString\u0026#34;); m3 = Class.forName(\u0026#34;io.github.ileonli.InterfaceA\u0026#34;, false, var0).getMethod(\u0026#34;targetA\u0026#34;); m4 = Class.forName(\u0026#34;io.github.ileonli.InterfaceB\u0026#34;, false, var0).getMethod(\u0026#34;targetB\u0026#34;); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } } private static MethodHandles.Lookup proxyClassLookup(MethodHandles.Lookup var0) throws IllegalAccessException { if (var0.lookupClass() == Proxy.class \u0026amp;\u0026amp; var0.hasFullPrivilegeAccess()) { return MethodHandles.lookup(); } else { throw new IllegalAccessException(var0.toString()); } } } 该代码主要依靠下边两个主要的方法和类：\njava.lang.reflect.Proxy.ProxyBuilder#defineProxyClass\njava.lang.reflect.ProxyGenerator\nProxy 的缺点 # JDK 动态代理有一个最致命的问题是其只能代理实现了接口的类。\n我们对代码进行一些修改，TargetClass 继承了 SuperClass 类。\ninterface InterfaceA { void targetA(); } interface InterfaceB { void targetB(); } abstract class SuperClass { abstract void superClassFunc(); } class TargetClass extends SuperClass implements InterfaceA, InterfaceB { @Override public void targetA() { System.out.println(\u0026#34;Target A\u0026#34;); } @Override public void targetB() { System.out.println(\u0026#34;Target B\u0026#34;); } @Override void superClassFunc() { System.out.println(\u0026#34;Super Class Func\u0026#34;); } } class SimpleInvocationHandler implements InvocationHandler { private final Object target; public SimpleInvocationHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.printf(\u0026#34;Before invocation method %s\\n\u0026#34;, method.getName()); Object result = method.invoke(target, args); System.out.printf(\u0026#34;After invocation method %s\\n\u0026#34;, method.getName()); return result; } } 反编译生成的代码后发现此类只包含实现的接口中的方法。\nimport java.lang.invoke.MethodHandles; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; final class $Proxy0 extends Proxy implements InterfaceA, InterfaceB { private static final Method m0; private static final Method m1; private static final Method m2; private static final Method m3; private static final Method m4; public $Proxy0(InvocationHandler var1) { super(var1); } public final int hashCode() { try { return (Integer)super.h.invoke(this, m0, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final boolean equals(Object var1) { try { return (Boolean)super.h.invoke(this, m1, new Object[]{var1}); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetA() { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetB() { try { super.h.invoke(this, m4, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { ClassLoader var0 = $Proxy0.class.getClassLoader(); try { m0 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;hashCode\u0026#34;); m1 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;equals\u0026#34;, Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0)); m2 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;toString\u0026#34;); m3 = Class.forName(\u0026#34;io.github.ileonli.InterfaceA\u0026#34;, false, var0).getMethod(\u0026#34;targetA\u0026#34;); m4 = Class.forName(\u0026#34;io.github.ileonli.InterfaceB\u0026#34;, false, var0).getMethod(\u0026#34;targetB\u0026#34;); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(((Throwable)var2).getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(((Throwable)var3).getMessage()); } } private static MethodHandles.Lookup proxyClassLookup(MethodHandles.Lookup var0) throws IllegalAccessException { if (var0.lookupClass() == Proxy.class \u0026amp;\u0026amp; var0.hasFullPrivilegeAccess()) { return MethodHandles.lookup(); } else { throw new IllegalAccessException(var0.toString()); } } } "},{"id":28,"href":"/docs/Netty/encoder-and-decoder/","title":"编码器和解码器","section":"Netty","content":" 编码器和解码器 # 编码器：将消息转换为适合于传输的格式（通常是字节流）。 解码器：将网络字节流转换为应用程序的消息格式。 因此，编码器处理出站数据，而解码器处理入站数据。\n解码器 # 由于解码器是负责处理入站数据的，因此，解码器是 ChannelInboundHandler。\n解码器主要有下边两种：\n将字节解码为消息的 ByteToMessageDecoder 和 ReplayingDecoder。 将一种消息类型解码为另一种消息的 MessageToMessageDecoder。 ByteToMessageDecoder # ReplayingDecoder # ReplayingDecoder 扩展了 ByteToMessageDecoder 类，使得我们不必调用 readableBytes() 方法。它通过使用一个自定义的 ByteBuf 实现， ReplayingDecoderByteBuf，包装传入的 ByteBuf 实现了这一点，其将在内部执行该调用\nMessageToMessageDecoder # 编码器 # 编解码器类 # 这些类同时实现了 ChannelInboundHandler 和 ChannelOutboundHandler 接口。\nByteToMessageCodec # MessageToMessageCodec # CombinedChannelDuplexHandler # CombinedChannelDuplexHandler 可将 ChannelInboundHandler 和 ChannelOutboundHandler 结合在一起。\n"}]