[{"id":0,"href":"/docs/boltdb/introduction/","title":"boltdb 介绍","section":"boltdb","content":" boltdb 介绍 # https://github.com/boltdb/bolt\nboltdb 是一个使用 Go 语言开发的 KV 存储库。该项目的目标是为那些不需要完整数据库服务器（如：Postgres或MySQL）的项目提供一个简单、快速且可靠的数据库。\nboltdb 目前已不再维护，CoreOS fork 了该项目，并继续维护 bbolt。\n打开数据库 # boltdb 中的顶层对象是 DB。它在磁盘上表示为一个单一文件，并且代表了数据的一个一致性快照。\n要打开数据库，只需使用 bolt.Open() 函数：\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;github.com/boltdb/bolt\u0026#34; ) func main() { // Open the my.db data file in your current directory. // It will be created if it doesn\u0026#39;t exist. db, err := bolt.Open(\u0026#34;my.db\u0026#34;, 0600, nil) if err != nil { log.Fatal(err) } defer db.Close() ... } 请注意，boltdb 会对数据文件加锁，因此多个进程不能同时打开同一个数据库。尝试打开一个已经被打开的 boltdb 数据库将导致程序挂起，直到其他进程关闭该数据库。为了防止无限期等待，可以为 Open() 函数传递一个超时选项：\ndb, err := bolt.Open(\u0026#34;my.db\u0026#34;, 0600, \u0026amp;bolt.Options{Timeout: 1 * time.Second}) 事务 # boltdb 一次只允许一个读写事务（transaction），同时允许任意数量的只读事务。每个事务在开始时都有一个一致的数据视图，即该事务开始时的数据状态。\n单个事务以及从它们创建的所有对象（例如：桶、键）都不是线程安全的。如果要在多个 goroutine 中处理数据，必须为每个 goroutine 启动一个事务，或者使用锁机制以确保同一时刻内只有一个 goroutine 访问事务。从 DB 创建事务是线程安全的。\n只读事务和读写事务不应相互依赖，通常也不应在同一个 goroutine 中同时打开。这可能会导致死锁，因为读写事务需要定期重新映射数据文件，但在有只读事务打开时无法进行此操作。\n读写事务 # 为开启一个读写事务，可以使用 DB.Update() 方法：\nerr := db.Update(func(tx *bolt.Tx) error { ... return nil }) 在闭包内部，将拥有数据库的一致性视图。通过在函数结尾处返回 nil 来提交事务。也可以在任何时候通过返回一个错误来回滚事务。在读写事务中，所有数据库操作都是允许的。\n始终检查返回的错误，因为它会报告任何可能导致事务未完成的磁盘故障。如果在闭包中返回一个错误，该错误将会被传递出去。\n只读事务 # 为开启一个只读事务，可以使用 DB.View() 方法：\nerr := db.View(func(tx *bolt.Tx) error { ... return nil }) 在这个闭包中，同样会获得数据库的一致性视图，但在只读事务中不允许进行任何修改操作。只能在只读事务中检索桶（bucket）、检索值以及复制数据库。\n批量读写事务 # 每次调用 DB.Update() 都会等待磁盘提交写入操作。这种开销可以通过使用 DB.Batch() 函数将多个更新操作组合在一起来提升写入性能。\nerr := db.Batch(func(tx *bolt.Tx) error { ... return nil }) 并发的 Batch 调用会被机会性地（opportunistically）组合成更大的事务。Batch 只有在多个 goroutine 调用时才有用。\n当有多个 Batch 同时调用时，系统会尝试将这些并发的 Batch 调用合并成一个更大的事务，以减少磁盘写入的开销。\nBatch 功能主要在存在多个 goroutine 并发调用时才发挥作用，如果只有一个 goroutine 调用 Batch，则合并的效果不明显。\n代价是，如果事务的某些部分失败，Batch 可能会多次调用给定的函数。因此，该函数必须是幂等的，并且副作用只能在 DB.Batch() 成功返回后生效。\n例如：不要在函数内部显示消息，而应在外层作用域中设置变量。\nvar id uint64 err := db.Batch(func(tx *bolt.Tx) error { // Find last key in bucket, decode as bigendian uint64, increment // by one, encode back to []byte, and add new key. ... id = newValue return nil }) if err != nil { return ... } fmt.Println(\u0026#34;Allocated ID %d\u0026#34;, id) 手动管理事务 # DB.View() 和 DB.Update() 函数是 DB.Begin() 函数的包装器。这些辅助函数会启动事务，执行一个函数，然后如果返回了错误，安全地关闭事务。这是推荐使用 boltdb 事务的方式。\n不过，有时可能希望手动启动和结束事务。可以直接使用 DB.Begin() 函数，但请务必确保关闭事务。\n// Start a writable transaction. tx, err := db.Begin(true) if err != nil { return err } defer tx.Rollback() // Use the transaction... _, err := tx.CreateBucket([]byte(\u0026#34;MyBucket\u0026#34;)) if err != nil { return err } // Commit the transaction and check for error. if err := tx.Commit(); err != nil { return err } DB.Begin() 的第一个参数是一个布尔值，用于指示事务是否应该是可写的。\n如果传递 true，则表示要创建一个可写事务（读写事务），允许对数据库进行修改。 如果传递 false，则表示要创建一个只读事务，只能读取数据而不能修改数据。 使用桶 # 桶（Buckets）是数据库中键值对的集合。桶中的所有键必须是唯一的。可以使用 DB.CreateBucket() 函数来创建一个桶：\ndb.Update(func(tx *bolt.Tx) error { b, err := tx.CreateBucket([]byte(\u0026#34;MyBucket\u0026#34;)) if err != nil { return fmt.Errorf(\u0026#34;create bucket: %s\u0026#34;, err) } return nil }) 可以使用 Tx.CreateBucketIfNotExists() 函数在桶不存在时创建它。这是一个常见的模式，即在打开数据库后，为所有顶级桶调用此函数，以确保它们在未来的事务中存在。\n要删除一个桶，只需调用 Tx.DeleteBucket() 函数。\n使用 KV 对 # 要将键值对保存到一个桶中，请使用 Bucket.Put() 函数：\ndb.Update(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(\u0026#34;MyBucket\u0026#34;)) err := b.Put([]byte(\u0026#34;answer\u0026#34;), []byte(\u0026#34;42\u0026#34;)) return err }) 这将把 answer 键的值设置为 42 在 MyBucket 桶中。要检索这个值，可以使用 Bucket.Get() 函数：\ndb.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(\u0026#34;MyBucket\u0026#34;)) v := b.Get([]byte(\u0026#34;answer\u0026#34;)) fmt.Printf(\u0026#34;The answer is: %s\\n\u0026#34;, v) return nil }) Get() 函数不会返回错误，因为其操作是保证有效的（除非发生系统故障）。如果键存在，它将返回其字节切片值。如果键不存在，它将返回 nil。需要注意的是，可以将零长度的值设置到一个键上，这与键不存在是不同的。\n要从桶中删除一个键，请使用 Bucket.Delete() 函数。\n请注意，从 Get() 返回的值仅在事务打开时有效。如果需要在事务外使用该值，则必须使用 copy() 将其复制到另一个字节切片中。\n桶的自增整数 # 通过使用 NextSequence() 函数，可以让 boltdb 确定一个序列，用作 KV 对的唯一标识符。请参见下面的示例：\n// CreateUser saves u to the store. The new user ID is set on u once the data is persisted. func (s *Store) CreateUser(u *User) error { return s.db.Update(func(tx *bolt.Tx) error { // Retrieve the users bucket. // This should be created when the DB is first opened. b := tx.Bucket([]byte(\u0026#34;users\u0026#34;)) // Generate ID for the user. // This returns an error only if the Tx is closed or not writeable. // That can\u0026#39;t happen in an Update() call so I ignore the error check. id, _ := b.NextSequence() u.ID = int(id) // Marshal user data into bytes. buf, err := json.Marshal(u) if err != nil { return err } // Persist bytes to users bucket. return b.Put(itob(u.ID), buf) }) } // itob returns an 8-byte big endian representation of v. func itob(v int) []byte { b := make([]byte, 8) binary.BigEndian.PutUint64(b, uint64(v)) return b } type User struct { ID int ... } 迭代 key # boltdb 将其键按字节排序存储在桶内。这使得对这些键的顺序遍历非常快速。要遍历键，我们将使用 Cursor：\ndb.View(func(tx *bolt.Tx) error { // Assume bucket exists and has keys b := tx.Bucket([]byte(\u0026#34;MyBucket\u0026#34;)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) 游标允许你移动到键列表中的特定位置，并一次一个地向前或向后遍历这些键。\n游标上提供了以下函数：\nFirst() Move to the first key. Last() Move to the last key. Seek() Move to a specific key. Next() Move to the next key. Prev() Move to the previous key. 每个函数的返回签名为 (key []byte, value []byte)。当你遍历到游标的末尾时，Next() 将返回一个 nil 键。你必须使用 First()、Last() 或 Seek() 来定位一个位置，然后再调用 Next() 或 Prev()。如果不进行定位，这些函数将返回 nil 键。\n在迭代过程中，如果键是非 nil 但值是 nil，这意味着该键指向的是一个桶而不是值。可以使用 Bucket.Bucket() 来访问子桶。\n前缀扫描 # 要遍历一个键前缀，你可以结合使用 Seek() 和 bytes.HasPrefix()：\ndb.View(func(tx *bolt.Tx) error { // Assume bucket exists and has keys c := tx.Bucket([]byte(\u0026#34;MyBucket\u0026#34;)).Cursor() prefix := []byte(\u0026#34;1234\u0026#34;) for k, v := c.Seek(prefix); k != nil \u0026amp;\u0026amp; bytes.HasPrefix(k, prefix); k, v = c.Next() { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) } return nil }) 范围扫描 # 另一个常见的用例是扫描一个范围，比如时间范围。如果你使用可排序的时间编码，例如 RFC3339，你可以这样查询特定的日期范围：\ndb.View(func(tx *bolt.Tx) error { // Assume our events bucket exists and has RFC3339 encoded time keys. c := tx.Bucket([]byte(\u0026#34;Events\u0026#34;)).Cursor() // Our time range spans the 90\u0026#39;s decade. min := []byte(\u0026#34;1990-01-01T00:00:00Z\u0026#34;) max := []byte(\u0026#34;2000-01-01T00:00:00Z\u0026#34;) // Iterate over the 90\u0026#39;s. for k, v := c.Seek(min); k != nil \u0026amp;\u0026amp; bytes.Compare(k, max) \u0026lt;= 0; k, v = c.Next() { fmt.Printf(\u0026#34;%s: %s\\n\u0026#34;, k, v) } return nil }) 请注意，虽然 RFC3339 是可排序的，但 Go 对 RFC3339Nano 的实现并不使用固定的十进制点后数字位数，因此不可排序。\nForEach() # 如果你需要遍历桶中的所有键，也可以使用 ForEach() 函数：\ndb.View(func(tx *bolt.Tx) error { // Assume bucket exists and has keys b := tx.Bucket([]byte(\u0026#34;MyBucket\u0026#34;)) b.ForEach(func(k, v []byte) error { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, v) return nil }) return nil }) 嵌套桶 # 你也可以将一个桶存储在一个键中，以创建嵌套桶。其 API 与 DB 对象上的桶管理 API 相同：\nfunc (*Bucket) CreateBucket(key []byte) (*Bucket, error) func (*Bucket) CreateBucketIfNotExists(key []byte) (*Bucket, error) func (*Bucket) DeleteBucket(key []byte) error 假设你有一个多租户应用程序，其中根级别的桶是账户桶。在这个桶内部有一个账户序列，这些账户本身是桶。在这个序列桶内部，你可以有许多与账户本身相关的桶（如用户、笔记等），将信息隔离成逻辑上的分组。\n// createUser creates a new user in the given account. func createUser(accountID int, u *User) error { // Start the transaction. tx, err := db.Begin(true) if err != nil { return err } defer tx.Rollback() // Retrieve the root bucket for the account. // Assume this has already been created when the account was set up. root := tx.Bucket([]byte(strconv.FormatUint(accountID, 10))) // Setup the users bucket. bkt, err := root.CreateBucketIfNotExists([]byte(\u0026#34;USERS\u0026#34;)) if err != nil { return err } // Generate an ID for the new user. userID, err := bkt.NextSequence() if err != nil { return err } u.ID = userID // Marshal and save the encoded user. if buf, err := json.Marshal(u); err != nil { return err } else if err := bkt.Put([]byte(strconv.FormatUint(u.ID, 10)), buf); err != nil { return err } // Commit the transaction. if err := tx.Commit(); err != nil { return err } return nil } 数据库备份 # boltdb 是一个单文件，因此易于备份。你可以使用 Tx.WriteTo() 函数将数据库的一致视图写入到 Writer 中。如果在只读事务中调用它，它将执行热备份，而不会阻塞其他数据库的读取和写入操作。\n默认情况下，它将使用常规文件句柄，这将利用操作系统的页面缓存。有关优化大于 RAM 数据集的信息，请参阅 Tx 文档。\n一个常见的用例是通过 HTTP 进行备份，这样你可以使用像 cURL 这样的工具来进行数据库备份。\nfunc BackupHandleFunc(w http.ResponseWriter, req *http.Request) { err := db.View(func(tx *bolt.Tx) error { w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/octet-stream\u0026#34;) w.Header().Set(\u0026#34;Content-Disposition\u0026#34;, `attachment; filename=\u0026#34;my.db\u0026#34;`) w.Header().Set(\u0026#34;Content-Length\u0026#34;, strconv.Itoa(int(tx.Size()))) _, err := tx.WriteTo(w) return err }) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) } } 可以使用下边的命令进行备份：\n$ curl http://localhost/backup \u0026gt; my.db 或者你可以打开浏览器访问 http://localhost/backup，它将自动下载。\n如果你想备份到另一个文件，可以使用 Tx.CopyFile() 辅助函数。\n统计 # 数据库会持续跟踪许多内部操作的计数，以便你更好地了解发生了什么。通过在两个时间点捕获这些统计信息的快照，我们可以看到在这段时间范围内执行了哪些操作。\n例如，我们可以启动一个 goroutine，每 10 秒记录一次统计信息：\ngo func() { // Grab the initial stats. prev := db.Stats() for { // Wait for 10s. time.Sleep(10 * time.Second) // Grab the current stats and diff them. stats := db.Stats() diff := stats.Sub(\u0026amp;prev) // Encode stats to JSON and print to STDERR. json.NewEncoder(os.Stderr).Encode(diff) // Save stats for the next loop. prev = stats } }() 将这些统计信息传送到像 statsd 这样的服务进行监控，或者提供一个 HTTP 端点以执行固定长度的采样，也是非常有用的。\n只读模式 # 有时候创建一个共享的只读 boltdb 数据库是很有用的。为此，在打开数据库时设置 Options.ReadOnly 标志。只读模式使用共享锁来允许多个进程从数据库中读取，但会阻止任何进程以读写模式打开数据库。\ndb, err := bolt.Open(\u0026#34;my.db\u0026#34;, 0666, \u0026amp;bolt.Options{ReadOnly: true}) if err != nil { log.Fatal(err) } 注意事项 # 选择合适的工具非常重要，boltdb 也不例外。在评估和使用 boltdb 时，请注意以下几点：\nboltdb 适合读取密集型工作负载。顺序写入性能也很快，但随机写入可能会很慢。你可以使用 DB.Batch() 或添加写前日志来帮助缓解这个问题。\nboltdb 内部使用 B+ 树，所以可能会有很多随机页面访问。相比旋转磁盘，SSD 能显著提高性能。\n尽量避免长时间运行的读取事务。boltdb 使用写时复制，所以在旧事务使用旧页面时，旧页面无法被回收。\n从 boltdb 返回的字节切片 只在事务期间有效。一旦事务已提交或回滚，它们指向的内存可能会被新页面重用或从虚拟内存中取消映射，当访问时可能会出现意外的地址错误。\nboltdb 在数据库文件上使用独占写锁，因此无法被多个进程共享。\n使用 Bucket.FillPercent 时要小心。对具有随机插入的桶设置较高的填充百分比会导致数据库的页面利用率很差。\n通常使用较大的桶。较小的桶在超过页面大小（通常为 4KB）后会导致页面利用率差。\n向新桶中批量加载大量随机写入 可能很慢，因为页面在事务提交之前不会拆分。在单个事务中随机插入超过 100,000 个键/值对到单个新桶是不建议的。\nboltdb 使用内存映射文件，因此底层操作系统处理数据的缓存。通常，操作系统会尽可能将文件缓存到内存中，并根据需要将内存释放给其他进程。这意味着，当处理大数据库时，boltdb 可能显示出非常高的内存使用量。然而，这是预期的，操作系统会根据需要释放内存。只要内存映射适合进程的虚拟地址空间，boltdb 可以处理比可用物理 RAM 大得多的数据库。在 32 位系统上可能会有问题。\nboltdb 数据库中的数据结构是内存映射的，所以数据文件将是特定字节序的。这意味着你不能将 boltdb 文件从小端机器复制到大端机器并使其正常工作。对于大多数用户来说，这不是问题，因为现代 CPU 大多是小端的。\n由于页面在磁盘上的布局方式，boltdb 不能截断数据文件并将空闲页面返回到磁盘。相反，boltdb 在其数据文件中维护一个未使用页面的空闲列表。这些空闲页面可以被后续事务重用。这对许多用例来说效果很好，因为数据库通常会增长。然而，重要的是要注意，删除大量数据不会允许你回收磁盘上的空间。\n对于页申请（page allocation）的信息，可以查看 此评论。\n阅读源代码 # boltdb 是一个相对较小的代码库（\u0026lt;3KLOC），用于嵌入式、可序列化、事务性的键/值数据库，因此对于对数据库工作原理感兴趣的人来说，它是一个很好的起点。\n最好的入手点是 boltdb 的主要入口：\nOpen() - 初始化对数据库的引用。负责创建数据库（如果不存在的话）、获取文件的独占锁、读取元页面和内存映射文件。\nDB.Begin() - 根据 writable 参数的值启动只读或读写事务。这需要暂时获取“元”锁来跟踪打开的事务。一次只能存在一个读写事务，因此在读写事务期间会获取rwlock。\nBucket.Put() - 将一个键/值对写入桶。在验证参数后，使用游标遍历 B+ 树到键和值将被写入的页面和位置。一旦找到位置，桶会将底层页面及其父页面加载到内存中作为“节点”。这些节点是读写事务期间发生变更的地方。这些更改会在提交时刷新到磁盘。\nBucket.Get() - 从桶中检索一个键/值对。使用游标移动到键/值对的页面和位置。在只读事务期间，键和值数据作为对底层 mmap 文件的直接引用返回，因此没有分配开销。对于读写事务，这些数据可能引用 mmap 文件或内存中的节点值之一。\nCursor - 这个对象用于遍历 B+ 树上的磁盘页面或内存节点。它可以定位到特定键，移动到第一个或最后一个值，或者向前或向后移动。游标处理 B+ 树的上下移动，对最终用户透明。\nTx.Commit() - 将内存中的脏节点和空闲页面列表转换为要写入磁盘的页面。写入磁盘的过程分为两个阶段。首先，将脏页面写入磁盘并进行 fsync()。其次，写入一个新的元页面，并进行另一个 fsync()。这种两阶段写入确保了在崩溃事件中，部分写入的数据页面会被忽略，因为指向它们的元页面永远不会被写入。部分写入的元页面会被使无效，因为它们是带有校验和的。\n"},{"id":1,"href":"/docs/MapDB/BTree/","title":"BTree","section":"MapDB","content":" BTree # BTree # 所有节点有 M 度 每个节点至少有 M / 2 个子结点 参考文献 # Modern B-Tree Techniques https://www.cs.usfca.edu/~galles/visualization/BTree.html https://www.youtube.com/watch?v=aZjYr87r1b8 "},{"id":2,"href":"/docs/JVM/ByteCode/ClassFile/","title":"Class 文件结构","section":"字节码","content":" Class 文件结构 # 前言 # 任何一个 class 文件都会对应一个类或接口，但并不是所有的类和接口都有对应的 class 文件（如：动态生成的类）。\n// Main.java public class Main { public static class InnerClass { } public static void main(String[] args) { } } 当执行 $javac Main.java 命令后，会生成 Main.class 和 Main$InnerClass.class 两个 class 文件。\nclass 文件由 8-bit 字节流组成。16-bit 和 32-bit 分别由 2 个和 4 个连续的 8-bit 组成。多字节数据使用大端（bit-endian）序保存。\n使用 u1、u2 和 u4 分别表示 1 字节、2 字节和 4 字节。\nNames # 二进制类和接口名称 # 在 Java 虚拟机中，类和接口的名称使用二进制名称格式表示。此格式与源代码中的类名表示略有不同。\n类名和接口名：二进制名称使用斜杠（/）而不是点（.）来分隔包和类的名称。例如，java.lang.Object 的二进制名称是 java/lang/Object。 内部类：对于内部类，二进制名称中使用美元符号（$）来分隔外部类和内部类的名称。例如，OuterClass.InnerClass 的二进制名称是 OuterClass$InnerClass。 二进制名称的使用场景 # 字节码指令：\n在字节码指令中，类和接口的引用通常使用二进制名称。例如，L 类型签名前缀后跟随二进制名称，如 Ljava/lang/Object; 表示 java.lang.Object。 类文件格式：\n在类文件的常量池中，类和接口的名称存储为二进制名称形式。例如，CONSTANT_Class_info 结构中引用的名称是二进制名称。 示例 # 普通类：\n源代码名称：com.example.MyClass 二进制名称：com/example/MyClass 内部类：\n源代码名称：com.example.OuterClass.InnerClass 二进制名称：com/example/OuterClass$InnerClass ClassFile # ClassFile { u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count]; } magic # magic 用于标识 class 文件的魔法数字，值为：0xCAFEBABE。\nminor_version, major_version # minor_version 和 major_version 分别表示 class 文件的次版本和主版本。使用主次版本一起表示 class 文件的版本，格式为：major_version.minor_version。\n每次发布新版本的 Java SE 都会有新的 major_version，反映重大变更和新特性引入。主版本内的 minor_version 通常用来指示类文件格式的次要更新和改进。\n高 major_version 的 JVM 可以支持低 major_version 的类文件。\nClass File Versions 可以查看所有 Java SE 对应的主版本。\nconstant_pool_count, constant_pool # 常量池是一个包含多种结构的表，用于表示类文件结构及其子结构中引用的各种字符串常量、类和接口名称、字段名称以及其他常量。\nconstant_pool_count 为常量池中条目（entry）的数量加 1。constant_pool 表的索引为：1 至 constant_pool_count - 1。\naccess_flags # 访问标志 (access_flags) 是用于表示类或接口的访问权限和属性的标志掩码。每个标志位表示特定的访问权限或属性。\n下表为 JDK 21 的类访问和属性修饰符：\nFlag Name Value Interpretation ACC_PUBLIC 0x0001 Declared public; may be accessed from outside its package. ACC_FINAL 0x0010 Declared final; no subclasses allowed. ACC_SUPER 0x0020 Treat superclass methods specially when invoked by the invokespecial instruction. ACC_INTERFACE 0x0200 Is an interface, not a class. ACC_ABSTRACT 0x0400 Declared abstract; must not be instantiated. ACC_SYNTHETIC 0x1000 Declared synthetic; not present in the source code. ACC_ANNOTATION 0x2000 Declared as an annotation interface. ACC_ENUM 0x4000 Declared as an enum class. ACC_MODULE 0x8000 Is a module, not a class or interface. this_class # this_class 项目必须是一个有效的常量池索引。该索引指向的常量池条目必须是一个 CONSTANT_Class_info 结构，表示由该类文件定义的类或接口。\nsuper_class # super_class 用于表示当前类或接口的父类，该索引指向常量池中的条目。\n对于类 # 如果 super_class 非 0，该索引指向的常量池条目必须是一个 CONSTANT_Class_info 结构，表示由该类文件定义的类或接口。 如果 super_class 为 0，表示该类为 Object。唯一一个没有直接父类的类。 对于接口 # 对于接口来说，super_class 始终为指向常量池条目的合法索引。所有接口的父类都为 Object 类。\n// Interface.java public interface Interface { } 使用 $javap -v Interface.class 反编译后的部分结果。\n// Interface.class public interface io.github.ileonli.Interface minor version: 0 major version: 65 flags: (0x0601) ACC_PUBLIC, ACC_INTERFACE, ACC_ABSTRACT this_class: #1 // io/github/ileonli/Interface super_class: #3 // java/lang/Object interfaces: 0, fields: 0, methods: 0, attributes: 1 Constant pool: #1 = Class #2 // io/github/ileonli/Interface #2 = Utf8 io/github/ileonli/Interface #3 = Class #4 // java/lang/Object #4 = Utf8 java/lang/Object #5 = Utf8 SourceFile #6 = Utf8 Interface.java // Interface.java public interface Interface extends Cloneable { } 使用 $javap -v Interface.class 反编译后的部分结果。\n// Interface.class public interface io.github.ileonli.Interface extends java.lang.Cloneable minor version: 0 major version: 65 flags: (0x0601) ACC_PUBLIC, ACC_INTERFACE, ACC_ABSTRACT this_class: #1 // io/github/ileonli/Interface super_class: #3 // java/lang/Object interfaces: 1, fields: 0, methods: 0, attributes: 1 Constant pool: #1 = Class #2 // io/github/ileonli/Interface #2 = Utf8 io/github/ileonli/Interface #3 = Class #4 // java/lang/Object #4 = Utf8 java/lang/Object #5 = Class #6 // java/lang/Cloneable #6 = Utf8 java/lang/Cloneable #7 = Utf8 SourceFile #8 = Utf8 Interface.java interfaces_count, interfaces[] # "},{"id":3,"href":"/docs/15-445/storage/","title":"Database Storage","section":"15-445","content":" Database Storage # https://15445.courses.cs.cmu.edu/fall2023/slides/03-storage1.pdf\nDBMS 假设数据库主要使用的存储是非易失的（non-volatile）。DBMS 主要工作之一为：管理数据在易失存储设备和非易失存储设备之间的移动。\n基于磁盘的结构 # 存储结构 # 对于存储设备来说：速度越快 -\u0026gt; 价钱昂贵，速度越慢 -\u0026gt; 价格便宜。因此，要在价格和速度之间进行一部分取舍。\n主流的做法为，采用速度更快的存储设备作为底层设备的缓存。\n此课程只关注非易失存储设备\nIntel 开发了 Optane 非易失存储设备，可以提供类似内存的速度和易失性（volatile），但又具有非易失性的特性（non-volatile）。这意味着数据在断电时仍然保持不变，适合用于需要快速恢复状态的应用场景，如数据库和日志记录。\n由于此业务不赚钱，Intel 已经终止了此设备的研发\n访问时间 # 不同存储设备的延迟对比如下：\n随机和顺序读取 # 在非易失存储设备上进行随机读取（random access）比顺序读取（sequential access）慢的多。\n为了充分利用顺序读取速度较快的优势，DBMS 可以使用下边的优化方法：\n减少写入随机页面的次数：尝试减少对随机存储页面（即内存或磁盘上的页面）的写操作次数。这样做的目的是让数据能够存储在连续的块中。连续的存储块更有利于提高数据的访问速度，因为读取连续的数据比读取散乱分布的数据效率更高。这种优化有助于提高存储系统的性能，特别是在磁盘 I/O 操作方面。 扩展（Extent）：当一次性分配多个页面时，这种分配方式称为扩展。换句话说，一个扩展就是一组连续分配的页面块。通过这种方式，可以更高效地管理存储空间，并进一步确保数据以连续的方式存储，从而提高读写性能。 设计原则 # 一个良好的 DBMS 应该有以下设计原则：\n允许管理的数据库的数据大小超过内存（RAM）。 尽量减少磁盘读写的次数。 最大化使用顺序读取，减少随机读取的次数。 large stalls：当磁盘读写操作没有得到有效管理时，尤其是在面对随机访问过多或磁盘 I/O 负载过重的情况下，系统可能会经历长时间的等待，导致处理速度明显变慢。\n面向磁盘的 DBMS # 当执行引擎（execution engine）需要获取页（page）时，会尝试从缓冲池（buffer pool）中获取。\n缓冲池作用为：将保存在磁盘中的页加载到内存中，由于内存通常远远小于磁盘大小，需要采用一些算法（如：LRU）来保证页的加载和换出。\n加载到缓冲池中后，我们就可以直接使用此页了。\n当需要修改数据时，可以直接对内存中的页进行修改，修改后没写回到磁盘的页称为脏页（dirty page）。\n为什么不使用 OS? # DBMS 可以使用 mmap 技术，将文件的内容直接映射到程序的地址空间中。\nOS 负责管理文件页面的调度和内存交换，因此 DBMS 不需要直接处理这些细节。\n当访问 page1 时，会触发缺页中断，将磁盘数据加载到内存中。\n当访问 page3 时，会触发缺页中断，将磁盘数据加载到内存中。\n当物理内存满了后，操作系统会采用置换算法将内存中的页换出到磁盘中。\n但操作系统不知道内存中的页正在进行的操作，如：正处于事务中的页在事务完成前不应该换出。\n当多线程访问 mmap 文件时，就会发生一些问题。\n使用 mmap 会有下边各种各样的问题：\n事务安全（Transaction Safety）：OS 可能在任意时间将脏页刷新磁盘中。 I/O 停顿（I/O Stalls）：DBMS 不知道有哪些页在内存中，当发生缺页时，OS 会将线程停顿。 错误处理（Error Handling）：DBMS 必须处理由于访问无效页产生的 SIGBUS 信号。 性能问题（Performance Issues）：会发生 OS 数据结构冲突，TLB 清空。 可以使用 madvise、mlock 和 msync 来解决 mmap 带来的问题。\nDBMS 会尽可能控制任何事情，可以比 OS 做的更好。\nAre You Sure You Want to Use MMAP in Your Database Management System? 介绍了为什么不推荐在 DBMS 中使用 mmap 的原因。\n文件存储 # DBMS 会将数据库在磁盘上以特有的格式保存为一个或多个文件。\n存储管理 # 存储管理（storage manager）有义务维护数据库的文件。为提高时间（spatial）和空间（temporal）局部性，会采用特定的调度策略。\n数据库文件会被组织为页的集合。存储管理需要处理对页的读写操作以及跟踪空闲的空间。\n数据库页 # 页是固定大小的数据块，页有以下特性：\n页中的数据块可用于存储元组（tuples）、元数据（meta-data）、索引（indexes）和日志记录（log records）。 大多数系统会将不同类型的数据分别存储在不同的页中，而不是在同一页内混合存储不同类型的数据。 每个页独立存储和管理自己的数据，使其在单独读取或处理时不需要引用其他页的数据。 每个页都有一个唯一的标识符，DBMS 使用中间层将 ID 映射到磁盘上的位置。 DBMS 中会存在 3 中不同类型的页：\n硬件页（通常是 4KB） OS 页（通常是 4KB，x64 为 2MB/1GB） 数据库页（512B - 32KB） 硬件页面（hardware page）是存储设备能够保证写入操作是安全的、不会失败的最大数据块。\n存储设备（如固态硬盘、硬盘驱动器等）在执行写入操作时，会以页为单位来处理数据。这些页通常是固定大小的（比如 4KB 或 8KB）。在写入数据时，设备可以确保这些页的数据能够被完整地写入，即使在断电或其他故障的情况下，这些数据也不会损坏或丢失。这样可以保证数据的可靠性和一致性。\n不同的 DBMS 以不同的文件形式管理页：\nHeap File Organization Tree File Organization Sequential / Sorted File Organization (ISAM) Hashing File Organization 堆文件 # 堆文件（heap file） 是一种无序的页面集合，其中的元组（记录）以随机顺序存储。\n在单个堆文件中获取第 i 个页是很容易的，由于页大小是固定的，只需要计算偏移值即可，计算公式：offset = Page# x PageSize。\n如果我们有多个堆文件，需要元数据来跟踪多个文件中存在的页面，以及哪些页面有可用空间。”\nDBMS 需要维护特殊的页，用于跟踪数据库文件中数据页的位置。\n必须确保目录页与数据页保持同步\n目录页面还记录了关于可用空间的元数据：每个页面中空闲插槽的数量，以及空闲（free）或空（empty）页的列表。\n页结构 # 页头 # 每个页包含一个头部的元数据，用于记录页内容的信息。可能会含有一下的元数据：\nPage Size Checksum DBMS Version Transaction Visibility Compression / Encoding Meta-data Schema Information Data Summary / Sketches 存储元组 # 如何在页里存储元组数据呢？\n错误的想法（稻草人的想法）：记录页内元组的数量，然后仅仅在尾部添加新的元组。\n如果我们需要删除一个元组，页内就会产生空洞。\n如果我们想将新插入的 4 号页放到刚删除元组的位置，仅靠数量一个元数据是不够的，我们需要额外的元数据。\n如果元组的长度是可变的话，我们也无法对其进行处理，无法定位到具体的元组。\n插槽页 # 可以采用插槽页（slotted pages）的方法，每个插槽存储元组开始的索引位置。\n也可以在插槽中存储元组的长度\n插槽数据和元组存储时，增长的方向如下所示：\n删除元组 # 当我们删除页中元组时，只需要将删除元组前的数据拷贝过来并更新插槽中的索引位置即可。\nrecord ids # 有些 DBMS 会在元组内存储一个唯一的记录标识，用于表示其在数据库中的物理位置。\n元组结构 # 元组本质上是字节序列，DBMS 需要将这些字节解释为属性类型和值。\n元组头 # 每个元组前面都有一个头部，包含关于自身的元数据。\n元组数据 # 属性通常按照创建表时指定的顺序存储，这样做的目录是因为简单。\n反规范化 # DBMS 可以将相关联的元组存储在一个页上，这样可以减少 I/O 次数，以提高数据库性能。\n更新操作可能会变得更加复杂和昂贵，如果一个数据项在多个页中都有存储（因为相关元组被预连接在一起），更新时需要在多个位置同步更新这些数据。这增加了更新操作的复杂性和时间开销。\n当我们需要使用 JOIN 时，只需要加载一次页即可。可明显减少 I/O 次数。\n很多数据库都已经使用了此技术。\n# "},{"id":4,"href":"/docs/ProGit/Git-%E5%9F%BA%E7%A1%80/","title":"Git 基础","section":"Pro Git","content":" Git 基础 # 获取 Git 仓库 # 有两种取得 Git 项目仓库的方法：\n将现有项目或目录下导入所有文件到 Git 中，可以使用 $ git init 命令。 从服务器克隆一个现有的 Git 仓库，使用 $ git clone \u0026lt;project url\u0026gt; 命令。 Git 生命周期 # 工作目录下的所有文件都处于两种状态之一：已跟踪和未跟踪。\n已跟踪：是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改、已修改或已放入暂存区。 未跟踪：工作目录中除已跟踪文件以外的所有其它文件都属于未跟踪文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态。\n编辑已跟踪的文件后（如：修改代码），Git 会将这些修改的文件标记为已修改文件。随后我们会逐步将修改过的文件加入暂存区中，然后提交暂存区中的所有文件。\n如此反复，使用 Git 的生命周期如下图所示：\n检查当前文件状态 # 如果需要查看文件处于的状态，可以使用 $ git status 命令。\n当我们对 $ git init 后的仓库使用此命令，可以看到下边的输出：\n$ git status On branch main No commits yet nothing to commit (create/copy files and use \u0026#34;git add\u0026#34; to track) 我们可以从上边输出中得到以下信息：\n当前的分支名称为 “main”。 所有已跟踪的文件自上次提交后未进行任何修改。 当前目录下没有处于未跟踪的文件。 现在，使用 echo 命令在项目下创建一个新的 README 文件。使用 $ git status 命令后，可以看到一个新的未跟踪文件：\n$ echo \u0026#39;My Project\u0026#39; \u0026gt; README $ git status On branch main No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) README nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) 从输出中可以看到 README 文件处于 Untracked files 下。Git 不会自动将未跟踪文件纳入跟踪范围，除非明确告之“我需要跟踪该文件”，\n跟踪新文件 # 使用命令 $ git add 开始跟踪一个文件。 所以，要跟踪 README 文件，可以运行：\n$ git add README 此时再次运行 $ git status 命令，可以看到 README 文件已被跟踪，并处于暂存状态：\n$ git status On branch main No commits yet Changes to be committed: (use \u0026#34;git rm --cached \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: README 在 Changes to be committed 下的文件处于已暂存状态。如果此时提交，那么该文件当前的版本将被保留在历史记录中。\n暂存已修改文件 # 如果修改了一个名为 CONTRIBUTING.md 的已被跟踪的文件，然后运行 git status 命令，会看到下面内容：\n$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: README Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: CONTRIBUTING.md 文件 CONTRIBUTING.md 出现在 Changes not staged for commit 这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。要暂存这次更新，需要运行 $ git add 命令。\n现在运行 $ git add CONTRIBUTING.md 将 CONTRIBUTING.md 文件放到暂存区，然后再看看 $ git status 的输出：\n$ git add CONTRIBUTING.md $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: CONTRIBUTING.md new file: README 现在两个文件都已暂存，下次提交时就会一并记录到仓库。假设此时，你想要在 CONTRIBUTING.md 里再加条注释，重新编辑保存后，准备提交这两个文件。\n不过且慢，再次运行 $ git status 看看：\n$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: CONTRIBUTING.md new file: README Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: CONTRIBUTING.md 可以看到 CONTRIBUTING.md 文件同时出现在暂存区和非暂存区。这是为什么？\n实际上 Git 只不过暂存了你运行 $ git add 命令时的版本，如果现在提交，CONTRIBUTING.md 的版本是你最后一次运行 $ git add 命令时的那个版本，而不是运行 $ git commit 时，在工作目录中的版本。\n所以，运行了 $ git add 之后又作了修订的文件，需要重新运行 $ git add 把最新版本重新暂存起来：\n$ git add CONTRIBUTING.md $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: CONTRIBUTING.md new file: README 提交更新 # 使用 $ git commit 前，一定要确保所有的修改已经 $ git add 过。\n$ git commit 这种方式会启动文本编辑器以便输入本次提交的说明。退出编辑器时，Git 会丢掉注释行，用你输入提交附带信息生成一次提交。\n# Please enter the commit message for your changes. Lines starting # with \u0026#39;#\u0026#39; will be ignored, and an empty message aborts the commit. # # On branch main # Changes to be committed: # modified: CONTRIBUTING.md # new file: README # 另外，你也可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行，如下所示：\n$ git commit -m \u0026#34;add: CONTRIBUTING.md and README\u0026#34; [main 34ae990] add: CONTRIBUTING.md and README 2 files changed, 2 insertions(+) create mode 100644 README 每一次运行提交操作，都是保存一次项目快照，以后可以回到这个状态，或者进行比较。\n跳过暂存区域 # 尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。\nGit 提供了一个跳过使用暂存区域的方式，只要在提交的时候，给 $ git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 $ git add 步骤。\n移除文件 # 要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。可以用 $ git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。\n如果只是简单地从工作目录中手工删除文件，运行 $ git status 时就会在 Changes not staged for commit 部分（未暂存清单）看到：\n$ rm README $ git status On branch main Changes not staged for commit: (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) deleted: README no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 然后再运行 $ git rm 记录此次移除文件的操作：\n$ git rm README rm \u0026#39;README\u0026#39; $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) deleted: README 下一次提交时，该文件就不再纳入版本管理了。\n如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f。这是一种安全特性，用于防止误删还没有添加到快照的数据，这样的数据不能被 Git 恢复。\n另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。换句话说，仍然文件保留在磁盘，但是并不想让 Git 继续跟踪。\n当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。\n为达到这一目的，可以使用 --cached 选项：\n$ git rm --cached README 状态简览 # 使用 $ git status -s 命令或 $ git status --short 命令可以获得一种更为紧凑的格式输出。\n忽略文件 # 有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。我们可以创建一个名为 .gitignore 文件，列出要忽略的文件。\n可以在 A collection of useful .gitignore templates 查看常用的模板。\n查看提交历史 # 在提交了若干更新，又或者克隆了某个项目之后，如果想回顾下历史提交记录。完成这个任务最简单而又有效的工具是 $ git log 命令。\n$ git log commit 6c669101bea2a6b2400f070f72f35f0866ea714a (HEAD -\u0026gt; main) Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:06:10 2024 +0800 add: README 查看已暂存和未暂存的修改 # 如果 $ git status 命令的输出对于你来说过于模糊，你想知道具体修改了什么地方，可以用 $ git diff 命令。\n撤消操作 # 修正提交 # 有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。此时，可以运行带有 --amend 选项的提交命令尝试重新提交：\n$ git commit --amend 我们有 3 个处于 Changes to be committed 状态的文件。\n$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: 1.txt modified: 2.txt modified: 3.txt 我们使用 $ git commit 提交其中的两个文件。\n$ git commit -m \u0026#34;change: 1.txt, 2.txt\u0026#34; 1.txt 2.txt [main 787cfc9] change: 1.txt, 2.txt 2 files changed, 2 insertions(+) $ git log commit 787cfc91428a9be730e97e103b00e2bfe59e671c (HEAD -\u0026gt; main) Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:40:12 2024 +0800 change: 1.txt, 2.txt commit 984668dbca2b4d3dbf40aad117122bd737a735db Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:37:31 2024 +0800 add 1.txt, 2.txt and 3.txt 此时，发现 3.txt 忘记提交了，此时我们可以使用 $ git commit 再次提交，但此时会多出一次提交记录。\n我们可以使用 $ git commit --amend 提交暂存区中的文件，以及修改提交信息。\n$ git commit --amend [main 71cfcbd] change: 1.txt, 2.txt and 3.txt Date: Sun Aug 4 16:40:12 2024 +0800 3 files changed, 3 insertions(+) 通过查看 git log，此时只有一次修改的记录，上一个修改记录被覆盖掉了。\n$ git log commit 82911668c9d16c8c85e636ecc7d4cd717d0ab9f0 (HEAD -\u0026gt; main) Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:40:12 2024 +0800 change: 1.txt, 2.txt and 3.txt commit 984668dbca2b4d3dbf40aad117122bd737a735db Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:37:31 2024 +0800 add 1.txt, 2.txt and 3.txt 取消暂存的文件 # 已经修改了两个文件并且想要将它们作为两次独立的修改提交，但是却意外地输入了 $ git add * 暂存了它们两个。如何只取消暂存两个中的一个呢？\n$ git status On branch main Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: 1.txt modified: 2.txt no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 我们可以使用 $ git restore --staged 将文件从暂存区移除，但保留工作区中的更改。\n$ git restore --staged 2.txt (base) leon@Inspiron7590:~/Projects/demo$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: 1.txt Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: 2.txt 撤消对文件的修改 # 如果你并不想保留对文件的修改怎么办？你该如何方便地撤消修改,将它还原成上次提交时的样子（或者刚克隆完的样子，或者刚把它放入工作目录时的样子）？\n$ git status On branch main Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: README no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 我们可以直接使用 $ git restore 命令。可以看到 README 文件的修改已被撤销。\n$ git restore README $ git status On branch main nothing to commit, working tree clean "},{"id":5,"href":"/docs/MyBatis/SqlSession/","title":"SqlSession","section":"MyBatis","content":" SqlSession # SalSession 是用于操作数据库的接口，具体的操作都通过此接口。\nSqlSessionFactoryBuilder # 此类可以被实例化、使用和丢弃，一旦使用此类创建了 SqlSessionFactory，后续就不需要使用此类了。因此 SqlSessionFactoryBuilder 实例的最佳作用域是方法作用域（也就是局部方法变量）。\n可以重用 SqlSessionFactoryBuilder 来创建多个 SqlSessionFactory 实例，但最好还是不要一直保留着它，以保证 XML 资源可以被释放。\nSqlSessionFactory # SqlSessionFactory 一旦被创建就应该在应用的运行期间一直存在，没有任何理由丢弃它或重新创建另一个实例。使用 SqlSessionFactory 的最佳实践是在应用运行期间只创建一次。\nSqlSessionFactory 的作用是为了创建 SqlSession 实例。SqlSession 是 MyBatis 执行 SQL 命令的核心接口，通过此实例可以对数据库进行查询、插入、更新和删除操作。\nimport java.sql.Connection; /** * Creates an {@link SqlSession} out of a connection or a DataSource * * @author Clinton Begin */ public interface SqlSessionFactory { SqlSession openSession(); SqlSession openSession(boolean autoCommit); SqlSession openSession(Connection connection); SqlSession openSession(TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType); SqlSession openSession(ExecutorType execType, boolean autoCommit); SqlSession openSession(ExecutorType execType, TransactionIsolationLevel level); SqlSession openSession(ExecutorType execType, Connection connection); Configuration getConfiguration(); } SqlSessionFactory 主要有两个具体的实现：\nDefaultSqlSessionFactory： SqlSessionManager： DefaultSqlSessionFactory # DefaultSqlSessionFactory 是用于获取 SqlSession 的工厂类。\n有下边两种创建 SqlSession 的具体实现：\nprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx = null; try { final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(\u0026#34;Error opening session. Cause: \u0026#34; + e, e); } finally { ErrorContext.instance().reset(); } } private SqlSession openSessionFromConnection(ExecutorType execType, Connection connection) { try { boolean autoCommit; try { autoCommit = connection.getAutoCommit(); } catch (SQLException e) { // Failover to true, as most poor drivers // or databases won\u0026#39;t support transactions autoCommit = true; } final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); final Transaction tx = transactionFactory.newTransaction(connection); final Executor executor = configuration.newExecutor(tx, execType); return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { throw ExceptionFactory.wrapException(\u0026#34;Error opening session. Cause: \u0026#34; + e, e); } finally { ErrorContext.instance().reset(); } } SqlSessionManager # SqlSessionManager 内部保存了一个 ThreadLocal 用于保存 SqlSession。\npublic class SqlSessionManager implements SqlSessionFactory, SqlSession { private final SqlSessionFactory sqlSessionFactory; private final SqlSession sqlSessionProxy; private final ThreadLocal\u0026lt;SqlSession\u0026gt; localSqlSession = new ThreadLocal\u0026lt;\u0026gt;(); private SqlSessionManager(SqlSessionFactory sqlSessionFactory) { this.sqlSessionFactory = sqlSessionFactory; this.sqlSessionProxy = (SqlSession) Proxy.newProxyInstance(SqlSessionFactory.class.getClassLoader(), new Class[] { SqlSession.class }, new SqlSessionInterceptor()); } } sqlSessionProxy 是通过动态代理代理的类，当获取 SqlSession 时，会先从 localSqlSession 中获取，如果不存在才新建 SqlSession。\nprivate class SqlSessionInterceptor implements InvocationHandler { public SqlSessionInterceptor() { // Prevent Synthetic Access } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { final SqlSession sqlSession = SqlSessionManager.this.localSqlSession.get(); if (sqlSession != null) { try { return method.invoke(sqlSession, args); } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } } try (SqlSession autoSqlSession = openSession()) { try { final Object result = method.invoke(autoSqlSession, args); autoSqlSession.commit(); return result; } catch (Throwable t) { autoSqlSession.rollback(); throw ExceptionUtil.unwrapThrowable(t); } } } } 当使用 startManagedSession 方法时，会新建一个 SqlSession，并保存到 localSqlSession 中。\npublic void startManagedSession() { this.localSqlSession.set(openSession()); } 所有操作都会通过 sqlSessionProxy 进行代理，复用同一个 SqlSession。\n@Override public \u0026lt;T\u0026gt; T selectOne(String statement) { return sqlSessionProxy.selectOne(statement); } 下图中的操作和上边一样，同样会经过 sqlSessionProxy 进行代理。\nSqlSession # 每个线程都应该有自己的 SqlSession 实例，SqlSession 实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。\nSqlSession 继承了 Closeable 接口，下边是使用 SqlSession 的最佳实践：\ntry (SqlSession session = sqlSessionFactory.openSession()) { // 你的应用逻辑代码 } "},{"id":6,"href":"/docs/system-programming/network-byte-order/","title":"网络字节序","section":"Linux 网络编程","content":" 网络字节序 # 大小端 # 不同架构的 CPU 中，4 字节整数 1 在内存中存储的方式是不同的。\n大端序（big endian）：最高位有效字节存储在低内存地址，而最低位有效字节存储在高内存地址。 小端序（little endian）：最高位有效字节存储在高内存地址，而最低位有效字节存储在低内存地址。 对于一个 4 字节整数 0x01020304，大小端序存储方式分别如下：\n地址: 0 1 2 3 （大端序保存） 01 02 03 04 地址: 0 1 2 3 （小端序保存） 04 03 02 01 可以使用下边的方法判断机器的字节序：\n通过 endian.h 提供的 BYTE_ORDER 宏。 #include \u0026lt;endian.h\u0026gt; bool big_endian() { return BYTE_ORDER == BIG_ENDIAN; } bool little_endian() { return BYTE_ORDER == LITTLE_ENDIAN; } 将 uint16_t 类型的数字转为 char *，通过高字节和低字节进行判断。 bool big_endian() { uint16_t val = 0x0102; return ((char *) (\u0026amp;val))[0] == 0x01; } bool little_endian() { uint16_t val = 0x0102; return ((char *) (\u0026amp;val))[1] == 0x01; } 和方法 2 类似，利用的是 union 相同的内存位置存储不同的数据类型。 union endian { uint16_t val; char bytes[2]; }; bool big_endian() { union endian en{}; en.val = 0x0102; return en.bytes[0] == 0x01; } bool little_endian() { union endian en{}; en.val = 0x0102; return en.bytes[0] == 0x02; } 为什么有两种不同的字节序？\n大端序是人类最熟悉的读写方法，从左向右处理。\n小端序更利于计算机处理，因为计算都是从低位开始的，先处理低位字节，效率比较高。\n网络字节序 # 如果通信双方采用不同的架构，收发数据后进行解析时会发生问题。如：大端序机器 A 发送 0x01020304 到小端序机器 B 时，B 以小端序方式解析该数字为 0x04030201。\n为解决上边问题，网络传输数据时，通信双方需要约定统一方式，把此约定叫做网络字节序（network byte order）。\n网络字节序规定使用大端序，大多数网络协议（例如 TCP/IP 协议族）规定了网络字节序采用大端序。\n因此，小端序发送数据时，需要先转为大端序。\n字节序转换 # 下边函数用于字节序的相互转换：\n#include \u0026lt;arpa/inet.h\u0026gt; uint32_t htonl(uint32_t hostlong); uint16_t htons(uint16_t hostshort); uint32_t ntohl(uint32_t netlong); uint16_t ntohs(uint16_t netshort); 函数名中的 h 表示主机（host）字节序，n 表示网络（network）字节序；s 表示 short 类型，l 表示 long 类型。\n"},{"id":7,"href":"/docs/Netty/ByteBuf/","title":"ByteBuf","section":"Netty","content":" ByteBuf # 基本结构 # +-------------------+------------------+------------------+-------------+ | discardable bytes | readable bytes | writable bytes | ... | | | (CONTENT) | | | +-------------------+------------------+------------------+-------------+ | | | | | 0 \u0026lt;= readerIndex \u0026lt;= writerIndex \u0026lt;= capacity maxCapacity 相关操作 # 有些方法会返回 this，以支持链式调用。\n容量 # ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); int capacity = buf.capacity();// 获取当前的容量 int maxCapacity = buf.maxCapacity();// 支持的最大容量，通常为 Integer.MAX_VALUE int readableBytes = buf.readableBytes();// writerIndex - readerIndex int writableBytes = buf.writableBytes();// capacity - writerIndex boolean readable; readable = buf.isReadable(8);// isReadable(int), writerIndex - readerIndex \u0026gt;= size readable = buf.isReadable();// 相当于 isReadable(1) boolean writable; writable = buf.isWritable(8); // isWritable(int), capacity - writerIndex \u0026gt;= size writable = buf.isWritable(); // 相当于 isWritable(1) int maxWritableBytes = buf.maxWritableBytes();// maxCapacity - writerIndex 读写 # readType() 用于读取 Type 类型的数据，writeType() 用于写入 Type 类型的值。\n与 readType() 类似的有 getType()，与 writeType() 类似的有 setType()。唯一的区别是 getType() 和 setType() 不会改变读写指针，而 readType() 和 writeType()会改变读写指针。\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); boolean booleanV = true; buf.writeBoolean(booleanV); // 8-bit buf.readBoolean(); byte byteV = 0; buf.writeByte(byteV); // 8-bit buf.readByte(); short shortV = 0; buf.writeShort(shortV); // 16-bit buf.readShort(); int mediumV = 0; buf.writeMedium(mediumV); // 24-bit buf.readMedium(); int intV = 0; buf.writeInt(intV); // 32-bit buf.readInt(); long longV = 0; buf.writeLong(longV); // 64-bit buf.readLong(); char charV = 0; buf.writeChar(charV); // 8-bit buf.readChar(); float floatV = 0; buf.writeFloat(floatV); // 32-bit buf.readFloat(); double doubleV = 0.0; buf.writeDouble(doubleV); // 64-bit buf.readDouble(); byte[] bytes = new byte[]{0, 1, 2, 3, 4, 5, 6}; // 等价于 buf.writeBytes(bytes, 0, bytes.length) buf.writeBytes(bytes); // 从 `bytes` 的 `srcIndex` 处读取`length` 字节，写入到 `buf` buf.writeBytes(bytes, 1, 3); byte[] bytesDestination = new byte[8]; buf.readBytes(bytesDestination); ByteBuf originalBuf = ByteBufAllocator.DEFAULT.buffer(); // 等价于 buf.writeBytes(originalBuf, originalBuf.readableBytes()) buf.writeBytes(originalBuf); // 等价于 buf.writeBytes(originalBuf, originalBuf.readerIndex(), 3); buf.writeBytes(originalBuf, 3); // 从 `originalBuf` 的 `srcIndex` 处读取`length` 字节，写入到 `buf` buf.writeBytes(originalBuf, 1, 3); ByteBuf bufDestination = ByteBufAllocator.DEFAULT.buffer(); buf.readBytes(bufDestination); 派生 # duplicate() slice() slice(int, int) readSlice(int) retainedDuplicate() retainedSlice() retainedSlice(int, int) readRetainedSlice(int) 读写指针 # ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); int readerIndex = buf.readerIndex(); // 获取当前读指针位置 int writerIndex = buf.writerIndex(); // 获取当前写指针位置 buf.readerIndex(0); // readerIndex(int)，设置读指针位置 buf.writerIndex(0); // writerIndex(int)，设置写指针位置 buf.markReaderIndex(); // 记录当前读指针位置 // do something buf.resetReaderIndex(); // 恢复到之前 mark 的读指针位置 buf.markWriterIndex(); // 记录当前写指针位置 // do something buf.resetWriterIndex(); // 恢复到之前 mark 的写指针位置 丢弃字节 # ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); System.out.println(buf); // PooledUnsafeDirectByteBuf(ridx: 0, widx: 0, cap: 256) for (int i = 0; i \u0026lt; 16; i++) { buf.writeInt(i); } for (int i = 0; i \u0026lt; 8; i++) { buf.readInt(); } System.out.println(buf); // PooledUnsafeDirectByteBuf(ridx: 32, widx: 64, cap: 256) buf.discardReadBytes(); System.out.println(buf); // PooledUnsafeDirectByteBuf(ridx: 0, widx: 32, cap: 256) 调用 discardReadBytes() 丢弃 0 ~ readerIndex 之间的字节。将 readerIndex 和 writerIndex 之间的字节移动到第 0 个索引，并将 readerIndex 和 writerIndex 分别设置为 0 和 oldWriterIndex - oldReaderIndex。\nBEFORE discardReadBytes() +-------------------+------------------+------------------+ | discardable bytes | readable bytes | writable bytes | +-------------------+------------------+------------------+ | | | | 0 \u0026lt;= readerIndex \u0026lt;= writerIndex \u0026lt;= capacity AFTER discardReadBytes() +------------------+--------------------------------------+ | readable bytes | writable bytes (got more space) | +------------------+--------------------------------------+ | | | readerIndex (0) \u0026lt;= writerIndex (decreased) \u0026lt;= capacity 也可以调用 clear() 方法，当调用后会直接将 readerIndex 和 writerIndex 同时设为 0。\nBEFORE clear() +-------------------+------------------+------------------+ | discardable bytes | readable bytes | writable bytes | +-------------------+------------------+------------------+ | | | | 0 \u0026lt;= readerIndex \u0026lt;= writerIndex \u0026lt;= capacity AFTER clear() +---------------------------------------------------------+ | writable bytes (got more space) | +---------------------------------------------------------+ | | 0 = readerIndex = writerIndex \u0026lt;= capacity ByteBufHolder # ByteBufHolder 可用于封装 ByteBuf 数据，可用于存储消息对象。\n分类 # Heap 和 Direct # Heap 底层使用 byte[]。\nDirect 底层使用 java.nio.ByteBuffer。\nPooled 和 Unpooled # 池化和非池化的区别，Netty 维护者（Norman Maurer）的 回答：\nThe difference is that with unpooled Netty will allocate a new buffer everytime you call ByteBufAllocator.buffer which comes with some overhead, especially with direct buffers. When you use pooled Netty will try to pool the buffers and so minimize the overhead of allocation and releasing of buffers. Safe 和 Unsafe # Unsafe 的 ByteBuf 会使用 sun.misc.Unsafe 直接申请内存。\nAbstractByteBuf # AbstractByteBuf 是 buffer 的基本骨架，提供了基本的操作。\n类中共有 4 个 *Index 和 1 个指定最大容量的字段 maxCapacity。\nint readerIndex; int writerIndex; private int markedReaderIndex; private int markedWriterIndex; private int maxCapacity; readerIndex 和 writerIndex 分别指定当前读入和写入的位置，当调用 read* 和 write* 方法时会修改位置，而 get* 和 set* 方法不会。\nmarkedReaderIndex 和 markedWriterIndex 用于标注当前的位置，默认值为 0。调用 markReaderIndex() 和 markWriterIndex() 方法用于标记当前读入和写入的位置。\n当调用 resetReaderIndex() 和 resetWriterIndex() 方法时，会将当前的 readerIndex 和 writerIndex 设置为 markedReaderIndex 和 markedWriterIndex。\npublic ByteBuf resetReaderIndex() { readerIndex(markedReaderIndex); return this; } public ByteBuf resetWriterIndex() { writerIndex(markedWriterIndex); return this; } 可读可写只需要判断 writerIndex 和 readerIndex 的相对位置即可。\npublic boolean isReadable() { return writerIndex \u0026gt; readerIndex; } public boolean isWritable() { return capacity() \u0026gt; writerIndex; } public int readableBytes() { return writerIndex - readerIndex; } public int writableBytes() { return capacity() - writerIndex; } ByteBufAllocator # 继承关系 # 默认 Allocator # ByteBufAllocator 类中的 DEFAULT 指定 Netty 使用的 Allocator。\npublic interface ByteBufAllocator { ByteBufAllocator DEFAULT = ByteBufUtil.DEFAULT_ALLOCATOR; } ByteBufUtil 类通过获取系统变量确认默认的 ByteBufAllocator，默认使用 PooledByteBufAllocator 类。\n可以通过 java -Dio.netty.allocator.type: {unpooled|pooled} 指定。\npublic final class ByteBufUtil { ... static final ByteBufAllocator DEFAULT_ALLOCATOR; static { String allocType = SystemPropertyUtil.get( \u0026#34;io.netty.allocator.type\u0026#34;, PlatformDependent.isAndroid() ? \u0026#34;unpooled\u0026#34; : \u0026#34;pooled\u0026#34;); allocType = allocType.toLowerCase(Locale.US).trim(); ByteBufAllocator alloc; if (\u0026#34;unpooled\u0026#34;.equals(allocType)) { alloc = UnpooledByteBufAllocator.DEFAULT; logger.debug(\u0026#34;-Dio.netty.allocator.type: {}\u0026#34;, allocType); } else if (\u0026#34;pooled\u0026#34;.equals(allocType)) { alloc = PooledByteBufAllocator.DEFAULT; logger.debug(\u0026#34;-Dio.netty.allocator.type: {}\u0026#34;, allocType); } else { alloc = PooledByteBufAllocator.DEFAULT; logger.debug(\u0026#34;-Dio.netty.allocator.type: pooled (unknown: {})\u0026#34;, allocType); } DEFAULT_ALLOCATOR = alloc; } ... } 内存回收 # Netty 使用引用计数方法对 ByteBuf 进行回收。实现 ReferenceCounted 的实例开始时的引用计数为 1，只要引用计数大于 0，就能保证对象不会被释放。当引用计数减少到 0 时，该实例就会被释放。\nUnpooledHeapByteBuf 使用的是 JVM 内存，只需等 GC 回收即可。 UnpooledDirectByteBuf 使用了直接内存， 扩容逻辑 # 当向 ByteBuf 写入数据，而容量不足时（writerIndex \u0026gt; capacity()），会自动进行扩容。\n每次调用 write*() 时，方法内部会调用 ensureWritable0() 确保有足够的空间。\n调用 ensureWritable0() 时会传入 minWritableBytes 参数，确保有足够的字节数，调用 writeLong() 时，会被设为 8。\npublic abstract class AbstractByteBuf extends ByteBuf { ... public ByteBuf writeInt(int value) { ensureWritable0(4); _setInt(writerIndex, value); writerIndex += 4; return this; } ... } ensureWritable0 # ensureWritable0() 进行扩容的代码如下：\n获取当前的写入索引（writerIndex），并计算目标容量（targetCapacity），即当前写入索引加上要写入的最小字节数。 使用非短路逻辑与运算符（\u0026amp;）来检查目标容量是否在合理范围内。这里选择使用非短路逻辑与运算符是为了减少分支，因为该代码段通常是一个热点路径，并且目标容量很少会溢出。如果目标容量在合理范围内，则表示缓冲区已经有足够的空间，直接返回。 如果启用了边界检查（checkBounds），并且目标容量小于 0 或者大于最大容量（maxCapacity），则抛出索引越界异常。 如果目标容量不在合理范围内，需要增加缓冲区的容量。首先，调用 maxFastWritableBytes() 方法获取一个快速可写入的字节数，然后根据这个字节数和传入的最小可写入字节数来计算新的容量。如果快速可写入字节数大于等于传入的最小可写入字节数，则新容量直接设定为当前写入索引加上快速可写入字节数，否则通过调用 calculateNewCapacity 方法来计算新容量。 通过调用 capacity(newCapacity) 方法来调整缓冲区的容量，确保其足够可写入。 public abstract class AbstractByteBuf extends ByteBuf { ... final void ensureWritable0(int minWritableBytes) { final int writerIndex = writerIndex(); final int targetCapacity = writerIndex + minWritableBytes; // using non-short-circuit \u0026amp; to reduce branching - this is a hot path and targetCapacity should rarely overflow if (targetCapacity \u0026gt;= 0 \u0026amp; targetCapacity \u0026lt;= capacity()) { ensureAccessible(); return; } if (checkBounds \u0026amp;\u0026amp; (targetCapacity \u0026lt; 0 || targetCapacity \u0026gt; maxCapacity)) { ensureAccessible(); throw new IndexOutOfBoundsException(String.format( \u0026#34;writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s\u0026#34;, writerIndex, minWritableBytes, maxCapacity, this)); } // Normalize the target capacity to the power of 2. final int fastWritable = maxFastWritableBytes(); int newCapacity = fastWritable \u0026gt;= minWritableBytes ? writerIndex + fastWritable : alloc().calculateNewCapacity(targetCapacity, maxCapacity); // Adjust to the new capacity. capacity(newCapacity); } ... } calculateNewCapacity # calculateNewCapacity 计算新的容量时的思路总结如下：\nminNewCapacity 参数为最小申请的容量，检查传入的 minNewCapacity 参数是否为非负数，如果不是，则抛出异常。 检查 minNewCapacity 是否超过了最大容量 maxCapacity，如果超过了，则抛出异常。 设定一个阈值 threshold，表示页面大小为 4 MiB。 minNewCapacity 等于阈值 threshold，则直接返回阈值，不再需要进行容量的调整。 minNewCapacity 大于阈值 threshold，则按照阈值为单位递增容量。在这种情况下，新容量的计算方式不再是简单的翻倍增加，而是以阈值为单位递增。 minNewCapacity 小于等于阈值 threshold 时，则将 minNewCapacity 设置为大于等于 64 的最接近的 2 的幂，以确保足够的容量同时尽量减小内存的浪费。 返回新容量和最大容量中较小的一个值，以确保新容量不会超过最大容量限制。 public abstract class AbstractByteBufAllocator implements ByteBufAllocator { ... public int calculateNewCapacity(int minNewCapacity, int maxCapacity) { checkPositiveOrZero(minNewCapacity, \u0026#34;minNewCapacity\u0026#34;); if (minNewCapacity \u0026gt; maxCapacity) { throw new IllegalArgumentException(String.format( \u0026#34;minNewCapacity: %d (expected: not greater than maxCapacity(%d)\u0026#34;, minNewCapacity, maxCapacity)); } final int threshold = CALCULATE_THRESHOLD; // 4 MiB page if (minNewCapacity == threshold) { return threshold; } // If over threshold, do not double but just increase by threshold. if (minNewCapacity \u0026gt; threshold) { int newCapacity = minNewCapacity / threshold * threshold; if (newCapacity \u0026gt; maxCapacity - threshold) { newCapacity = maxCapacity; } else { newCapacity += threshold; } return newCapacity; } // 64 \u0026lt;= newCapacity is a power of 2 \u0026lt;= threshold final int newCapacity = MathUtil.findNextPositivePowerOfTwo(Math.max(minNewCapacity, 64)); return Math.min(newCapacity, maxCapacity); } ... } "},{"id":8,"href":"/docs/ProGit/Git-%E5%88%86%E6%94%AF/","title":"Git 分支","section":"Pro Git","content":" Git 分支 # 分支创建 # 使用 $ git branch 命令后，会在当前所在的提交对象上创建一个指针。此操作并不会直接切换到新创建的分支上。\n那么，Git 又是怎么知道当前在哪一个分支上呢？有一个名为 HEAD 的特殊指针，指向当前分支。\n$ git branch testing 分支切换 # 要切换到一个已存在的分支，需要使用 $ git switch 命令。\n$ git switch testing 这样 HEAD 就指向 testing 分支了。\n分支合并 # testing 分支提交 # $ touch 1.txt $ git commit -a -m \u0026#39;add: 1.txt\u0026#39; master 分支提交 # $ git switch master $ touch 2.txt $ git commit -a -m \u0026#39;add: 2.txt\u0026#39; 合并 # 使用 $ git merge 即可将 testing 分支中的内容合并到 master 分支中。\n$ git merge testing "},{"id":9,"href":"/docs/MyBatis/Mapper/","title":"Mapper","section":"MyBatis","content":" Mapper # MapperRegistry # MapperRegistry 是 Mapper 接口及其对应的代理对象工厂的注册中心。\nConfiguration 是 MyBatis 全局性的配置对象，在 MyBatis 初始化的过程中，所有配置信息会被解析成相应的对象并记录到 Configuration 对象中。\nknownMappers # MapperRegistry 类中的 knownMappers 用做具体保存。\nkey 是 Mapper 接口对应的 Class 对象，value 为 MapperProxyFactory 工厂对象。\nprivate final Map\u0026lt;Class\u0026lt;?\u0026gt;, MapperProxyFactory\u0026lt;?\u0026gt;\u0026gt; knownMappers = new ConcurrentHashMap\u0026lt;\u0026gt;(); addMapper # addMapper 会将接口类和包装后的对象放入到 knownMappers 对象中。\npublic \u0026lt;T\u0026gt; void addMapper(Class\u0026lt;T\u0026gt; type) { if (type.isInterface()) { if (hasMapper(type)) { throw new BindingException(\u0026#34;Type \u0026#34; + type + \u0026#34; is already known to the MapperRegistry.\u0026#34;); } boolean loadCompleted = false; try { knownMappers.put(type, new MapperProxyFactory\u0026lt;\u0026gt;(type)); // It\u0026#39;s important that the type is added before the parser is run // otherwise the binding may automatically be attempted by the // mapper parser. If the type is already known, it won\u0026#39;t try. MapperAnnotationBuilder parser = new MapperAnnotationBuilder(config, type); parser.parse(); loadCompleted = true; } finally { if (!loadCompleted) { knownMappers.remove(type); } } } } getMapper # 当使用 SqlSession 类中的 \u0026lt;T\u0026gt; T getMapper(Class\u0026lt;T\u0026gt; type); 方法获取 Mapper 时，会转发到 MapperRegistry 的 getMapper 方法进行具体处理。\n@SuppressWarnings(\u0026#34;unchecked\u0026#34;) public \u0026lt;T\u0026gt; T getMapper(Class\u0026lt;T\u0026gt; type, SqlSession sqlSession) { final MapperProxyFactory\u0026lt;T\u0026gt; mapperProxyFactory = (MapperProxyFactory\u0026lt;T\u0026gt;) knownMappers.get(type); if (mapperProxyFactory == null) { throw new BindingException(\u0026#34;Type \u0026#34; + type + \u0026#34; is not known to the MapperRegistry.\u0026#34;); } try { return mapperProxyFactory.newInstance(sqlSession); } catch (Exception e) { throw new BindingException(\u0026#34;Error getting mapper instance. Cause: \u0026#34; + e, e); } } MapperProxyFactory # mapperInterface # MapperProxyFactory 中的 mapperInterface 为 Mapper 接口类。\nnewInstance # newInstance 的返回值 T 为 Mapper 接口类型（JDK 动态代理需要配合接口使用）。\npublic class MapperProxyFactory\u0026lt;T\u0026gt; { private final Class\u0026lt;T\u0026gt; mapperInterface; private final Map\u0026lt;Method, MapperMethodInvoker\u0026gt; methodCache = new ConcurrentHashMap\u0026lt;\u0026gt;(); public MapperProxyFactory(Class\u0026lt;T\u0026gt; mapperInterface) { this.mapperInterface = mapperInterface; } public Class\u0026lt;T\u0026gt; getMapperInterface() { return mapperInterface; } public Map\u0026lt;Method, MapperMethodInvoker\u0026gt; getMethodCache() { return methodCache; } @SuppressWarnings(\u0026#34;unchecked\u0026#34;) protected T newInstance(MapperProxy\u0026lt;T\u0026gt; mapperProxy) { return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy); } public T newInstance(SqlSession sqlSession) { final MapperProxy\u0026lt;T\u0026gt; mapperProxy = new MapperProxy\u0026lt;\u0026gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); } } MapperProxy # MapperProxy 类是 MyBatis 中最重要的类之一，通过这个代理对象，MyBatis 能够在不显式编写实现类的情况下，将对 Mapper 接口的方法调用转换为相应的 SQL 查询，并执行这些查询。\ninvoke # 该类继承自 InvocationHandler 接口，通过重写 invoke 方法提供额外的逻辑。\npublic class MapperProxy\u0026lt;T\u0026gt; implements InvocationHandler, Serializable 如果执行的 method 为 Object 类的方法，则不进行动态代理，直接执行。\n@Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { if (Object.class.equals(method.getDeclaringClass())) { return method.invoke(this, args); } return cachedInvoker(method).invoke(proxy, method, args, sqlSession); } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } } cachedInvoker # 这个方法的主要功能是从 methodCache 缓存中获取或创建一个 MapperMethodInvoker，以优化调用 Mapper 接口方法的性能。\nJDK 1.8 在接口中引入了 default 方法，用于在具体类不提供该方法的实现的情况下，允许接口方法提供实现。\nMyBatis 对 default 方法进行了额外处理，根据是否为 default 方法进行不同的处理：\n不是 default 方法：使用 PlainMethodInvoker 类进行处理，需要交给数据库处理。 是 default 方法：使用 DefaultMethodInvoker 类进行处理，调用时，直接执行。 private MapperMethodInvoker cachedInvoker(Method method) throws Throwable { try { return MapUtil.computeIfAbsent(methodCache, method, m -\u0026gt; { if (!m.isDefault()) { return new PlainMethodInvoker(new MapperMethod(mapperInterface, method, sqlSession.getConfiguration())); } try { if (privateLookupInMethod == null) { return new DefaultMethodInvoker(getMethodHandleJava8(method)); } return new DefaultMethodInvoker(getMethodHandleJava9(method)); } catch (IllegalAccessException | InstantiationException | InvocationTargetException | NoSuchMethodException e) { throw new RuntimeException(e); } }); } catch (RuntimeException re) { Throwable cause = re.getCause(); throw cause == null ? re : cause; } } MethodHandles # MethodHandles 在 JDK 1.9 才引入 privateLookupIn 方法用于直接访问 private 方法。\n为了支持 JDK 1.8 之前的代码，下边的代码根据不同的 JDK 版本，设计了两种方式访问私有方法。\nstatic { Method privateLookupIn; try { privateLookupIn = MethodHandles.class.getMethod(\u0026#34;privateLookupIn\u0026#34;, Class.class, MethodHandles.Lookup.class); } catch (NoSuchMethodException e) { privateLookupIn = null; } privateLookupInMethod = privateLookupIn; Constructor\u0026lt;Lookup\u0026gt; lookup = null; if (privateLookupInMethod == null) { // JDK 1.8 try { lookup = MethodHandles.Lookup.class.getDeclaredConstructor(Class.class, int.class); lookup.setAccessible(true); } catch (NoSuchMethodException e) { throw new IllegalStateException( \u0026#34;There is neither \u0026#39;privateLookupIn(Class, Lookup)\u0026#39; nor \u0026#39;Lookup(Class, int)\u0026#39; method in java.lang.invoke.MethodHandles.\u0026#34;, e); } catch (Exception e) { lookup = null; } } lookupConstructor = lookup; } getMethodHandleJava9 # private MethodHandle getMethodHandleJava9(Method method) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException { final Class\u0026lt;?\u0026gt; declaringClass = method.getDeclaringClass(); return ((Lookup) privateLookupInMethod.invoke(null, declaringClass, MethodHandles.lookup())).findSpecial( declaringClass, method.getName(), MethodType.methodType(method.getReturnType(), method.getParameterTypes()), declaringClass); } getMethodHandleJava8 # private MethodHandle getMethodHandleJava8(Method method) throws IllegalAccessException, InstantiationException, InvocationTargetException { final Class\u0026lt;?\u0026gt; declaringClass = method.getDeclaringClass(); return lookupConstructor.newInstance(declaringClass, ALLOWED_MODES).unreflectSpecial(method, declaringClass); } MapperMethodInvoker # interface MapperMethodInvoker { Object invoke(Object proxy, Method method, Object[] args, SqlSession sqlSession) throws Throwable; } PlainMethodInvoker # private static class PlainMethodInvoker implements MapperMethodInvoker { private final MapperMethod mapperMethod; public PlainMethodInvoker(MapperMethod mapperMethod) { this.mapperMethod = mapperMethod; } @Override public Object invoke(Object proxy, Method method, Object[] args, SqlSession sqlSession) throws Throwable { return mapperMethod.execute(sqlSession, args); } } DefaultMethodInvoker # 用于处理接口中的 default 方法，直接使用 MethodHandle 执行即可。\nbindTo 将对象绑定到 MethodHandle 中，调用时就不需要传递对象了。\nprivate static class DefaultMethodInvoker implements MapperMethodInvoker { private final MethodHandle methodHandle; public DefaultMethodInvoker(MethodHandle methodHandle) { this.methodHandle = methodHandle; } @Override public Object invoke(Object proxy, Method method, Object[] args, SqlSession sqlSession) throws Throwable { return methodHandle.bindTo(proxy).invokeWithArguments(args); } } MapperMethod # MapperMethod 中封装了 Mapper 接口中对应方法的信息，以及对应 SQL 语句的信息。\nprivate final SqlCommand command; private final MethodSignature method; SqlCommand # SqlCommand 类中的 name 为 MappedStatement 的 id。\nprivate final String name; private final SqlCommandType type; type 为 SQL 的类型。\npublic enum SqlCommandType { UNKNOWN, INSERT, UPDATE, DELETE, SELECT, FLUSH } MethodSignature # MethodSignature 类中的属性保存了 Mapper 接口中方法的签名。\n通过不同的返回值，MyBatis 可以动态的返回不同类型的值。\nprivate final boolean returnsMany; private final boolean returnsMap; private final boolean returnsVoid; private final boolean returnsCursor; private final boolean returnsOptional; private final Class\u0026lt;?\u0026gt; returnType; private final String mapKey; private final Integer resultHandlerIndex; private final Integer rowBoundsIndex; private final ParamNameResolver paramNameResolver; execute # execute 方法会根据不同的 SqlCommandType 来动态选择执行。\npublic Object execute(SqlSession sqlSession, Object[] args) { Object result; switch (command.getType()) { case INSERT: { Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; } case UPDATE: { Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; } case DELETE: { Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; } case SELECT: if (method.returnsVoid() \u0026amp;\u0026amp; method.hasResultHandler()) { executeWithResultHandler(sqlSession, args); result = null; } else if (method.returnsMany()) { result = executeForMany(sqlSession, args); } else if (method.returnsMap()) { result = executeForMap(sqlSession, args); } else if (method.returnsCursor()) { result = executeForCursor(sqlSession, args); } else { Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); if (method.returnsOptional() \u0026amp;\u0026amp; (result == null || !method.getReturnType().equals(result.getClass()))) { result = Optional.ofNullable(result); } } break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException(\u0026#34;Unknown execution method for: \u0026#34; + command.getName()); } if (result == null \u0026amp;\u0026amp; method.getReturnType().isPrimitive() \u0026amp;\u0026amp; !method.returnsVoid()) { throw new BindingException(\u0026#34;Mapper method \u0026#39;\u0026#34; + command.getName() + \u0026#34;\u0026#39; attempted to return null from a method with a primitive return type (\u0026#34; + method.getReturnType() + \u0026#34;).\u0026#34;); } return result; } "},{"id":10,"href":"/docs/MyBatis/ResultSetHandler/","title":"ResultSetHandler","section":"MyBatis","content":" ResultSetHandler # MyBatis 会将 ResultSet 按照映射配置文件中定义的映射规则（例如 \u0026lt;resultMap\u0026gt; 节点和 resultType 属性等）映射成相应的对象。\n在 StatementHandler 接口执行完指定的 select 语句之后，会将查询得到的 ResultSet 交给 ResultSetHandler 完成映射处理。\nResultSetHandler 除了负责映射 select 语句查询得到的结果集，还会处理存储过程执行后的输出参数。\nDefaultResultSetHandler # ResultSetHandler 只有一个实现类 DefaultResultSetHandler。\npublic interface ResultSetHandler { \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; handleResultSets(Statement stmt) throws SQLException; \u0026lt;E\u0026gt; Cursor\u0026lt;E\u0026gt; handleCursorResultSets(Statement stmt) throws SQLException; void handleOutputParameters(CallableStatement cs) throws SQLException; } MultiQueries # JDBC # 为了同时执行多条查询语句，需要设置 allowMultiQueries=true。\nConnection conn = DriverManager.getConnection( \u0026#34;jdbc:mysql://localhost/db?allowMultiQueries=true\u0026#34;, \u0026#34;root\u0026#34;, \u0026#34;0987654321\u0026#34;); String sql = \u0026#34;\u0026#34;\u0026#34; SELECT * FROM `user`; SELECT * FROM `blog`; \u0026#34;\u0026#34;\u0026#34;; try (Statement stmt = conn.createStatement()) { stmt.execute(sql); int cnt = 0; ResultSet rs = stmt.getResultSet(); while (rs != null) { if (stmt.getMoreResults()) { rs = stmt.getResultSet(); } else { rs = null; } cnt++; } System.out.println(cnt); } 每一个查询语句会返回一个 ResultSet。上边的代码执行后，会返回两个 ResultSet。因此，cnt 的结果为 2（一共有两个 SELECT 查询）。\nMyBatis # MyBatis 可以把多个查询语句包装到一个查询语句中。\nhttps://github.com/mybatis/mybatis-3/issues/274\n\u0026lt;select id=\u0026#34;findAll\u0026#34;\u0026gt; SELECT * FROM `blog`; SELECT * FROM `user`; \u0026lt;/select\u0026gt; handleResultSets # @Override public List\u0026lt;Object\u0026gt; handleResultSets(Statement stmt) throws SQLException { ErrorContext.instance().activity(\u0026#34;handling results\u0026#34;).object(mappedStatement.getId()); final List\u0026lt;Object\u0026gt; multipleResults = new ArrayList\u0026lt;\u0026gt;(); int resultSetCount = 0; ResultSetWrapper rsw = getFirstResultSet(stmt); List\u0026lt;ResultMap\u0026gt; resultMaps = mappedStatement.getResultMaps(); int resultMapCount = resultMaps.size(); validateResultMapsCount(rsw, resultMapCount); while (rsw != null \u0026amp;\u0026amp; resultMapCount \u0026gt; resultSetCount) { ResultMap resultMap = resultMaps.get(resultSetCount); handleResultSet(rsw, resultMap, multipleResults, null); rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; } String[] resultSets = mappedStatement.getResultSets(); if (resultSets != null) { while (rsw != null \u0026amp;\u0026amp; resultSetCount \u0026lt; resultSets.length) { ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]); if (parentMapping != null) { String nestedResultMapId = parentMapping.getNestedResultMapId(); ResultMap resultMap = configuration.getResultMap(nestedResultMapId); handleResultSet(rsw, resultMap, null, parentMapping); } rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; } } return collapseSingleResultList(multipleResults); } "},{"id":11,"href":"/docs/MyBatis/StatementHandler/","title":"StatementHandler","section":"MyBatis","content":" StatementHandler # StatementHandler 接口中的功能很多，例如创建 Statement 对象，为 SQL 语句绑定实参，执行 select、insert、update、delete 等多种类型的 SQL 语句，批量执行 SQL 语句，将结果集映射成结果对象。\npublic interface StatementHandler { Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException; void parameterize(Statement statement) throws SQLException; void batch(Statement statement) throws SQLException; int update(Statement statement) throws SQLException; \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; query(Statement statement, ResultHandler resultHandler) throws SQLException; \u0026lt;E\u0026gt; Cursor\u0026lt;E\u0026gt; queryCursor(Statement statement) throws SQLException; BoundSql getBoundSql(); ParameterHandler getParameterHandler(); } prepare：从 Connection 中创建 Statement 对象。 parameterize：绑定 statement 执行时需要的参数。 batch：批量执行 SQL 语句。 update：执行 insert、update 和 delete 操作。 query 和 queryCursor：用于执行 select 操作。 getBoundSql：获取绑定的 SQL。 getParameterHandler：负责处理 SQL 语句中的参数的处理器。 BaseStatementHandler # prepare # BaseStatementHandler 中设计了模板方法 prepare，通过该方法可以获取 Statement 对象。\n@Override public Statement prepare(Connection connection, Integer transactionTimeout) throws SQLException { ErrorContext.instance().sql(boundSql.getSql()); Statement statement = null; try { statement = instantiateStatement(connection); setStatementTimeout(statement, transactionTimeout); setFetchSize(statement); return statement; } catch (SQLException e) { closeStatement(statement); throw e; } catch (Exception e) { closeStatement(statement); throw new ExecutorException(\u0026#34;Error preparing statement. Cause: \u0026#34; + e, e); } } protected abstract Statement instantiateStatement(Connection connection) throws SQLException; 参数和结果处理组件 # BaseStatementHandler 依赖两个重要的组件，它们分别是 ParameterHandler 和 ResultSetHandler。\nParameterHandler：BoundSql 中记录的 SQL 语句可能包含 ? 占位符，每个 ? 都对应了 BoundSql 中 parameterMappings 集合中的一个元素，在该 ParameterMapping 对象中记录了对应的参数名称以及该参数的相关属性。ParameterHandler 负责调用 PreparedStatement 的一系列 set*() 方法为 SQL 语句绑定实参。 ResultSetHandler：用于将查询到的 ResultSet 进行处理，转为 model。 RoutingStatementHandler # RoutingStatementHandler 内部会根据 StatementType 创建不同的处理对象。\n后续该类的所有操作都会转发到 delegate 对象上进行处理。\nprivate final StatementHandler delegate; public RoutingStatementHandler(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) { switch (ms.getStatementType()) { case STATEMENT: delegate = new SimpleStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case PREPARED: delegate = new PreparedStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; case CALLABLE: delegate = new CallableStatementHandler(executor, ms, parameter, rowBounds, resultHandler, boundSql); break; default: throw new ExecutorException(\u0026#34;Unknown statement type: \u0026#34; + ms.getStatementType()); } } SimpleStatementHandler # SimpleStatementHandler 中重写的 instantiateStatement 方法会直接使用 connection.createStatement(); 创建一个 Statement 实例。\n@Override protected Statement instantiateStatement(Connection connection) throws SQLException { if (mappedStatement.getResultSetType() == ResultSetType.DEFAULT) { return connection.createStatement(); } return connection.createStatement(mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); } 该对象上的所有操作都会直接通过 java.sql.Statement 对象来完成数据库的所有操作。\n@Override public int update(Statement statement) throws SQLException { String sql = boundSql.getSql(); Object parameterObject = boundSql.getParameterObject(); KeyGenerator keyGenerator = mappedStatement.getKeyGenerator(); int rows; if (keyGenerator instanceof Jdbc3KeyGenerator) { statement.execute(sql, Statement.RETURN_GENERATED_KEYS); rows = statement.getUpdateCount(); keyGenerator.processAfter(executor, mappedStatement, statement, parameterObject); } else if (keyGenerator instanceof SelectKeyGenerator) { statement.execute(sql); rows = statement.getUpdateCount(); keyGenerator.processAfter(executor, mappedStatement, statement, parameterObject); } else { statement.execute(sql); rows = statement.getUpdateCount(); } return rows; } @Override public void batch(Statement statement) throws SQLException { String sql = boundSql.getSql(); statement.addBatch(sql); } @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; query(Statement statement, ResultHandler resultHandler) throws SQLException { String sql = boundSql.getSql(); statement.execute(sql); return resultSetHandler.handleResultSets(statement); } @Override public \u0026lt;E\u0026gt; Cursor\u0026lt;E\u0026gt; queryCursor(Statement statement) throws SQLException { String sql = boundSql.getSql(); statement.execute(sql); return resultSetHandler.handleCursorResultSets(statement); } PreparedStatementHandler # PreparedStatementHandler 依赖于 java.sql.PreparedStatement 对象完成对数据库的操作。\njava.sql.PreparedStatement 用于执行预编译的 SQL 语句，尤其适合于执行多次的 SQL 查询或更新操作。\n@Override protected Statement instantiateStatement(Connection connection) throws SQLException { String sql = boundSql.getSql(); if (mappedStatement.getKeyGenerator() instanceof Jdbc3KeyGenerator) { String[] keyColumnNames = mappedStatement.getKeyColumns(); if (keyColumnNames == null) { return connection.prepareStatement(sql, Statement.RETURN_GENERATED_KEYS); } else { return connection.prepareStatement(sql, keyColumnNames); } } if (mappedStatement.getResultSetType() == ResultSetType.DEFAULT) { return connection.prepareStatement(sql); } else { return connection.prepareStatement(sql, mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); } } CallableStatementHandler # CallableStatementHandler 依赖于 java.sql.CallableStatement 对象完成对数据库的操作。\njava.sql.CallableStatement 专门用于调用数据库中的存储过程或函数。\n@Override protected Statement instantiateStatement(Connection connection) throws SQLException { String sql = boundSql.getSql(); if (mappedStatement.getResultSetType() == ResultSetType.DEFAULT) { return connection.prepareCall(sql); } return connection.prepareCall(sql, mappedStatement.getResultSetType().getValue(), ResultSet.CONCUR_READ_ONLY); } "},{"id":12,"href":"/docs/JVM/ByteCode/constant_pool/","title":"常量池","section":"字节码","content":" 常量池 # 常量池是一个表，所有的表项都有以下的格式。tag 表示表项的类型，info 用于表示 tag 类型所需要存储的信息。\ncp_info { u1 tag; u1 info[]; } 常量池索引是从 1 开始的，不是直接从 0 开始。如果需要表达“不引用任何一个常量池项目”的含义，可以把索引值设置为 0 来表示。\n为什么设计常量池？ # 复用 # 常量池允许在类文件中共享常量数据。例如，字符串常量、类名、方法名和字段名等。可以避免了在类文件中多次存储相同的常量，从而减少类文件的大小。\n下边的代码，通过 $javac Main.java 编译后，使用 $javap -v Main.class 进行反编译。\npublic class Main { public static void main(String[] args) { String str = \u0026#34;Hello World!\u0026#34;; System.out.println(str); System.out.println(\u0026#34;Hello World!\u0026#34;); } } public class io.github.ileonli.Main minor version: 0 major version: 65 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #21 // io/github/ileonli/Main super_class: #2 // java/lang/Object interfaces: 0, fields: 0, methods: 2, attributes: 1 Constant pool: #1 = Methodref #2.#3 // java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #2 = Class #4 // java/lang/Object #3 = NameAndType #5:#6 // \u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #4 = Utf8 java/lang/Object #5 = Utf8 \u0026lt;init\u0026gt; #6 = Utf8 ()V #7 = String #8 // Hello World! #8 = Utf8 Hello World! #9 = Fieldref #10.#11 // java/lang/System.out:Ljava/io/PrintStream; #10 = Class #12 // java/lang/System #11 = NameAndType #13:#14 // out:Ljava/io/PrintStream; #12 = Utf8 java/lang/System #13 = Utf8 out #14 = Utf8 Ljava/io/PrintStream; #15 = Methodref #16.#17 // java/io/PrintStream.println:(Ljava/lang/String;)V #16 = Class #18 // java/io/PrintStream #17 = NameAndType #19:#20 // println:(Ljava/lang/String;)V #18 = Utf8 java/io/PrintStream #19 = Utf8 println #20 = Utf8 (Ljava/lang/String;)V #21 = Class #22 // io/github/ileonli/Main #22 = Utf8 io/github/ileonli/Main #23 = Utf8 Code #24 = Utf8 LineNumberTable #25 = Utf8 main #26 = Utf8 ([Ljava/lang/String;)V #27 = Utf8 SourceFile #28 = Utf8 Main.java { public io.github.ileonli.Main(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return LineNumberTable: line 3: 0 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: (0x0009) ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=2, args_size=1 0: ldc #7 // String Hello World! 2: astore_1 3: getstatic #9 // Field java/lang/System.out:Ljava/io/PrintStream; 6: aload_1 7: invokevirtual #15 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 10: getstatic #9 // Field java/lang/System.out:Ljava/io/PrintStream; 13: ldc #7 // String Hello World! 15: invokevirtual #15 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 18: return LineNumberTable: line 5: 0 line 6: 3 line 7: 10 line 8: 18 } 从 class 文件的反编译结果可以看出 main 方法中有大量的复用：\n0: ldc #7 和 13: ldc #7 使用 #7 来代替 Hello World! 字符串。 3: getstatic #9 和 10: getstatic #9 使用 #9 来代替 java/lang/System.out:Ljava/io/PrintStream; 变量。 7: invokevirtual #15 和 15: invokevirtual #15 使用 #15 来代替 java/io/PrintStream.println:(Ljava/lang/String;)V 方法。 符号引用 # JVM 中的指令并不依赖于运行时类、接口、类实例或数组的布局。相反，指令通过常量池表中的符号信息进行引用。\n这意味着 JVM 指令在运行时操作时，不需要直接处理类或对象的内存布局，而是通过常量池中的符号来找到所需的类、方法、字段等信息。\n如我们有个类 Example，其中有个方法为 printMesssage。在编译后的 class 文件中，常量池会有以下条目：\nCONSTANT_Class_info：表示 Example 类。 CONSTANT_NameAndType_info：表示 printMessage 方法的名字和类型。 CONSTANT_Methodref_info：表示 Example 类中的 printMessage 方法。 public class Example { public void printMessage() { System.out.println(\u0026#34;Hello, World!\u0026#34;); } } 使用 $javap -v Example.class 反编译得到的结果。\nJVM 指令例如 invokevirtual 会使用这些常量池条目来确定具体要调用的方法，而不是直接引用方法在内存中的地址。\npublic class io.github.ileonli.Example minor version: 0 major version: 65 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #21 // io/github/ileonli/Example super_class: #2 // java/lang/Object interfaces: 0, fields: 0, methods: 2, attributes: 1 Constant pool: #1 = Methodref #2.#3 // java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #2 = Class #4 // java/lang/Object #3 = NameAndType #5:#6 // \u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #4 = Utf8 java/lang/Object #5 = Utf8 \u0026lt;init\u0026gt; #6 = Utf8 ()V #7 = Fieldref #8.#9 // java/lang/System.out:Ljava/io/PrintStream; #8 = Class #10 // java/lang/System #9 = NameAndType #11:#12 // out:Ljava/io/PrintStream; #10 = Utf8 java/lang/System #11 = Utf8 out #12 = Utf8 Ljava/io/PrintStream; #13 = String #14 // Hello, World! #14 = Utf8 Hello, World! #15 = Methodref #16.#17 // java/io/PrintStream.println:(Ljava/lang/String;)V #16 = Class #18 // java/io/PrintStream #17 = NameAndType #19:#20 // println:(Ljava/lang/String;)V #18 = Utf8 java/io/PrintStream #19 = Utf8 println #20 = Utf8 (Ljava/lang/String;)V #21 = Class #22 // io/github/ileonli/Example #22 = Utf8 io/github/ileonli/Example #23 = Utf8 Code #24 = Utf8 LineNumberTable #25 = Utf8 printMessage #26 = Utf8 SourceFile #27 = Utf8 Example.java { public io.github.ileonli.Example(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return LineNumberTable: line 3: 0 public void printMessage(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #13 // String Hello, World! 5: invokevirtual #15 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 5: 0 line 6: 8 } 常量池项目类型 # 常量池中的表项共有下边几种：\nConstant Kind Tag Class File Format Java SE CONSTANT_Utf8 1 45.3 1.0.2 CONSTANT_Integer 3 45.3 1.0.2 CONSTANT_Float 4 45.3 1.0.2 CONSTANT_Long 5 45.3 1.0.2 CONSTANT_Double 6 45.3 1.0.2 CONSTANT_Class 7 45.3 1.0.2 CONSTANT_String 8 45.3 1.0.2 CONSTANT_Fieldref 9 45.3 1.0.2 CONSTANT_Methodref 10 45.3 1.0.2 CONSTANT_InterfaceMethodref 11 45.3 1.0.2 CONSTANT_NameAndType 12 45.3 1.0.2 CONSTANT_MethodHandle 15 51.0 7 CONSTANT_MethodType 16 51.0 7 CONSTANT_Dynamic 17 55.0 11 CONSTANT_InvokeDynamic 18 51.0 7 CONSTANT_Module 19 53.0 9 CONSTANT_Package 20 53.0 9 CONSTANT_Class_info # CONSTANT_Class_info 用于表示一个类，或者一个接口。\nname_index 为指向常量池表项的索引，该表项必须为 CONSTANT_Utf8_info。\nCONSTANT_Class_info { u1 tag; u2 name_index; } "},{"id":13,"href":"/docs/system-programming/address-families/","title":"网络地址族","section":"Linux 网络编程","content":" 网络地址族 # 网络地址 # 网络地址分为 IPv4 和 IPv6，分别使用 sockaddr_in 和 sockaddr_in6 结构体表示。\nsockaddr_in # struct sockaddr_in { sa_family_t sin_family; /* address family: AF_INET */ in_port_t sin_port; /* port in network byte order */ struct in_addr sin_addr; /* internet address */ /* Pad to size of `struct sockaddr\u0026#39;. */ unsigned char sin_zero[8]; }; /* Internet address */ struct in_addr { uint32_t s_addr; /* address in network byte order */ }; sin_family：在 IPv4 中设为 AF_INET。 sin_port：网络字节序保存的端口（0～65535）。 sin_addr：网络字节序保存的 32 位 IP 地址信息。 sin_zero：使 sockaddr_in 和 sockaddr 结构体大小保持一致而插入的填充位，需手动设为 0。 https://man7.org/linux/man-pages/man7/ip.7.html\nsockaddr_in6 # struct sockaddr_in6 { sa_family_t sin6_family; /* AF_INET6 */ in_port_t sin6_port; /* port number */ uint32_t sin6_flowinfo; /* IPv6 flow information */ struct in6_addr sin6_addr; /* IPv6 address */ uint32_t sin6_scope_id; /* Scope ID (new in Linux 2.4) */ }; struct in6_addr { unsigned char s6_addr[16]; /* IPv6 address */ }; sin6_family：在 IPv6 中总设为 AF_INET6。 sin6_port：网络字节序保存的端口（0～65535）。 sin6_flowinfo：IPv6 流信息（不广泛使用）。 sin6_addr：表示 IPv6 地址的结构体，定义为 struct in6_addr。 sin6_scope_id：范围标识符（用于链路本地和站点本地地址）。 https://man7.org/linux/man-pages/man7/ipv6.7.html\nin_addr 和 in6_addr # in_addr # 我们比较熟悉的 IPv4 地址表示方法为点分十进制表示法，如：201.123.235.213。\n而 in_addr 结构体使用 uint32_t 保存 IPv4 地址，我们需要将字符串形式的 IPv4 地址转为 32 位整数表示。\ninet_addr 函数可用于转换，该函数在转换的同时会进行网络字节序的转换。\ninet_ntoa 函数则相反，将 in_addr 结构体转为字符串。\n注意：inet_ntoa 函数返回的是一个指向静态缓冲区的指针，最好将返回值拷贝到其它地方，以免被覆盖。\n#include \u0026lt;arpa/inet.h\u0026gt; in_addr_t inet_addr(const char *cp); char *inet_ntoa(struct in_addr in); 也可以使用 inet_aton 函数，该函数将结果直接保存到传入的 inp 结构体中。\n#include \u0026lt;arpa/inet.h\u0026gt; int inet_aton(const char *cp, struct in_addr *inp); in6_addr # sockaddr_in5 结构体中的 in6_addr 结构体包含一个 unsigned char 类型的成员 s6_addr，用于存储 128 位的 IPv6 地址。\ninet_pton 函数中的 af 参数必须为 AF_INET 和 AF_INET6，分别处理 IPv4 和 IPv6 协议。\n#include \u0026lt;arpa/inet.h\u0026gt; int inet_pton(int af, const char *restrict src, void *restrict dst); const char *inet_ntop(int af, const void *restrict src, char dst[restrict .size], socklen_t size); 网络地址初始化 # IPv4 # #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; int main() { const char *address = \u0026#34;211.123.211.168\u0026#34;; // IP 地址 const char *port = \u0026#34;7890\u0026#34;; // 端口 struct sockaddr_in addr; memset(\u0026amp;addr, 0, sizeof(addr)); addr.sin_family = AF_INET; // IPv4; addr.sin_addr.s_addr = inet_addr(address); // 设置 IP 地址 addr.sin_port = htons(atoi(port)); // 以网络字节序设置端口 } IPv6 # #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; int main() { const char *address = \u0026#34;2001:0db8:85a3:0000:0000:8a2e:0370:7334\u0026#34;; // IPv6 地址 const char *port = \u0026#34;7890\u0026#34;; // 端口 struct sockaddr_in6 addr; memset(\u0026amp;addr, 0, sizeof(addr)); addr.sin6_family = AF_INET6; // IPv6 inet_pton(AF_INET6, address, \u0026amp;addr.sin6_addr); // 设置 IP 地址 addr.sin6_port = htons(atoi(port)); // 以网络字节序设置端口 } 思考 # 为什么 sockaddr_in 和 sockaddr_in6 分别表示 IPv4 和 IPv6 协议，还要额外使用 sa_family_t 指定协议版本呢？\n因为 connect、bind、和 accept 函数第二个参数都接收 sockaddr 结构体。因此，需要使用 sa_family 用于区分不同版本的协议。通过使用通用的 sockaddr 结构体，该函数不仅可以处理 IPv4 和 IPv6 协议，还可处理其它协议。这样，就不需要为每种协议都提供对应的函数。\nstruct sockaddr { sa_family_t sa_family; /* Address family */ char sa_data[]; /* Socket address */ }; "},{"id":14,"href":"/docs/Netty/EventLoop/","title":"EventLoop","section":"Netty","content":" EventLoop # 一旦注册，将处理 Channel 的所有 I/O 操作。一个 EventLoop 实例通常会处理多个 Channel，但这可能取决于实现细节和内部机制。\nEventLoop 本质是一个单线程执行器，同时维护了一个 Selector。\nEventLoop 由 Thread 驱动，且不会更改\ntry (EventLoop loop = new DefaultEventLoop()) { for (int i = 0; i \u0026lt; 3; i++) { loop.submit(() -\u0026gt; { for (int j = 0; j \u0026lt; 16; j++) { System.out.print(j + \u0026#34; \u0026#34;); } System.out.println(); }); } } 使用 EventLoop 的定时调度功能。\ntry (EventLoop loop = new DefaultEventLoop()) { ScheduledFuture\u0026lt;?\u0026gt; future = loop.schedule( () -\u0026gt; LocalDateTime.now(), 3, TimeUnit.SECONDS); System.out.println(future.get()); } 如果（当前）调用线程正是支撑 EventLoop 的线程，那么所提交的代码块将会被（直接）执行。否则，EventLoop 将调度该任务以便稍后执行，并将它放入到内部队列中。当\n如果必须要进行阻塞调用或者执行长时间运行的任务，我们建议使用一个专门的 EventExecutor。\n继承关系 # OrderedEventExecutor # 用于标记 EventExecutor 将以有序（ordered） / 串行（serial）的方式处理提交的任务。\npublic interface OrderedEventExecutor extends EventExecutor { } EventLoopGroup # next() 方法用于获取该 EventLoopGroup 中的下一个 EventLoop。 register() 将 Channel 注册到该 EventLoopGroup 中，只可以注册一次。 public interface EventLoopGroup extends EventExecutorGroup { @Override EventLoop next(); ChannelFuture register(Channel channel); ChannelFuture register(ChannelPromise promise); @Deprecated ChannelFuture register(Channel channel, ChannelPromise promise); } EventExecutor # EventExecutor 是一个特殊的 EventExecutorGroup，它提供了一些方便的方法来查看线程是否在事件循环中执行。除此之外，它还扩展了 EventExecutorGroup 以允许一种通用的方式来访问方法。\nnext() 返回自身。 parent() 返回所属的 EventExecutorGroup，没有则返回 null。 inEventLoop() 返回当前执行线程是否是 EventLoop 所绑定的线程。 public interface EventExecutor extends EventExecutorGroup { @Override EventExecutor next(); EventExecutorGroup parent(); boolean inEventLoop(); boolean inEventLoop(Thread thread); \u0026lt;V\u0026gt; Promise\u0026lt;V\u0026gt; newPromise(); \u0026lt;V\u0026gt; ProgressivePromise\u0026lt;V\u0026gt; newProgressivePromise(); \u0026lt;V\u0026gt; Future\u0026lt;V\u0026gt; newSucceededFuture(V result); \u0026lt;V\u0026gt; Future\u0026lt;V\u0026gt; newFailedFuture(Throwable cause); } EventExecutorGroup # EventExecutorGroup 负责通过它的 next() 方法提供 EventExecutor。除此之外，还负责处理生命周期，允许以全局方式关闭它们。\npublic interface EventExecutorGroup extends ScheduledExecutorService, Iterable\u0026lt;EventExecutor\u0026gt; { boolean isShuttingDown(); Future\u0026lt;?\u0026gt; shutdownGracefully(); Future\u0026lt;?\u0026gt; shutdownGracefully(long quietPeriod, long timeout, TimeUnit unit); Future\u0026lt;?\u0026gt; terminationFuture(); @Override @Deprecated void shutdown(); @Override @Deprecated List\u0026lt;Runnable\u0026gt; shutdownNow(); EventExecutor next(); @Override Iterator\u0026lt;EventExecutor\u0026gt; iterator(); @Override Future\u0026lt;?\u0026gt; submit(Runnable task); @Override \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Runnable task, T result); @Override \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task); @Override ScheduledFuture\u0026lt;?\u0026gt; schedule(Runnable command, long delay, TimeUnit unit); @Override \u0026lt;V\u0026gt; ScheduledFuture\u0026lt;V\u0026gt; schedule(Callable\u0026lt;V\u0026gt; callable, long delay, TimeUnit unit); @Override ScheduledFuture\u0026lt;?\u0026gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit); @Override ScheduledFuture\u0026lt;?\u0026gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit); } ScheduledExecutorService # 继承自 java.util.concurrent.ScheduledExecutorService 类。\nEventLoop 主要实现 # EventLoopGroup defaultGroup = new DefaultEventLoopGroup(); EventLoopGroup nioGroup = new NioEventLoopGroup(); # public abstract class SingleThreadEventExecutor extends AbstractScheduledEventExecutor implements OrderedEventExecutor { ... private void execute(Runnable task, boolean immediate) { boolean inEventLoop = inEventLoop(); addTask(task); if (!inEventLoop) { startThread(); if (isShutdown()) { boolean reject = false; try { if (removeTask(task)) { reject = true; } } catch (UnsupportedOperationException e) { // The task queue does not support removal so the best thing we can do is to just move on and // hope we will be able to pick-up the task before its completely terminated. // In worst case we will log on termination. } if (reject) { reject(); } } } if (!addTaskWakesUp \u0026amp;\u0026amp; immediate) { wakeup(inEventLoop); } } ... } 处理 I/O 事件 # "},{"id":15,"href":"/docs/MyBatis/Executor/","title":"Executor","section":"MyBatis","content":" Executor # SqlSession 中的具体操作都会通过 Executor 接口进行实现。\npublic class DefaultSqlSession implements SqlSession { ... private final Executor executor; ... } ExecutorType # Executor 一共有三种类型：\nSIMPLE： REUSE： BATCH： public enum ExecutorType { SIMPLE, REUSE, BATCH } BaseExecutor # BaseExecutor 是继承自 Executor 接口的抽象类。该类实现了 Executor 中的大部分方法。\n该类使用了模板方法模式，继承 BaseExecutor 的子类只需要实现下边的四个基本方法即可完成数据库的相关操作。\npublic abstract class BaseExecutor implements Executor { ... protected abstract int doUpdate(MappedStatement ms, Object parameter) throws SQLException; protected abstract List\u0026lt;BatchResult\u0026gt; doFlushStatements(boolean isRollback) throws SQLException; protected abstract \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException; protected abstract \u0026lt;E\u0026gt; Cursor\u0026lt;E\u0026gt; doQueryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds, BoundSql boundSql) throws SQLException; ... } SimpleExecutor # @Override public int doUpdate(MappedStatement ms, Object parameter) throws SQLException { Statement stmt = null; try { Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(this, ms, parameter, RowBounds.DEFAULT, null, null); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.update(stmt); } finally { closeStatement(stmt); } } @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException { Statement stmt = null; try { Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); stmt = prepareStatement(handler, ms.getStatementLog()); return handler.query(stmt, resultHandler); } finally { closeStatement(stmt); } } @Override protected \u0026lt;E\u0026gt; Cursor\u0026lt;E\u0026gt; doQueryCursor(MappedStatement ms, Object parameter, RowBounds rowBounds, BoundSql boundSql) throws SQLException { Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, null, boundSql); Statement stmt = prepareStatement(handler, ms.getStatementLog()); Cursor\u0026lt;E\u0026gt; cursor = handler.queryCursor(stmt); stmt.closeOnCompletion(); return cursor; } @Override public List\u0026lt;BatchResult\u0026gt; doFlushStatements(boolean isRollback) { return Collections.emptyList(); } "},{"id":16,"href":"/docs/MyBatis/Cache/","title":"Cache","section":"MyBatis","content":" 一级缓存和二级缓存 # MyBatis 提供了二层缓存架构，分别为：一级缓存和二级缓存。\n一级缓存 # 一级缓存是会话级别的，MyBatis 每创建一个 SqlSession，就表示开启了一次数据库会话。在一次会话内，可能会在短时间内反复执行完全相同的查询语句。\nExecutor 对象内会建立一个简单的缓存，在执行查询操作时，会先查询一级缓存，如果其中存在完全一样的查询语句，则直接从一级缓存中取出结果。\n一级缓存的生命周期与 SqlSession 相同，SqlSession 内部有 Executor 对象，当调用 SqlSession 的 close() 方法时，会调用 Executor 的 close() 方法。\n具体流程 # @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException { BoundSql boundSql = ms.getBoundSql(parameter); CacheKey key = createCacheKey(ms, parameter, rowBounds, boundSql); return query(ms, parameter, rowBounds, resultHandler, key, boundSql); } @SuppressWarnings(\u0026#34;unchecked\u0026#34;) @Override public \u0026lt;E\u0026gt; List\u0026lt;E\u0026gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException { ErrorContext.instance().resource(ms.getResource()).activity(\u0026#34;executing a query\u0026#34;).object(ms.getId()); if (closed) { throw new ExecutorException(\u0026#34;Executor was closed.\u0026#34;); } if (queryStack == 0 \u0026amp;\u0026amp; ms.isFlushCacheRequired()) { clearLocalCache(); } List\u0026lt;E\u0026gt; list; try { queryStack++; list = resultHandler == null ? (List\u0026lt;E\u0026gt;) localCache.getObject(key) : null; if (list != null) { handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); } else { list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); } } finally { queryStack--; } if (queryStack == 0) { for (DeferredLoad deferredLoad : deferredLoads) { deferredLoad.load(); } // issue #601 deferredLoads.clear(); if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) { // issue #482 clearLocalCache(); } } return list; } CacheKey # CacheKey 由 MappedStatement 的 id、对应的 offset 和 limit、SQL 语句（包含 ? 占位符）、用户传入的参数和 Environment 的 id 组成。\n下边为用于创建 CacheKey 的参数例子：\nms.getId()：io.github.ileonli.mapper.UserMapper.findById boundSql.getSql()：SELECT * FROM user WHERE id = ? parameterMappings：传入到 SQL 中的参数 public CacheKey createCacheKey(MappedStatement ms, Object parameterObject, RowBounds rowBounds, BoundSql boundSql) { if (closed) { throw new ExecutorException(\u0026#34;Executor was closed.\u0026#34;); } CacheKey cacheKey = new CacheKey(); cacheKey.update(ms.getId()); cacheKey.update(rowBounds.getOffset()); cacheKey.update(rowBounds.getLimit()); cacheKey.update(boundSql.getSql()); List\u0026lt;ParameterMapping\u0026gt; parameterMappings = boundSql.getParameterMappings(); TypeHandlerRegistry typeHandlerRegistry = ms.getConfiguration().getTypeHandlerRegistry(); // mimic DefaultParameterHandler logic MetaObject metaObject = null; for (ParameterMapping parameterMapping : parameterMappings) { if (parameterMapping.getMode() != ParameterMode.OUT) { Object value; String propertyName = parameterMapping.getProperty(); if (boundSql.hasAdditionalParameter(propertyName)) { value = boundSql.getAdditionalParameter(propertyName); } else if (parameterObject == null) { value = null; } else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) { value = parameterObject; } else { if (metaObject == null) { metaObject = configuration.newMetaObject(parameterObject); } value = metaObject.getValue(propertyName); } cacheKey.update(value); } } if (configuration.getEnvironment() != null) { // issue #176 cacheKey.update(configuration.getEnvironment().getId()); } return cacheKey; } 二级缓存 # "},{"id":17,"href":"/docs/Netty/EventLoopGroup/","title":"EventLoopGroup","section":"Netty","content":" EventLoopGroup # "},{"id":18,"href":"/docs/system-programming/block-and-nonblock-io/","title":"（非）阻塞 I/O","section":"Linux 网络编程","content":" （非）阻塞 I/O 和 epoll（翻译） # 原文：https://eklitzke.org/blocking-io-nonblocking-io-and-epoll\n在这篇文章中，我想解释使用非阻塞 I/O 时会发生什么。我特别想说明的是:\n使用 fcntl 函数设置文件描述符的 O_NONBLOCK 时的语义。 非阻塞（nonblocking） I/O 与异步（asynchronous） I/O 的区别。 为什么非阻塞 I/O 经常与诸如 select、epoll 和 kqueue 等 I/O 多路复用器一起使用。 非阻塞模式如何与 epoll 中的边缘触发轮询交互。 阻塞模式 # 默认情况下，Unix 系统所有的文件描述符都以“阻塞模式”启动。这意味着像 read、write 或 connect 这样的 I/O 系统调用可能会阻塞。一个很容易理解的方法是当你从一个普通的基于 TTY 的程序中的 stdin 读取数据时会发生什么。如果你在 stdin上调用 read，那么你的程序将会阻塞，直到数据实际上可用，比如当用户实际上在键盘上键入字符时。具体来说，内核会将进程置于“睡眠”状态，直到 stdin 上的数据可用。其他类型的文件描述符也是如此。例如，如果你尝试从 TCP 套接字中读取数据，那么 read 调用将会阻塞，直到连接的另一端实际上发送数据。\n阻塞对于应该并发运行的程序来说是一个问题，因为被阻塞的进程会被挂起。解决这个问题有两种不同但互补的方式：\n非阻塞模式。 I/O 多路复用系统调用，例如 select 和 epoll。 这两种解决方案经常一起使用，但它们是解决这个问题的独立策略，通常两者都会被使用。接下来我们将会看到它们之间的区别以及为什么它们通常都会被同时使用。\n非阻塞模式 # 通过 fcntl 函数在文件描述符的标志集中添加 O_NONBLOCK，可以将文件描述符设置为“非阻塞模式”：\n/* set O_NONBLOCK on fd */ int flags = fcntl(fd, F_GETFL, 0); fcntl(fd, F_SETFL, flags | O_NONBLOCK); 从这一点开始，文件描述符被视为非阻塞的。当发生这种情况时，像 read 和 write 这样的 I/O 系统调用将返回 -1，并且 errno 将被设置为 EWOULDBLOCK。\n这很有趣，但单独使用实际上并不是那么有用。仅仅使用这种基本方法是没有有效方式同时在多个文件描述符上进行 I/O 的。例如，假设我们有两个文件描述符，并希望同时读取它们。这可以通过循环检查每个文件描述符是否有数据，然后在再次检查之前短暂休眠来实现：\nstruct timespec sleep_interval{.tv_sec = 0, .tv_nsec = 1000}; ssize_t nbytes; for (;;) { /* try fd1 */ if ((nbytes = read(fd1, buf, sizeof(buf))) \u0026lt; 0) { if (errno != EWOULDBLOCK) { perror(\u0026#34;read/fd1\u0026#34;); } } else { handle_data(buf, nbytes); } /* try fd2 */ if ((nbytes = read(fd2, buf, sizeof(buf))) \u0026lt; 0) { if (errno != EWOULDBLOCK) { perror(\u0026#34;read/fd2\u0026#34;); } } else { handle_data(buf, nbytes); } /* sleep for a bit; real version needs error checking! */ nanosleep(sleep_interval, NULL); } 这种方法确实有效，但存在很多缺点：\n当数据传入速度很慢时，程序会频繁而不必要地唤醒，这会浪费 CPU 资源。 当数据到达时，如果程序正在睡眠，可能不会立即读取数据，因此程序的延迟会很高。 使用这种模式处理大量文件描述符会变得繁琐。 为了解决这些问题，我们需要 I/O 多路复用。\nI/O 多路复用（select, epoll, kqueue） # 有几种I/O多路复用系统调用。例如，POSIX 定义的 select，Linux 上的 epoll 系列，以及 BSD 上的 kqueue 系列都是 I/O 多路复用的例子。它们在基本原理上都是相同的：它们让内核知道一组文件描述符上感兴趣的事件（通常是读事件和写事件），然后它们会阻塞，直到发生感兴趣的事件。例如，你可以告诉内核你只对文件描述符 X 上的读事件感兴趣，对文件描述符 Y 上的读和写事件都感兴趣，以及对文件描述符 Z 上的写事件感兴趣。\n这些 I/O 多路复用系统调用通常不关心文件描述符是处于阻塞模式还是非阻塞模式。你可以将所有的文件描述符都保留在阻塞模式下，它们仍然可以与 select 或 epoll 一起正常工作。如果你只对 select 或 epoll 返回的文件描述符调用 read 和 write，那么即使这些文件描述符处于阻塞模式，这些调用也不会阻塞。但有一个重要的例外，文件描述符的阻塞或非阻塞状态对于边缘触发轮询是重要的，下面会进一步解释。\n并发的多路复用方法是我所谓的“异步 I/O”。有时人们也会将这种方法称为“非阻塞 I/O”，我认为这是对系统编程层面中“非阻塞”含义的混淆。我建议将术语“非阻塞”保留用于指代文件描述符是否实际处于非阻塞模式。\nO_NONBLOCK 与 I/O 多路复用的交互方式 # 假设我们正在使用带有阻塞文件描述符的 select 编写一个简单的套接字服务器。为简单起见，在此示例中，我们只有要从中读取的文件描述符，这些文件描述符存储在 read_fds 中。事件循环的核心部分将调用 select，然后针对每个具有数据的文件描述符调用一次 read：\nssize_t nbytes; for (;;) { /* select call happens here */ if (select(FD_SETSIZE, \u0026amp;read_fds, NULL, NULL, NULL) \u0026lt; 0) { perror(\u0026#34;select\u0026#34;); exit(EXIT_FAILURE); } for (int i = 0; i \u0026lt; FD_SETSIZE; i++) { if (FD_ISSET(i, \u0026amp;read_fds)) { /* read call happens here */ if ((nbytes = read(i, buf, sizeof(buf))) \u0026gt;= 0) { handle_read(nbytes, buf); } else { /* real version needs to handle EINTR correctly */ perror(\u0026#34;read\u0026#34;); exit(EXIT_FAILURE); } } } } 这样做是有效的，而且完全没问题。但是，如果 buf 很小，而且有大量数据同时传输会发生什么？具体来说，假设 buf 是一个 1024 字节的缓冲区，但一次传输了 64KB 的数据。为了处理这个请求，我们将调用 select，然后调用 64 次 read。总共需要 128 次系统调用，这是相当多的。\n如果缓冲区大小太小，就必须调用很多次 read，这是无法避免的。但也许我们可以减少调用 select 的次数？在这个例子中，理想情况下我们只会调用一次 select。\n事实上，这是可能的，而且可以通过将文件描述符设置为非阻塞模式来实现。基本思想是你可以在一个循环中不断调用 read，直到它返回 EWOULDBLOCK 为止。实现如下所示：\nssize_t nbytes; for (;;) { /* select call happens here */ if (select(FD_SETSIZE, \u0026amp;read_fds, NULL, NULL, NULL) \u0026lt; 0) { perror(\u0026#34;select\u0026#34;); exit(EXIT_FAILURE); } for (int i = 0; i \u0026lt; FD_SETSIZE; i++) { if (FD_ISSET(i, \u0026amp;read_fds)) { /* NEW: loop until EWOULDBLOCK is encountered */ for (;;) { /* read call happens here */ nbytes = read(i, buf, sizeof(buf)); if (nbytes \u0026gt;= 0) { handle_read(nbytes, buf); } else { if (errno != EWOULDBLOCK) { /* real version needs to handle EINTR correctly */ perror(\u0026#34;read\u0026#34;); exit(EXIT_FAILURE); } break; } } } } } 在这个例子中（1024 字节缓冲区，传入 64KB 的数据），我们将进行 66 次系统调用：select 将被调用一次，read 将被调用 64 次而不会出错，read 将被调用并返回 EWOULDBLOCK 一次。这要比之前的例子好得多！这几乎是前一个例子的一半，这将显著提高性能和可伸缩性。\n这种方法的缺点是由于新的循环，至少会有一次额外的 read 调用，因为它被调用直到返回 EWOULDBLOCK。假设通常情况下读取缓冲区足够大，可以在一个 read 调用中读取所有传入的数据。那么在循环中，通常情况下会有三次系统调用而不是只有两次：select 等待数据，read 实际读取数据，然后再次调用 read 以获取 EWOULDBLOCK。\n边缘触发轮询（Edge-Triggered Polling） # 边缘触发轮询是非阻塞 I/O 的另一个重要用途，特别是在 epoll 系统调用中。这个系统调用有两种模式：水平触发和边缘触发。水平触发是一种更简单的编程模型，类似于经典的 select 系统调用。为了解释它们之间的区别，我们需要了解 epoll 在内核中的工作方式。\n假设你告诉内核你有兴趣使用 epoll 来监视某个文件描述符上的读事件。内核为每个文件描述符维护这些兴趣的列表。当数据到达文件描述符时，内核遍历兴趣列表，并唤醒每个在 epoll_wait 中被阻塞的进程，其中包含了该文件描述符在事件列表中。\n上述内容无论 epoll 处于哪种触发模式都会发生。水平触发和边缘触发轮询的区别在于调用 epoll_wait 时内核的行为。在水平触发模式中，内核将遍历兴趣列表中的每个文件描述符，以查看它是否已满足兴趣条件。例如，如果你在文件描述符 8 上注册了一个读事件，调用 epoll_wait 时内核将首先检查：文件描述符 8 是否已经有数据准备好读取？如果任何文件描述符匹配兴趣条件，则 epoll_wait 可以立即返回而不阻塞。\n相比之下，在边缘触发模式中，内核跳过这个检查，并在调用 epoll_wait 时立即将进程置于睡眠状态。这使得程序员必须完全负责，需要完全读取和写入每个文件描述符的所有数据，然后才能等待。\n边缘触发模式使得 epoll 成为时间复杂度为 O(1) 的 I/O 多路复用器：epoll_wait 调用会立即挂起，由于事先为每个文件描述符维护了一个列表，当新数据到达时，内核会在 O(1) 时间知道必须要唤醒的进程。\n以下是边缘触发和水平触发模式之间差异的更详细示例。假设你的读取缓冲区是 100 字节，而文件描述符上传入了 200 字节的数据。然后假设你只调用了一次 read，然后再次调用了 epoll_wait。仍然有 100 字节的数据准备好读取。在水平触发模式中，内核会注意到这一点，并通知进程应该再次调用 read。相比之下，在边缘触发模式中，内核将立即进入睡眠状态。如果另一侧正在期待响应（例如，发送的数据是某种 RPC），那么两侧将会“死锁”，因为服务器将等待客户端发送更多数据，但客户端将等待服务器发送响应。\n要使用边缘触发轮询，你必须将文件描述符设置为非阻塞模式。然后你必须每次调用 read 或 write 直到它们返回 EWOULDBLOCK 为止。如果你未能满足这些条件，你将错过内核的通知。但这样做有一个很大的好处：每次调用 epoll_wait 都会更有效率，这对于具有极高并发性的程序来说非常重要。如果你想了解更多细节，我强烈建议你阅读 epoll(7) 手册页。\n"},{"id":19,"href":"/docs/Netty/Channel/","title":"Channel","section":"Netty","content":" Channel # "},{"id":20,"href":"/docs/system-programming/multiplexing/","title":"I/O 多路复用","section":"Linux 网络编程","content":" I/O 多路复用 # I/O 复用可以使程序同时监听多个文件描述符。\nselect # select 函数允许程序监视多个文件描述符，直到一个或多个文件描述符“准备好”进行某类 I/O 操作。\nselect 成功时返回就绪文件描述符的总数，如果超时时间内没有任何文件描述符就绪，则返回 0。失败时返回 -1 并设置 errno。\n#include \u0026lt;sys/select.h\u0026gt; int select(int nfds, fd_set* readfds, fd_set* writefds, fd_set* exceptfds, struct timeval * timeout); 函数参数 # nfds：指定被监听的文件描述符的总数。这个参数应该被设置为三个集合中编号最高的文件描述符，再加 1，因为文件描述符是从 0 开始的。\nreadfds、writefds 和 exceptfds：分别指向可读、可写和异常事件对应的文件描述符集合。如果没有文件描述符要监听，则可以将对应的 fd_set 参数设为 NULL。\nfd_set 结构体仅包含一个数组，数组每一位标记一个文件描述符，最大容纳长度由 FD_SETSIZE 指定。\n/* fd_set for select and pselect. */ typedef struct { /* XPG4.2 requires this member name. Otherwise avoid the name from the global namespace. */ #ifdef __USE_XOPEN __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;fds_bits) #else __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;__fds_bits) #endif } fd_set; 为方便对此结构体进行操作，提供了以下几个宏函数对其进行操作，宏函数如下：\n为方便展示，对宏函数中的所有参数加上了类型\nFD_SET(fd, fdsetp)：将文件描述符 fd 添加到 fdset 指向的集合中。 FD_CLR(fd, fdsetp)：将文件描述符 fd 从 fdset 指向的集合中移除。 FD_ISSET(fd, fdsetp)：如果文件描述符 fd 是 fdset 指向的集合中的成员，则返回 true。 FD_ZERO(fdsetp)：将 fdset 指向的集合初始化为空。 timeval：用来设置 select 函数的超时时间，采用指针作为参数是因为内核将修改以告诉应用程序 select 等待了多久。\n如果 timeval 结构体中的 tv_sec 和 tv_usec 成员都传递 0，则 select 函数立即返回。如果传递 NULL，则一直阻塞，直到某个文件描述符就绪。\n/* A time value that is accurate to the nearest microsecond but also has a range of years. */ struct timeval { #ifdef __USE_TIME_BITS64 __time64_t tv_sec;\t/* Seconds. */ __suseconds64_t tv_usec;\t/* Microseconds. */ #else __time_t tv_sec;\t/* Seconds. */ __suseconds_t tv_usec;\t/* Microseconds. */ #endif }; 就绪条件 # 在网络编程中，下边情况下 socket 可读：\n在网络编程中，下边情况下 socket 可写：\nselect 函数能处理的异常情况只有一种：socket 上接收到带外数据。\n循环中使用 # 由于这些结构体会在调用中被修改，如果要在循环中重复调用 select 函数，我们必须保证每次都要重新初始化它们。\npoll # poll 函数和 select 函数调用返回值一致。\n#include \u0026lt;poll.h\u0026gt; int poll(struct pollfd *fds, nfds_t nfds, int timeout); 函数参数 # fds：需要 poll 函数检查的文件描述符，该参数为 pollfd 结构体数组。\npollfd 结构体中 fd 指定文件描述符；events 告诉 poll 函数需要监听哪些事件；revents 由内核对其进行修改，以通知应用程序 fd 上实际发生了哪些事件。\n位掩码 events 返回到revents 描述 POLLIN ● ● 可读取非高优先级的数据 POLLRDNORM ● ● 等同于POLLIN POLLRDBAND ● ● 可读取优先级数据（Linux 中不使用） POLLPRI ● ● 可读取高优先级数据 POLLRDHUP ● ● 对端套接字关闭 POLLOUT ● ● 普通数据可写 POLLWRNORM ● ● 等同于POLLOUT POLLWRBAND ● ● 优先级数据可写入 POLLERR ● 有错误发生 POLLHUP ● 出现挂断 POLLNVAL ● 文件描述符未打开 POLLMSG Linux 中不使用 struct pollfd { int fd; /* file descriptor */ short events; /* requested events */ short revents; /* returned events */ }; nfds：用于指定数组 fds 中元素的个数。\n/* Type used for the number of file descriptors. */ typedef unsigned long int nfds_t; timeout：指定 poll 的超时值，单位为毫秒。\n当 timeout 为 -1 时，poll 调用将一直阻塞，直到某个事件发生； 当 timeout 为 0 时，poll 调用将立即返回。 epoll # epoll 是 Linux 特有的 I/O 复用函数。epoll 需要使用额外的文件描述符，标识内核中的这个事件表，需要使用 epoll_create 函数创建，返回文件描述符。\nsize 是想要通过 epoll 来检查的文件描述符个数。该参数并不是一个上限，而是告诉内核应该如何为内部数据结构划分初始大小（从 Linux 2.6.8 版以来，size 参数被忽略不用，因为内核实现做了修改意味着该参数提供的信息已经不再需要了）。\n#include \u0026lt;sys/epoll.h\u0026gt; int epoll_create (int size); int epoll_create1 (int flags); epoll_ctl # epoll_ctl 函数能够修改由文件描述符 epfd 所代表的兴趣列表。\nint epoll_ctl (int epfd, int op, int fd, struct epoll_event *event); epfd 是调用 epoll_create 函数的返回值。\nop 用于操作操作类型。\n/* Valid opcodes ( \u0026#34;op\u0026#34; parameter ) to issue to epoll_ctl(). */ #define EPOLL_CTL_ADD 1\t/* Add a file descriptor to the interface. */ #define EPOLL_CTL_DEL 2\t/* Remove a file descriptor from the interface. */ #define EPOLL_CTL_MOD 3\t/* Change file descriptor epoll_event structure. */ events 是一个位掩码，指定了待检查描述符 fd 上感兴趣的事件集合。\nstruct epoll_event { uint32_t events;\t/* Epoll events */ epoll_data_t data; /* User data variable */ } data 当描述符 fd 就绪时，传递给调用者的信息。\ntypedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t; epoll_wait # 返回 epoll 实例中处于就绪态的文件描述符信息。单个 epoll_wait 函数调用能返回多个就绪态文件描述符的信息。\n调用成功后，epoll_wait 函数返回数组 events 元素个数。\nint epoll_wait (int epfd, struct epoll_event *events, int maxevents, int timeout); events 所指向的结构体数组中返回的是有关就绪态文件描述符的信息。\n数组 events 的空间由调用者负责申请，所包含的元素个数由参数 maxevents 指定。\ntimeout：指定 epoll 的超时值，单位为毫秒。\n当 timeout 为 -1 时，epoll 调用将一直阻塞，直到某个事件发生； 当 timeout 为 0 时，epoll 执行一次非阻塞式的检查，看兴趣列表中的文件描述符上产生了哪个事件。 当 timeout 大于 0 时，epoll 阻塞至多 timeout 毫秒，直到文件描述符上有事件发生，或者直到捕获到一个信号为止。 水平触发和边缘触发 # epoll 默认工作模式为水平触发，当往 epoll 内核事件表中注册一个文件描述符上的 EPOLLET 事件时，将以边缘触发模式工作。\nLT 模式（水平）：缓冲区剩余未读尽的数据会导致 epoll_wait 返回。直到新的事件满足才会触发。支持阻塞和非阻塞。\nET 模式（边缘）：缓冲区剩余未读尽的数据不会导致 epoll_wait 返回。必须设置为非阻塞。\n"},{"id":21,"href":"/docs/Netty/ChannelHandler/","title":"ChannelHandler","section":"Netty","content":" ChannelHandler # ChannelHandler 共分为两类，ChannelInboundHandler 和 ChannelOutboundHandler。\nChannelInboundHandler： ChannelOutboundHandler： 常用 # ChannelHandlerAdapter ChannelInboundHandlerAdapter ChannelOutboundHandlerAdapter ChannelDuplexHandler Pipeline 执行顺序 # Inbound 是从 ChannelPipeline 头到尾部，Outbound 是从 ChannelPipeline 尾到头部。\n生命周期 # handlerAdded new ChannelHandler() { @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { } @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception { } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { } } ChannelInboundHandler # ChannelInboundHandlerAdapter # ChannelInboundHandlerAdapter 中的所有方法默认会调用 ctx.fireChannel*() 传递到下一个 Handler。\nChannelInboundHandlerAdapter 不会释放 ByteBuf。\nChannelOutboundHandler # 编码器和解码器 # "},{"id":22,"href":"/docs/system-programming/reactor-pattern/","title":"Reactor 模型","section":"Linux 网络编程","content":" Reactor 模型 # Reactor 模型中定义的三种角色：\nReactor：负责监听和分配事件，将I/O事件分派给对应的 Handler。新的事件包含连接建立就绪、读就绪、写就绪等。 Acceptor：处理客户端新连接，并分派请求到处理器链中。 Handler：将自身与事件绑定，执行非阻塞读/写任务，完成channel的读入，完成处理业务逻辑后，负责将结果写出channel。可用资源池来管理。 One Loop Per Thread # 参考文献 # https://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf https://gee.cs.oswego.edu/dl/cpjslides/nio.pdf "},{"id":23,"href":"/docs/system-programming/sockets/","title":"套接字（socket）","section":"Linux 网络编程","content":" 套接字（socket） # 网络编程即编写程序使两台联网的计算机相互交换数据。计算机之间会通过网线、路由器和交换机等设备连接在一起，我们无需直接操控硬件，而使用操作系统提供的套接字（socket）。\n基本函数 # socket # 为了使用套接字，可以使用 socket 函数，创建用于通信的端点（endpoint）。\n#include \u0026lt;sys/socket.h\u0026gt; int socket(int domain, int type, int protocol); 成功时会返回文件描述符，失败时会返回 -1。\nhttps://man7.org/linux/man-pages/man2/socket.2.html\nbind # 当使用 socket 函数创建套接字后，会存在于名称空间（地址族）中，但没有为其分配地址。bind 函数将 addr 指定的地址分配给文件描述符 sockfd 引用的套接字。\n服务器可以不先调用 bind() 而直接调用 listen()，此时会为该 socket 分配一个 INADDR_ANY IP 地址（0.0.0.0）和临时端口（可通过 getsockname() 获取 socket 的地址）。\n#include \u0026lt;sys/socket.h\u0026gt; int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 成功时返回 0，失败时返回 -1。\nhttps://man7.org/linux/man-pages/man2/bind.2.html\nlisten # listen 函数将文件描述符引用的 socket 标记为被动，该 socket 会被用来接受来自其它主动 socket 的连接。\n#include \u0026lt;sys/socket.h\u0026gt; int listen(int sockfd, int backlog); 成功时返回 0，失败时返回 -1。\nhttps://man7.org/linux/man-pages/man2/listen.2.html\naccept # 执行 accept 函数会创建一个新的 socket，此 socket 会与执行 connect 函数的 socket 进行连接。此函数调用返回值是已连接的 socket 的文件描述符。\n#include \u0026lt;sys/socket.h\u0026gt; int accept(int sockfd, struct sockaddr *_Nullable restrict addr, socklen_t *_Nullable restrict addrlen); 成功时会返回文件描述符，失败时会返回 -1。\nhttps://man7.org/linux/man-pages/man2/accept.2.html\nconnect # connect 函数将文件描述符 sockfd 引用的套接字连接到由 addr 指定的地址。\n#include \u0026lt;sys/socket.h\u0026gt; int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); https://man7.org/linux/man-pages/man2/connect.2.html\n套接字协议 # socket 函数（int socket(int domain, int type, int protocol)）有三个参数用于选择传输协议和方式。\n协议族（domain） # 所有的协议族可以点击 address_families 查看，主要的协议族分类如下：\n协议族 描述 AF_INET 使用 IPv4 地址 AF_INET6 使用 IPv6 地址 AF_UNIX 本地通信，用于同一台机器上的进程间通信 AF_PACKET 原始数据包捕获和注入，需要特殊权限 AF_NETLINK 用于 Linux 内核与用户空间进程之间的通信 AF_常量 和 PF_常量 的区别？\nAF 表示地址族（address family），PF 表示协议族（protocol family）。在一开始的时候，设计人员相信单个协议族可以支持多个地址族。但在实践中，没有哪一个协议族能够支持多个已经被定义的地址族，并且所有既有实现都将 PF_常量 定义成对应的 AF_常量 的同义词。\n数据传输方式（type） # 数据传输类型主要有以下两种：\n面向连接的套接字（SOCK_STREAM）：提供有序的、可靠的、双向的、基于连接的字节流。可以支持带外（ out-of-band）数据传输机制。 面向消息的套接字（SOCK_DGRAM）：支持数据报（无连接、最大长度固定的不可靠消息）。 协议（protocol） # 在给定的协议族中，通常只有一个协议存在以支持特定的套接字类型，在这种情况下，可以将 protocol 指定为 0。\n在大部分情况下，第三个参数传递 0 即可。然而，协议族下可能存在许多协议，在这种情况下，必须使用 protocol 指定一个特定的协议。\n"},{"id":24,"href":"/docs/system-programming/echo-server/","title":"echo 服务器","section":"Linux 网络编程","content":" echo 服务器 # 辅助函数 # panic 函数用于错误处理，当发生错误时，调用 exit 函数直接退出程序。\nvoid panic(const char *format, ...) { va_list args; va_start(args, format); vfprintf(stderr, format, args); va_end(args); exit(EXIT_FAILURE); } readn 和 writen 函数分别用于从 fd 处读和写 n 个字节。\nssize_t readn(int fd, const void *buf, size_t n) { ssize_t nread; while (nleft \u0026gt; 0) { if ((nread = read(fd, buf, nleft)) \u0026lt; 0) { if (nleft == n) { return -1; // error, return -1 } else { break; // error, return amount read so far } while (nleft \u0026gt; 0) { if ((nread = read(fd, buf, nleft)) \u0026lt; 0) { if (nleft == n) { return -1; // error, return -1 } else { } nleft -= nread; buf += nread; } return n - nleft; } ssize_t writen(int fd, const void *buf, size_t n) { size_t nleft = n; ssize_t nwritten; while (nleft \u0026gt; 0) { if ((nwritten = write(fd, buf, nleft)) \u0026lt; 0) { if (nleft == n) { return -1; } else { break; } } else if (nwritten == 0) { break; } nleft -= nwritten; buf += nwritten; } return n - nleft; } read_line 函数用于从用户处读取一行输入。\nchar *read_line() { char *line = NULL; size_t buf_size = 0; ssize_t n_bytes = getline(\u0026amp;line, \u0026amp;buf_size, stdin); if (n_bytes == -1) { fprintf(stderr, \u0026#34;error: reading input\\n\u0026#34;); } if (line[n_bytes - 1] == \u0026#39;\\n\u0026#39;) { line[n_bytes - 1] = \u0026#39;\\0\u0026#39;; } return line; } set_nonblocking 函数用于将 fd 设为非阻塞模式。\nint set_nonblocking(int fd) { int flags = fcntl(fd, F_GETFL, 0); if (flags == -1 || fcntl(fd, F_SETFL, flags | O_NONBLOCK) == -1) { return -1; } return 0; } create_sockaddr_in 函数用于创建 struct sockaddr_in 结构体。\nstruct sockaddr_in *create_sockaddr_in(const char *address, int port) { struct sockaddr_in *addr = malloc(sizeof(struct sockaddr_in)); addr-\u0026gt;sin_family = AF_INET; addr-\u0026gt;sin_addr.s_addr = inet_addr(address); addr-\u0026gt;sin_port = htons(port); return addr; } 对于 socket、bind、listen、accept 和 connect 函数，大部分使用都是一样的，对其进行封装。\nint Socket() { int fd = socket(AF_INET, SOCK_STREAM, 0); if (fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } return fd; } void Bind(int socket_fd, struct sockaddr_in *addr) { int ret = bind(socket_fd, (struct sockaddr *)(addr), sizeof(*addr)); if (ret == -1) { panic(\u0026#34;bind() error: %s\\n\u0026#34;, strerror(errno)); } } void Listen(int socket_fd) { int ret = listen(socket_fd, 16); if (ret == -1) { panic(\u0026#34;listen() error: %s\\n\u0026#34;, strerror(errno)); } } int Accept(int socket_fd, struct sockaddr_in *addr, socklen_t *addr_len) { int fd = accept(socket_fd, (struct sockaddr *)addr, addr_len); if (fd == -1) { panic(\u0026#34;accept() error: %s\\n\u0026#34;, strerror(errno)); } int ret = set_nonblocking(fd); if (ret == -1) { panic(\u0026#34;set_nonblocking error\\n\u0026#34;); } return fd; } void Connect(int socket_fd, struct sockaddr_in *addr) { int ret = connect(socket_fd, (struct sockaddr *)(addr), sizeof(*addr)); if (ret == -1) { panic(\u0026#34;connect() error: %s\\n\u0026#34;, strerror(errno)); } } 客户端 # 客户端读取一行用户的输入，将数据传给服务器，服务器将所有的字母大写后再传给客户端。\nvoid run_client(const char *remote_address, int remote_port) { int client_fd = Socket(); struct sockaddr_in *server_addr = create_sockaddr_in(remote_address, remote_port); Connect(client_fd, server_addr); for (;;) { char *input = read_line(); size_t input_len = strlen(input); char buf[input_len + 1]; if (input_len == 0) { goto out; } ssize_t sent_bytes = send(client_fd, input, input_len, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } ssize_t recv_bytes = recv(client_fd, buf, input_len, 0); if (recv_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } printf(\u0026#34;%s\\n\u0026#34;, buf); out: free(input); } } 为什么多路复用需要搭配非阻塞 # On Linux, select() may report a socket file descriptor as \u0026#34;ready for reading\u0026#34;, while nevertheless a subsequent read blocks. This could for example happen when data has arrived but upon examination has the wrong checksum and is discarded. There may be other circumstances in which a file descriptor is spuriously reported as ready. Thus it may be safer to use O_NONBLOCK on sockets that should not block. 参考链接： select\n普通版本 # #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; int used_for_cleanup_fd = -1; void panic(const char *format, ...) { va_list args; va_start(args, format); vfprintf(stderr, format, args); va_end(args); exit(EXIT_FAILURE); } void cleanup() { if (used_for_cleanup_fd != -1) close(used_for_cleanup_fd); } void run_client(const char *remote_address, int remote_port) { int ret; char buf[512]; int client_fd = socket(AF_INET, SOCK_STREAM, 0); if (client_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = client_fd; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(remote_address); server_addr.sin_port = htons(remote_port); ret = connect(client_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;connect() error: %s\\n\u0026#34;, strerror(errno)); } for (;;) { fgets(buf, sizeof(buf), stdin); buf[strcspn(buf, \u0026#34;\\n\u0026#34;)] = \u0026#39;\\0\u0026#39;; size_t buf_len = strlen(buf); if (buf_len == 0) { continue; } if (buf_len \u0026gt;= sizeof(buf) - 1) { panic(\u0026#34;input too long\\n\u0026#34;); } ssize_t sent_bytes = send(client_fd, buf, buf_len, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } ssize_t recv_bytes = recv(client_fd, buf, sizeof(buf), 0); if (recv_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } printf(\u0026#34;%s\\n\u0026#34;, buf); } } void run_server(const char *address, int port) { int ret; char buf[512]; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(address); server_addr.sin_port = htons(port); int server_fd = socket(AF_INET, SOCK_STREAM, 0); if (server_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = server_fd; ret = bind(server_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;bind() error: %s\\n\u0026#34;, strerror(errno)); } ret = listen(server_fd, 16); if (ret == -1) { panic(\u0026#34;listen() error: %s\\n\u0026#34;, strerror(errno)); } struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); for (;;) { int client_fd = accept(server_fd, (struct sockaddr *)(\u0026amp;client_addr), \u0026amp;client_addr_len); if (client_fd == -1) { panic(\u0026#34;accept() error: %s\\n\u0026#34;, strerror(errno)); } for (;;) { ssize_t read_bytes = recv(client_fd, buf, sizeof(buf), 0); if (read_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } if (read_bytes == 0) { close(client_fd); break; } for (ssize_t i = 0; i \u0026lt; read_bytes; i++) { buf[i] = (char)toupper((unsigned char)buf[i]); } ssize_t sent_bytes = send(client_fd, buf, read_bytes, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } } } } int main(int argc, char *argv[]) { if (argc \u0026lt; 4) { panic(\u0026#34;usage: \u0026lt;mode\u0026gt; \u0026lt;IP\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); } char *mode = argv[1]; char *address = argv[2]; int port = atoi(argv[3]); if (strncmp(mode, \u0026#34;client\u0026#34;, 6) == 0) run_client(address, port); if (strncmp(mode, \u0026#34;server\u0026#34;, 6) == 0) run_server(address, port); return 0; } select 版本 # #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;sys/select.h\u0026gt; #define MAX(a, b) a \u0026lt; b ? b : a int used_for_cleanup_fd = -1; void panic(const char *format, ...) { va_list args; va_start(args, format); vfprintf(stderr, format, args); va_end(args); exit(EXIT_FAILURE); } void cleanup() { if (used_for_cleanup_fd != -1) close(used_for_cleanup_fd); } void run_client(const char *remote_address, int remote_port) { int ret; char buf[512]; int client_fd = socket(AF_INET, SOCK_STREAM, 0); if (client_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = client_fd; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(remote_address); server_addr.sin_port = htons(remote_port); ret = connect(client_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;connect() error: %s\\n\u0026#34;, strerror(errno)); } for (;;) { fgets(buf, sizeof(buf), stdin); buf[strcspn(buf, \u0026#34;\\n\u0026#34;)] = \u0026#39;\\0\u0026#39;; size_t buf_len = strlen(buf); if (buf_len == 0) { continue; } if (buf_len \u0026gt;= sizeof(buf) - 1) { panic(\u0026#34;input too long\\n\u0026#34;); } ssize_t sent_bytes = send(client_fd, buf, buf_len, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } ssize_t recv_bytes = recv(client_fd, buf, sizeof(buf), 0); if (recv_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } printf(\u0026#34;%s\\n\u0026#34;, buf); } } void run_server(const char *address, int port) { int ret; char buf[512]; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(address); server_addr.sin_port = htons(port); int server_fd = socket(AF_INET, SOCK_STREAM, 0); if (server_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = server_fd; ret = bind(server_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;bind() error: %s\\n\u0026#34;, strerror(errno)); } ret = listen(server_fd, 16); if (ret == -1) { panic(\u0026#34;listen() error: %s\\n\u0026#34;, strerror(errno)); } struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); fd_set fds; FD_ZERO(\u0026amp;fds); FD_SET(server_fd, \u0026amp;fds); int max_fd = server_fd; for (;;) { fd_set rfds = fds; int retval = select(max_fd + 1, \u0026amp;rfds, NULL, NULL, NULL); if (retval == -1) { panic(\u0026#34;select() error: %s\\n\u0026#34;, strerror(errno)); } if (FD_ISSET(server_fd, \u0026amp;rfds)) { // new connection int client_fd = accept(server_fd, (struct sockaddr *)(\u0026amp;client_addr), \u0026amp;client_addr_len); if (client_fd == -1) { panic(\u0026#34;accept() error: %s\\n\u0026#34;, strerror(errno)); } FD_SET(client_fd, \u0026amp;fds); max_fd = MAX(max_fd, client_fd); if (retval == 1) continue; } for (int fd = server_fd + 1; fd \u0026lt;= max_fd; fd++) { if (FD_ISSET(fd, \u0026amp;rfds)) { ssize_t read_bytes = recv(fd, buf, sizeof(buf), 0); if (read_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } if (read_bytes == 0) { FD_CLR(fd, \u0026amp;fds); close(fd); break; } for (ssize_t i = 0; i \u0026lt; read_bytes; i++) { buf[i] = (char)toupper((unsigned char)buf[i]); } ssize_t sent_bytes = send(fd, buf, read_bytes, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } } } } } int main(int argc, char *argv[]) { if (argc \u0026lt; 4) { panic(\u0026#34;usage: \u0026lt;mode\u0026gt; \u0026lt;IP\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); } char *mode = argv[1]; char *address = argv[2]; int port = atoi(argv[3]); if (strncmp(mode, \u0026#34;client\u0026#34;, 6) == 0) run_client(address, port); if (strncmp(mode, \u0026#34;server\u0026#34;, 6) == 0) run_server(address, port); return 0; } "},{"id":25,"href":"/docs/Java/Agent/","title":"Agent","section":"Java","content":" https://www.cnblogs.com/crazymakercircle/p/16635330.html\nhttps://docs.oracle.com/javase/8/docs/platform/jvmti/jvmti.html#whatIs\n"},{"id":26,"href":"/docs/JVM/AsmTools/","title":"AsmTools","section":"JVM","content":" AsmTools # AsmTools 官网： AsmTools\n编译 AsmTools # GitHub: AsmTools\nHow To Build AsmTools\n使用 # java -jar asmtools.jar jdis [option] [filename.class]\n参数 -g 可打印出更详细的信息。 "},{"id":27,"href":"/docs/boltdb/node/","title":"boltdb node","section":"boltdb","content":" 分裂 # // spill writes the nodes to dirty pages and splits nodes as it goes. // Returns an error if dirty pages cannot be allocated. func (n *node) spill() error { var tx = n.bucket.tx if n.spilled { return nil } // Spill child nodes first. Child nodes can materialize sibling nodes in // the case of split-merge so we cannot use a range loop. We have to check // the children size on every loop iteration. sort.Sort(n.children) for i := 0; i \u0026lt; len(n.children); i++ { if err := n.children[i].spill(); err != nil { return err } } // We no longer need the child list because it\u0026#39;s only used for spill tracking. n.children = nil // Split nodes into appropriate sizes. The first node will always be n. var nodes = n.split(tx.db.pageSize) for _, node := range nodes { // Add node\u0026#39;s page to the freelist if it\u0026#39;s not new. if node.pgid \u0026gt; 0 { tx.db.freelist.free(tx.meta.txid, tx.page(node.pgid)) node.pgid = 0 } // Allocate contiguous space for the node. p, err := tx.allocate((node.size() / tx.db.pageSize) + 1) if err != nil { return err } // Write the node. if p.id \u0026gt;= tx.meta.pgid { panic(fmt.Sprintf(\u0026#34;pgid (%d) above high water mark (%d)\u0026#34;, p.id, tx.meta.pgid)) } node.pgid = p.id node.write(p) node.spilled = true // Insert into parent inodes. if node.parent != nil { var key = node.key if key == nil { key = node.inodes[0].key } node.parent.put(key, node.inodes[0].key, nil, node.pgid, 0) node.key = node.inodes[0].key _assert(len(node.key) \u0026gt; 0, \u0026#34;spill: zero-length node key\u0026#34;) } // Update the statistics. tx.stats.Spill++ } // If the root node split and created a new root then we need to spill that // as well. We\u0026#39;ll clear out the children to make sure it doesn\u0026#39;t try to respill. if n.parent != nil \u0026amp;\u0026amp; n.parent.pgid == 0 { n.children = nil return n.parent.spill() } return nil } 合并 # // rebalance attempts to combine the node with sibling nodes if the node fill // size is below a threshold or if there are not enough keys. func (n *node) rebalance() { if !n.unbalanced { return } n.unbalanced = false // Update statistics. n.bucket.tx.stats.Rebalance++ // Ignore if node is above threshold (25%) and has enough keys. var threshold = n.bucket.tx.db.pageSize / 4 if n.size() \u0026gt; threshold \u0026amp;\u0026amp; len(n.inodes) \u0026gt; n.minKeys() { return } // Root node has special handling. if n.parent == nil { // If root node is a branch and only has one node then collapse it. if !n.isLeaf \u0026amp;\u0026amp; len(n.inodes) == 1 { // Move root\u0026#39;s child up. child := n.bucket.node(n.inodes[0].pgid, n) n.isLeaf = child.isLeaf n.inodes = child.inodes[:] n.children = child.children // Reparent all child nodes being moved. for _, inode := range n.inodes { if child, ok := n.bucket.nodes[inode.pgid]; ok { child.parent = n } } // Remove old child. child.parent = nil delete(n.bucket.nodes, child.pgid) child.free() } return } // If node has no keys then just remove it. if n.numChildren() == 0 { n.parent.del(n.key) n.parent.removeChild(n) delete(n.bucket.nodes, n.pgid) n.free() n.parent.rebalance() return } _assert(n.parent.numChildren() \u0026gt; 1, \u0026#34;parent must have at least 2 children\u0026#34;) // Destination node is right sibling if idx == 0, otherwise left sibling. var target *node var useNextSibling = (n.parent.childIndex(n) == 0) if useNextSibling { target = n.nextSibling() } else { target = n.prevSibling() } // If both this node and the target node are too small then merge them. if useNextSibling { // Reparent all child nodes being moved. for _, inode := range target.inodes { if child, ok := n.bucket.nodes[inode.pgid]; ok { child.parent.removeChild(child) child.parent = n child.parent.children = append(child.parent.children, child) } } // Copy over inodes from target and remove target. n.inodes = append(n.inodes, target.inodes...) n.parent.del(target.key) n.parent.removeChild(target) delete(n.bucket.nodes, target.pgid) target.free() } else { // Reparent all child nodes being moved. for _, inode := range n.inodes { if child, ok := n.bucket.nodes[inode.pgid]; ok { child.parent.removeChild(child) child.parent = target child.parent.children = append(child.parent.children, child) } } // Copy over inodes to target and remove node. target.inodes = append(target.inodes, n.inodes...) n.parent.del(n.key) n.parent.removeChild(n) delete(n.bucket.nodes, n.pgid) n.free() } // Either this node or the target node was deleted from the parent so rebalance it. n.parent.rebalance() } "},{"id":28,"href":"/docs/boltdb/transaction/","title":"boltdb 事务","section":"boltdb","content":" boltdb 事务 # boltdb 所有操作（Update 和 View）都会生成一个 Tx，用于记录此次事务的信息。\n// txid represents the internal transaction identifier. type txid uint64 // Tx represents a read-only or read/write transaction on the database. // Read-only transactions can be used for retrieving values for keys and creating cursors. // Read/write transactions can create and remove buckets and create and remove keys. // // IMPORTANT: You must commit or rollback transactions when you are done with // them. Pages can not be reclaimed by the writer until no more transactions // are using them. A long running read transaction can cause the database to // quickly grow. type Tx struct { writable bool managed bool db *DB meta *meta root Bucket pages map[pgid]*page stats TxStats commitHandlers []func() // WriteFlag specifies the flag for write-related methods like WriteTo(). // Tx opens the database file with the specified flag to copy the data. // // By default, the flag is unset, which works well for mostly in-memory // workloads. For databases that are much larger than available RAM, // set the flag to syscall.O_DIRECT to avoid trashing the page cache. WriteFlag int } Begin # // Begin starts a new transaction. // Multiple read-only transactions can be used concurrently but only one // write transaction can be used at a time. Starting multiple write transactions // will cause the calls to block and be serialized until the current write // transaction finishes. // // Transactions should not be dependent on one another. Opening a read // transaction and a write transaction in the same goroutine can cause the // writer to deadlock because the database periodically needs to re-mmap itself // as it grows and it cannot do that while a read transaction is open. // // If a long running read transaction (for example, a snapshot transaction) is // needed, you might want to set DB.InitialMmapSize to a large enough value // to avoid potential blocking of write transaction. // // IMPORTANT: You must close read-only transactions after you are finished or // else the database will not reclaim old pages. func (db *DB) Begin(writable bool) (*Tx, error) { if writable { return db.beginRWTx() } return db.beginTx() } Begin 方法用于开始一个新的事务。多个只读事务可以同时执行，但同一时间只能有一个写事务。如果启动多个写事务，调用将被阻塞，直到当前写事务完成。允许多个 Goroutine 同时打开多个读事务和一个写事务。\n事务之间不应互相依赖。在同一个 Goroutine 中同时打开一个读事务和一个写事务可能会导致死锁，因为数据库在增长时需要定期重新映射（re-mmap）自身，而这在有读事务打开时无法进行。\n如果需要长时间运行的读事务（例如快照事务），建议将 DB.InitialMmapSize 设置为一个足够大的值，以避免写事务可能被阻塞。\n重要提示：在完成只读事务后，必须关闭它们，否则数据库将无法回收旧的页面。\ndb.beginTx() # 当调用 db.beginTx() 时，会调用 db.metalock.Lock() 和 db.mmaplock.RLock() 获取锁。\n在此方法内会调用 db.metalock.Unlock() 释放 metalock 锁，而不会释放 mmaplock 锁。\nmmaplock 为 sync.RWMutex 锁，该锁允许多个读操作同时进行，但写操作是独占的。\nfunc (db *DB) beginTx() (*Tx, error) { // Lock the meta pages while we initialize the transaction. We obtain // the meta lock before the mmap lock because that\u0026#39;s the order that the // write transaction will obtain them. db.metalock.Lock() // Obtain a read-only lock on the mmap. When the mmap is remapped it will // obtain a write lock so all transactions must finish before it can be // remapped. db.mmaplock.RLock() // Exit if the database is not open yet. if !db.opened { db.mmaplock.RUnlock() db.metalock.Unlock() return nil, ErrDatabaseNotOpen } // Create a transaction associated with the database. t := \u0026amp;Tx{} t.init(db) // Keep track of transaction until it closes. db.txs = append(db.txs, t) n := len(db.txs) // Unlock the meta pages. db.metalock.Unlock() // Update the transaction stats. db.statlock.Lock() db.stats.TxN++ db.stats.OpenTxN = n db.statlock.Unlock() return t, nil } db.beginRWTx() # 调用 db.rwlock.Lock() 获取 rwlock，此方法结束并不会释放该锁，当事务结束后才会释放该锁。保证同时只有一个 Goroutine 可获取写事务。\nfunc (db *DB) beginRWTx() (*Tx, error) { // If the database was opened with Options.ReadOnly, return an error. if db.readOnly { return nil, ErrDatabaseReadOnly } // Obtain writer lock. This is released by the transaction when it closes. // This enforces only one writer transaction at a time. db.rwlock.Lock() // Once we have the writer lock then we can lock the meta pages so that // we can set up the transaction. db.metalock.Lock() defer db.metalock.Unlock() // Exit if the database is not open yet. if !db.opened { db.rwlock.Unlock() return nil, ErrDatabaseNotOpen } // Create a transaction associated with the database. t := \u0026amp;Tx{writable: true} t.init(db) db.rwtx = t // Free any pages associated with closed read-only transactions. var minid txid = 0xFFFFFFFFFFFFFFFF for _, t := range db.txs { if t.meta.txid \u0026lt; minid { minid = t.meta.txid } } if minid \u0026gt; 0 { db.freelist.release(minid - 1) } return t, nil } init # 每开启一个事务，都会在内存中创建对应的结构。\ninit 会对 root 会使用 COW（copy on write）技术。\n// init initializes the transaction. func (tx *Tx) init(db *DB) { tx.db = db tx.pages = nil // Copy the meta page since it can be changed by the writer. tx.meta = \u0026amp;meta{} db.meta().copy(tx.meta) // Copy over the root bucket. tx.root = newBucket(tx) tx.root.bucket = \u0026amp;bucket{} *tx.root.bucket = tx.meta.root // Increment the transaction id and add a page cache for writable transactions. if tx.writable { tx.pages = make(map[pgid]*page) tx.meta.txid += txid(1) } } 会将 meta 中的 root bucket 拷贝到当前创建的 tx 中。\n// Copy over the root bucket. tx.root = newBucket(tx) tx.root.bucket = \u0026amp;bucket{} *tx.root.bucket = tx.meta.root 每次调用 tx 的 Bucket、CreateBucket 和 DeleteBucket 方法，都会在内存中新生成一份，而不会直接写入到磁盘中。\nboltdb 是序列化的，\nCommit() # // Commit writes all changes to disk and updates the meta page. // Returns an error if a disk write error occurs, or if Commit is // called on a read-only transaction. func (tx *Tx) Commit() error { _assert(!tx.managed, \u0026#34;managed tx commit not allowed\u0026#34;) if tx.db == nil { return ErrTxClosed } else if !tx.writable { return ErrTxNotWritable } // TODO(benbjohnson): Use vectorized I/O to write out dirty pages. // Rebalance nodes which have had deletions. var startTime = time.Now() tx.root.rebalance() if tx.stats.Rebalance \u0026gt; 0 { tx.stats.RebalanceTime += time.Since(startTime) } // spill data onto dirty pages. startTime = time.Now() if err := tx.root.spill(); err != nil { tx.rollback() return err } tx.stats.SpillTime += time.Since(startTime) // Free the old root bucket. tx.meta.root.root = tx.root.root opgid := tx.meta.pgid // Free the freelist and allocate new pages for it. This will overestimate // the size of the freelist but not underestimate the size (which would be bad). tx.db.freelist.free(tx.meta.txid, tx.db.page(tx.meta.freelist)) p, err := tx.allocate((tx.db.freelist.size() / tx.db.pageSize) + 1) if err != nil { tx.rollback() return err } if err := tx.db.freelist.write(p); err != nil { tx.rollback() return err } tx.meta.freelist = p.id // If the high water mark has moved up then attempt to grow the database. if tx.meta.pgid \u0026gt; opgid { if err := tx.db.grow(int(tx.meta.pgid+1) * tx.db.pageSize); err != nil { tx.rollback() return err } } // Write dirty pages to disk. startTime = time.Now() if err := tx.write(); err != nil { tx.rollback() return err } // If strict mode is enabled then perform a consistency check. // Only the first consistency error is reported in the panic. if tx.db.StrictMode { ch := tx.Check() var errs []string for { err, ok := \u0026lt;-ch if !ok { break } errs = append(errs, err.Error()) } if len(errs) \u0026gt; 0 { panic(\u0026#34;check fail: \u0026#34; + strings.Join(errs, \u0026#34;\\n\u0026#34;)) } } // Write meta to disk. if err := tx.writeMeta(); err != nil { tx.rollback() return err } tx.stats.WriteTime += time.Since(startTime) // Finalize the transaction. tx.close() // Execute commit handlers now that the locks have been removed. for _, fn := range tx.commitHandlers { fn() } return nil } close # func (tx *Tx) close() { if tx.db == nil { return } if tx.writable { // Grab freelist stats. var freelistFreeN = tx.db.freelist.free_count() var freelistPendingN = tx.db.freelist.pending_count() var freelistAlloc = tx.db.freelist.size() // Remove transaction ref \u0026amp; writer lock. tx.db.rwtx = nil tx.db.rwlock.Unlock() // Merge statistics. tx.db.statlock.Lock() tx.db.stats.FreePageN = freelistFreeN tx.db.stats.PendingPageN = freelistPendingN tx.db.stats.FreeAlloc = (freelistFreeN + freelistPendingN) * tx.db.pageSize tx.db.stats.FreelistInuse = freelistAlloc tx.db.stats.TxStats.add(\u0026amp;tx.stats) tx.db.statlock.Unlock() } else { tx.db.removeTx(tx) } // Clear all references. tx.db = nil tx.meta = nil tx.root = Bucket{tx: tx} tx.pages = nil } "},{"id":29,"href":"/docs/boltdb/bucket/","title":"boltdb 介绍","section":"boltdb","content":"// bucket represents the on-file representation of a bucket. // This is stored as the \u0026#34;value\u0026#34; of a bucket key. If the bucket is small enough, // then its root page can be stored inline in the \u0026#34;value\u0026#34;, after the bucket // header. In the case of inline buckets, the \u0026#34;root\u0026#34; will be 0. type bucket struct { root pgid // page id of the bucket\u0026#39;s root-level page sequence uint64 // monotonically incrementing, used by NextSequence() } // Bucket represents a collection of key/value pairs inside the database. type Bucket struct { *bucket tx *Tx // the associated transaction buckets map[string]*Bucket // subbucket cache page *page // inline page reference rootNode *node // materialized node for the root page. nodes map[pgid]*node // node cache // Sets the threshold for filling nodes when they split. By default, // the bucket will fill to 50% but it can be useful to increase this // amount if you know that your write workloads are mostly append-only. // // This is non-persisted across transactions so it must be set in every Tx. FillPercent float64 } buckets 不是直接加载进来的，而是使用了，才会进行加载。\n// Otherwise create a bucket and cache it. var child = b.openBucket(v) if b.buckets != nil { b.buckets[string(name)] = child } Get # Bucket 的 Get 方法会在当前 Bucket 中找到 key 对应的 value。\nGet 不会遍历子 Bucket 中的 key，只会在当前 Bucket 中寻找。\n// Get retrieves the value for a key in the bucket. // Returns a nil value if the key does not exist or if the key is a nested bucket. // The returned value is only valid for the life of the transaction. func (b *Bucket) Get(key []byte) []byte { k, v, flags := b.Cursor().seek(key) // Return nil if this is a bucket. if (flags \u0026amp; bucketLeafFlag) != 0 { return nil } // If our target node isn\u0026#39;t the same key as what\u0026#39;s passed in then return nil. if !bytes.Equal(key, k) { return nil } return v } Put # Bucket 中的 Put 方法会插入 key 和 value。主要逻辑为 c.node().put(key, key, value, 0, 0)。\n// Put sets the value for a key in the bucket. // If the key exist then its previous value will be overwritten. // Supplied value must remain valid for the life of the transaction. // Returns an error if the bucket was created from a read-only transaction, if the key is blank, if the key is too large, or if the value is too large. func (b *Bucket) Put(key []byte, value []byte) error { if b.tx.db == nil { return ErrTxClosed } else if !b.Writable() { return ErrTxNotWritable } else if len(key) == 0 { return ErrKeyRequired } else if len(key) \u0026gt; MaxKeySize { return ErrKeyTooLarge } else if int64(len(value)) \u0026gt; MaxValueSize { return ErrValueTooLarge } // Move cursor to correct position. c := b.Cursor() k, _, flags := c.seek(key) // Return an error if there is an existing key with a bucket value. if bytes.Equal(key, k) \u0026amp;\u0026amp; (flags\u0026amp;bucketLeafFlag) != 0 { return ErrIncompatibleValue } // Insert into node. key = cloneBytes(key) c.node().put(key, key, value, 0, 0) return nil } node.put 方法的代码如下：\n为什么函数参数设计有 oldKey 和 newKey 两个参数呢？\noldKey 主要用于寻找插入位置。\n// put inserts a key/value. func (n *node) put(oldKey, newKey, value []byte, pgid pgid, flags uint32) { if pgid \u0026gt;= n.bucket.tx.meta.pgid { panic(fmt.Sprintf(\u0026#34;pgid (%d) above high water mark (%d)\u0026#34;, pgid, n.bucket.tx.meta.pgid)) } else if len(oldKey) \u0026lt;= 0 { panic(\u0026#34;put: zero-length old key\u0026#34;) } else if len(newKey) \u0026lt;= 0 { panic(\u0026#34;put: zero-length new key\u0026#34;) } // Find insertion index. index := sort.Search(len(n.inodes), func(i int) bool { return bytes.Compare(n.inodes[i].key, oldKey) != -1 }) // Add capacity and shift nodes if we don\u0026#39;t have an exact match and need to insert. exact := (len(n.inodes) \u0026gt; 0 \u0026amp;\u0026amp; index \u0026lt; len(n.inodes) \u0026amp;\u0026amp; bytes.Equal(n.inodes[index].key, oldKey)) if !exact { n.inodes = append(n.inodes, inode{}) copy(n.inodes[index+1:], n.inodes[index:]) } inode := \u0026amp;n.inodes[index] inode.flags = flags inode.key = newKey inode.value = value inode.pgid = pgid _assert(len(inode.key) \u0026gt; 0, \u0026#34;put: zero-length inode key\u0026#34;) } 第一步：n.inodes 中存储了调用 sort.Search 查找插入位置。\n// Find insertion index. index := sort.Search(len(n.inodes), func(i int) bool { return bytes.Compare(n.inodes[i].key, oldKey) != -1 }) 第二步：当不满足 n.inodes 切片有元素、index 在范围内，并且 n.inodes 中 index 位置的 key 等于 oldKey 条件时，对 n.inodes 进行扩容。\n// Add capacity and shift nodes if we don\u0026#39;t have an exact match and need to insert. exact := (len(n.inodes) \u0026gt; 0 \u0026amp;\u0026amp; index \u0026lt; len(n.inodes) \u0026amp;\u0026amp; bytes.Equal(n.inodes[index].key, oldKey)) if !exact { n.inodes = append(n.inodes, inode{}) copy(n.inodes[index+1:], n.inodes[index:]) } 第三步：将函数参数赋值给新创建的 inode 中。\ninode := \u0026amp;n.inodes[index] inode.flags = flags inode.key = newKey inode.value = value inode.pgid = pgid "},{"id":30,"href":"/docs/boltdb/storage/","title":"boltdb 存储","section":"boltdb","content":" boltdb 存储 # bolt.Open() # bolt.Open() 是使用数据库的第一个方法，也是最重要的方法之一。该代码的作用是初始化一个 DB 对象。\n参数设置 # 首先会创建一个 DB 对象，opened 用于指示数据库是否已成功打开。。\nvar db = \u0026amp;DB{opened: true} 对参数进行一些初始化设置。\n// Set default options if no options are provided. if options == nil { options = DefaultOptions } db.NoGrowSync = options.NoGrowSync db.MmapFlags = options.MmapFlags // Set default values for later DB operations. db.MaxBatchSize = DefaultMaxBatchSize db.MaxBatchDelay = DefaultMaxBatchDelay db.AllocSize = DefaultAllocSize OpenFile # 使用 os.OpenFile() 方法打开传入的数据库文件路径，不存在则创建。\nflag := os.O_RDWR if options.ReadOnly { flag = os.O_RDONLY db.readOnly = true } // Open data file and separate sync handler for metadata writes. db.path = path var err error if db.file, err = os.OpenFile(db.path, flag|os.O_CREATE, mode); err != nil { _ = db.close() return nil, err } flock # boltdb 同一时刻只允许一个进程对数据库进行读写操作，因此使用 flock 对数据库文件进行加锁。\n// Lock file so that other processes using boltdb in read-write mode cannot // use the database at the same time. This would cause corruption since // the two processes would write meta pages and free pages separately. // The database file is locked exclusively (only one process can grab the lock) // if !options.ReadOnly. // The database file is locked using the shared lock (more than one process may // hold a lock at the same time) otherwise (options.ReadOnly is set). if err := flock(db, mode, !db.readOnly, options.Timeout); err != nil { _ = db.close() return nil, err } flock 它用于在文件描述符上获取建议性锁（advisory lock）。\n在一个文件上不能同时获取 LOCK_SH 和 LOCK_EX 锁。\n下面是对 flock 代码进行详细解释：\nfunc flock(db *DB, mode os.FileMode, exclusive bool, timeout time.Duration) error db *DB：传入的 DB 是一个数据库对象。 mode os.FileMode：代表文件的模式，通常与文件的权限设置相关。 exclusive bool：这个布尔值指示是否要获取一个排他锁（exclusive lock）。如果为 true，表示获取排他锁，否则获取共享锁。 timeout time.Duration：尝试获取锁的超时时间。 var t time.Time for { // If we\u0026#39;re beyond our timeout then return an error. // This can only occur after we\u0026#39;ve attempted a flock once. if t.IsZero() { t = time.Now() } else if timeout \u0026gt; 0 \u0026amp;\u0026amp; time.Since(t) \u0026gt; timeout { return ErrTimeout } var t time.Time：初始化时间变量 t。 t.IsZero()：判断时间 t 是否为零值。如果是零值，说明这是第一次尝试获取锁，此时会将 t 设置为当前时间。 timeout \u0026gt; 0 \u0026amp;\u0026amp; time.Since(t) \u0026gt; timeout：如果设置了超时时间且当前时间与初始时间的差值超过了超时时间，则返回超时错误 ErrTimeout。 flag := syscall.LOCK_SH if exclusive { flag = syscall.LOCK_EX } syscall.LOCK_SH：共享锁标志。 syscall.LOCK_EX：排他锁标志。 根据 exclusive 参数，决定使用共享锁还是排他锁。 err := syscall.Flock(int(db.file.Fd()), flag|syscall.LOCK_NB) if err == nil { return nil } else if err != syscall.EWOULDBLOCK { return err } syscall.Flock(int(db.file.Fd()), flag|syscall.LOCK_NB)：使用系统调用 Flock 尝试获取文件锁。 int(db.file.Fd())：获取文件描述符。 flag|syscall.LOCK_NB：非阻塞地获取锁（LOCK_NB）。 err == nil：如果获取锁成功，返回 nil，表示操作成功。 err != syscall.EWOULDBLOCK：如果出现其他错误（除了锁被占用），直接返回错误。 // Wait for a bit and try again. time.Sleep(50 * time.Millisecond) 如果锁被占用（即 err == syscall.EWOULDBLOCK），则等待 50 毫秒后重试。 WriteAt # // Default values for test hooks db.ops.writeAt = db.file.WriteAt 这行代码的作用是将文件对象的 WriteAt 方法赋值给 db.ops.writeAt，使得 db.ops.writeAt 可以作为文件写入操作的默认实现。如果有需要（例如在测试中），可以替换 db.ops.writeAt 为其它自定义函数。\n数据库文件 # 这段代码负责在打开数据库文件时进行初始化工作，确保文件存在且正确设置了数据库的页大小。\n如果文件不存在或大小为零，代码将初始化一个新的数据库文件。 如果文件已经存在且包含数据，代码将读取文件中的元数据以确定页面大小。 页大小对于数据库文件的正确读取和写入至关重要，任何与页面大小相关的错误都可能导致严重的问题。\n// Initialize the database if it doesn\u0026#39;t exist. if info, err := db.file.Stat(); err != nil { return nil, err } else if info.Size() == 0 { // Initialize new files with meta pages. if err := db.init(); err != nil { return nil, err } } else { // Read the first meta page to determine the page size. var buf [0x1000]byte if _, err := db.file.ReadAt(buf[:], 0); err == nil { m := db.pageInBuffer(buf[:], 0).meta() if err := m.validate(); err != nil { // If we can\u0026#39;t read the page size, we can assume it\u0026#39;s the same // as the OS -- since that\u0026#39;s how the page size was chosen in the // first place. // // If the first page is invalid and this OS uses a different // page size than what the database was created with then we // are out of luck and cannot access the database. db.pageSize = os.Getpagesize() } else { db.pageSize = int(m.pageSize) } } } 上边代码逻辑如下：\n检查文件状态：\nif info, err := db.file.Stat(); err != nil { return nil, err } db.file.Stat() 方法用于获取文件的状态信息（os.FileInfo），包括文件的大小、修改时间等。 如果获取文件状态时发生错误（例如文件不存在），则返回错误 err。 初始化新文件：\nelse if info.Size() == 0 { // Initialize new files with meta pages. if err := db.init(); err != nil { return nil, err } } 如果文件大小为零，意味着文件是新创建的或为空。 调用 db.init() 方法来初始化新的数据库文件，通常会在文件中写入元数据页（meta pages）等必要信息。 如果初始化过程中发生错误，则返回该错误。 读取现有文件的元数据页：\nelse { // Read the first meta page to determine the page size. var buf [0x1000]byte if _, err := db.file.ReadAt(buf[:], 0); err == nil { m := db.pageInBuffer(buf[:], 0).meta() if err := m.validate(); err != nil { db.pageSize = os.Getpagesize() } else { db.pageSize = int(m.pageSize) } } } 如果文件已存在且大小大于零，意味着文件中可能已有数据。 使用 db.file.ReadAt(buf[:], 0) 读取文件的前 4KB（0x1000 字节）内容，包含了数据库的元数据页。 db.pageInBuffer(buf[:], 0).meta() 提取了元数据页的内容，并使用 m.validate() 进行验证。 确定页面大小：\n如果元数据页有效，m.pageSize 将指定数据库文件的页面大小，并将其设置为 db.pageSize。 如果元数据页无效（例如因为文件损坏或不兼容），则页面大小将默认设置为操作系统的页面大小 os.Getpagesize()。 pagePool # 下边代码可以利用 sync.Pool 来管理页面对象的重用，从而减少内存分配的开销，提高程序的性能。\n// Initialize page pool. db.pagePool = sync.Pool{ New: func() interface{} { return make([]byte, db.pageSize) }, } mmap # 下边代码将数据文件映射到内存中，在处理文件时可以直接访问内存中的数据，而不必反复进行磁盘读取。可提高读取文件的性能。\n// Memory map the data file. if err := db.mmap(options.InitialMmapSize); err != nil { _ = db.close() return nil, err } freelist # 整个过程的目的是将数据文件中存储的 freelist 信息读入内存中的 freelist 对象中，以便在后续的操作中可以方便地管理和维护空闲的数据块或页面。这有助于数据库的性能和空间管理。\n// Read in the freelist. db.freelist = newFreelist() db.freelist.read(db.page(db.meta().freelist)) DB.init() # 当调用 bolt.Open() 打开的文件为空时，会调用 db.init() 对数据库文件进行一些初始化操作。\n当我们使用下边的代码新建一个数据库。\ndb, err := bolt.Open(\u0026#34;db.db\u0026#34;, 0600, nil) if err != nil { panic(err) } defer db.Close() boltdb 提供了 main.go 工具，对用于对数据库文件进行分析。\n$ bolt pages db.db ID TYPE ITEMS OVRFLW ======== ========== ====== ====== 0 meta 0 1 meta 0 2 freelist 0 3 leaf 0 可以看到，新初始化包含 4 个页，2 个 meta、1 个 freelist 和 1 个 leaf 页。\n下边是对 db.init() 代码的解析：\npageSize # 将页大小设置为操作系统的页大小。\n// Set the page size to the OS page size. db.pageSize = os.Getpagesize() pages # 首先会创建 4 个页大小的 []byte，用于容纳后续创建的页，分别是：2 个 meta、1 个 freelist 和 1 个 leaf 页。\n通过循环创建两个 meta 页，并对其进行初始化。\n// Create two meta pages on a buffer. buf := make([]byte, db.pageSize*4) for i := 0; i \u0026lt; 2; i++ { p := db.pageInBuffer(buf[:], pgid(i)) p.id = pgid(i) p.flags = metaPageFlag // Initialize the meta page. m := p.meta() m.magic = magic m.version = version m.pageSize = uint32(db.pageSize) m.freelist = 2 m.root = bucket{root: 3} m.pgid = 4 m.txid = txid(i) m.checksum = m.sum64() } 创建一个 freelist。\n// Write an empty freelist at page 3. p := db.pageInBuffer(buf[:], pgid(2)) p.id = pgid(2) p.flags = freelistPageFlag p.count = 0 创建一个 leaf page。\n// Write an empty leaf page at page 4. p = db.pageInBuffer(buf[:], pgid(3)) p.id = pgid(3) p.flags = leafPageFlag p.count = 0 将 buf 保存到磁盘中，完成数据库磁盘文件的初始化。\n使用 fdatasync 可以确保将文件的内存缓冲区的内容同步到磁盘中，而不仅仅写入到操作系统的内存缓冲区。\n// Write the buffer to our data file. if _, err := db.ops.writeAt(buf, 0); err != nil { return err } if err := fdatasync(db); err != nil { return err } 为什么创建两个 meta # meta 是 boltdb 数据库最重要的信息，所有信息都保存在此结构中。如果此结构发生错误，则无法重新读取数据库信息。\n事务在初始化时只会使用一个 meta0 或 meta1。例如：本次事务使用 meta0，如果事务提交后，meta0 写入一半时出错，调用 validate() 校验失败，则可以使用 meta1 恢复出数据库信息，而不至于全部丢失。\n当发现一个新写入的 meta 出错时会使用另一个:\n// meta retrieves the current meta page reference. func (db *DB) meta() *meta { // We have to return the meta with the highest txid which doesn\u0026#39;t fail // validation. Otherwise, we can cause errors when in fact the database is // in a consistent state. metaA is the one with the higher txid. metaA := db.meta0 metaB := db.meta1 if db.meta1.txid \u0026gt; db.meta0.txid { metaA = db.meta1 metaB = db.meta0 } // Use higher meta page if valid. Otherwise fallback to previous, if valid. if err := metaA.validate(); err == nil { return metaA } else if err := metaB.validate(); err == nil { return metaB } // This should never be reached, because both meta1 and meta0 were validated // on mmap() and we do fsync() on every write. panic(\u0026#34;bolt.DB.meta(): invalid meta pages\u0026#34;) } "},{"id":31,"href":"/docs/boltdb/page/","title":"boltdb 页结构","section":"boltdb","content":" boltdb 页结构 # page # type page struct { id pgid flags uint16 count uint16 overflow uint32 ptr uintptr } id：是页面的标识符，每个页面在数据库文件中都有一个唯一的 ID，用于在数据库中定位和引用该页面。 flags：用来表示页面的类型或其他特性。 count：表示页面中存储的元素数量（通常是键值对的数量或子页面的引用数量）。 overflow：表示页面溢出的数量。如果一个页面装不下所有的数据，它可能会使用多个连续的页面来存储，这些连续的页面被称为溢出页面。 ptr：用于指向页面的数据部分。在内存中指向实际存储键值对或其他数据的区域。这个指针使得可以通过内存地址快速访问页面中的数据。 一个 page 页的结构如下所示：\n根据 flags 的设置，ptr 会指向 4 种结构体之一。\nconst ( branchPageFlag = 0x01 leafPageFlag = 0x02 metaPageFlag = 0x04 freelistPageFlag = 0x10 ) branchPageFlag：ptr 指向 branchPageElement[] 数组。 leafPageFlag：ptr 指向 leafPageElement[] 数组。 metaPageFlag：ptr 指向 meta 结构体。 freelistPageFlag：ptr 指向 freelist 结构体。 branchPageElement # // branchPageElement represents a node on a branch page. type branchPageElement struct { pos uint32 ksize uint32 pgid pgid } branchPageElement(index) 会返回 index 位置的 branchPageElement。\nbranchPageElements() 会返回页面中所有分支节点的切片。\n// branchPageElement retrieves the branch node by index func (p *page) branchPageElement(index uint16) *branchPageElement { return \u0026amp;((*[0x7FFFFFF]branchPageElement)(unsafe.Pointer(\u0026amp;p.ptr)))[index] } // branchPageElements retrieves a list of branch nodes. func (p *page) branchPageElements() []branchPageElement { if p.count == 0 { return nil } return ((*[0x7FFFFFF]branchPageElement)(unsafe.Pointer(\u0026amp;p.ptr)))[:] } 使用 pos 可以定位到 key 所在的位置，通过保存的 ksize 获取值。\n// key returns a byte slice of the node key. func (n *branchPageElement) key() []byte { buf := (*[maxAllocSize]byte)(unsafe.Pointer(n)) return (*[maxAllocSize]byte)(unsafe.Pointer(\u0026amp;buf[n.pos]))[:n.ksize] } leafPageElement # // leafPageElement represents a node on a leaf page. type leafPageElement struct { flags uint32 pos uint32 ksize uint32 vsize uint32 } 和 branchPageElement 一样的步骤。\n// leafPageElement retrieves the leaf node by index func (p *page) leafPageElement(index uint16) *leafPageElement { n := \u0026amp;((*[0x7FFFFFF]leafPageElement)(unsafe.Pointer(\u0026amp;p.ptr)))[index] return n } // leafPageElements retrieves a list of leaf nodes. func (p *page) leafPageElements() []leafPageElement { if p.count == 0 { return nil } return ((*[0x7FFFFFF]leafPageElement)(unsafe.Pointer(\u0026amp;p.ptr)))[:] } 通过 pos 获取 KV 在的起始索引，再使用 ksize 和 vsize 分别获取 key 和 value。\n// key returns a byte slice of the node key. func (n *leafPageElement) key() []byte { buf := (*[maxAllocSize]byte)(unsafe.Pointer(n)) return (*[maxAllocSize]byte)(unsafe.Pointer(\u0026amp;buf[n.pos]))[:n.ksize:n.ksize] } // value returns a byte slice of the node value. func (n *leafPageElement) value() []byte { buf := (*[maxAllocSize]byte)(unsafe.Pointer(n)) return (*[maxAllocSize]byte)(unsafe.Pointer(\u0026amp;buf[n.pos+n.ksize]))[:n.vsize:n.vsize] } pos 的作用 # 为什么要使用 pos 指向 key 所在位置的索引，而不直接将 key 和 value 数组保存在 leafPageElement 结构体中呢？\n这样可以直接把字节数组直接转为内存中 []leafPageElement 结构，而不需要额外的处理。\n// leafPageElements retrieves a list of leaf nodes. func (p *page) leafPageElements() []leafPageElement { if p.count == 0 { return nil } return ((*[0x7FFFFFF]leafPageElement)(unsafe.Pointer(\u0026amp;p.ptr)))[:] } 如果 leafPageElement 结构体设计为下边，就不能直接把 p.ptr 转为 []leafPageElement 了，因为 bytes 不是定长的。\n// leafPageElement represents a node on a leaf page. type leafPageElement struct { flags uint32 ksize uint32 vsize uint32 bytes []byte } 更改后的结构体需要使用循环对每个 leafPageElement 进行解析，这样会损失部分性能。\nfunc (p *page) leafPageElements() []leafPageElement { if p.count == 0 { return nil } es := make([]leafPageElement, p.count) for i := 0; i \u0026lt; int(p.count); i++ { es[i] = parseLeafPageElement() } return es } branchPageElement 设计和 leafPageElement 是一致的。区别在于，branchPageElement 只有 key，而没有 value。\nmeta # meta 是 boltdb 数据库的元数据，关于数据库信息都保存在此结构体中。\ntype meta struct { magic uint32 version uint32 pageSize uint32 flags uint32 root bucket freelist pgid pgid pgid txid txid checksum uint64 } magix：魔法数字，为：0xED0CDAED。 version：数据库文件保存的格式，目前为 2。 pageSize：页大小，从操作系统中获取。 flags：目前没有被使用。 root：根 bucket。 freelist：保存 freelist 的 pgid。 pgid：保存当前总的页面数量，即最大页面号加一。 txid：上一次写数据库的事务序号，可以看作是当前 boltdb 的修改版本号，每次写数据库时加 1，只读事务不会改变。 checksum：校验码，用于校验元数据页面是否出错的。 freelist # boltdb 磁盘分配的单位为页，freelist 只用于记录可用和闲置的页 ID。\n当 boltdb 删除数据后，并不会将页占用的空间还给操作系统\n// allocate returns a contiguous block of memory starting at a given page. func (db *DB) allocate(count int) (*page, error) { // Allocate a temporary buffer for the page. var buf []byte if count == 1 { buf = db.pagePool.Get().([]byte) } else { buf = make([]byte, count*db.pageSize) } p := (*page)(unsafe.Pointer(\u0026amp;buf[0])) p.overflow = uint32(count - 1) // Use pages from the freelist if they are available. if p.id = db.freelist.allocate(count); p.id != 0 { return p, nil } // Resize mmap() if we\u0026#39;re at the end. p.id = db.rwtx.meta.pgid var minsz = int((p.id+pgid(count))+1) * db.pageSize if minsz \u0026gt;= db.datasz { if err := db.mmap(minsz); err != nil { return nil, fmt.Errorf(\u0026#34;mmap allocate error: %s\u0026#34;, err) } } // Move the page id high water mark. db.rwtx.meta.pgid += pgid(count) return p, nil } node # node 代表 B+ 树在内存中的一个节点。\n// node represents an in-memory, deserialized page. type node struct { bucket *Bucket isLeaf bool unbalanced bool spilled bool key []byte pgid pgid parent *node children nodes inodes inodes } inode # inode 用于保存 node 节点中保存的一条 K/V 数据，使用 inodes 保存所有 K/V 数据。\n// inode represents an internal node inside of a node. // It can be used to point to elements in a page or point // to an element which hasn\u0026#39;t been added to a page yet. type inode struct { flags uint32 pgid pgid key []byte value []byte } type inodes []inode page -\u0026gt; node # // read initializes the node from a page. func (n *node) read(p *page) { n.pgid = p.id n.isLeaf = ((p.flags \u0026amp; leafPageFlag) != 0) n.inodes = make(inodes, int(p.count)) for i := 0; i \u0026lt; int(p.count); i++ { inode := \u0026amp;n.inodes[i] if n.isLeaf { elem := p.leafPageElement(uint16(i)) inode.flags = elem.flags inode.key = elem.key() inode.value = elem.value() } else { elem := p.branchPageElement(uint16(i)) inode.pgid = elem.pgid inode.key = elem.key() } _assert(len(inode.key) \u0026gt; 0, \u0026#34;read: zero-length inode key\u0026#34;) } // Save first key so we can find the node in the parent when we spill. if len(n.inodes) \u0026gt; 0 { n.key = n.inodes[0].key _assert(len(n.key) \u0026gt; 0, \u0026#34;read: zero-length node key\u0026#34;) } else { n.key = nil } } node -\u0026gt; page # // write writes the items onto one or more pages. func (n *node) write(p *page) { // Initialize page. if n.isLeaf { p.flags |= leafPageFlag } else { p.flags |= branchPageFlag } if len(n.inodes) \u0026gt;= 0xFFFF { panic(fmt.Sprintf(\u0026#34;inode overflow: %d (pgid=%d)\u0026#34;, len(n.inodes), p.id)) } p.count = uint16(len(n.inodes)) // Stop here if there are no items to write. if p.count == 0 { return } // Loop over each item and write it to the page. b := (*[maxAllocSize]byte)(unsafe.Pointer(\u0026amp;p.ptr))[n.pageElementSize()*len(n.inodes):] for i, item := range n.inodes { _assert(len(item.key) \u0026gt; 0, \u0026#34;write: zero-length inode key\u0026#34;) // Write the page element. if n.isLeaf { elem := p.leafPageElement(uint16(i)) elem.pos = uint32(uintptr(unsafe.Pointer(\u0026amp;b[0])) - uintptr(unsafe.Pointer(elem))) elem.flags = item.flags elem.ksize = uint32(len(item.key)) elem.vsize = uint32(len(item.value)) } else { elem := p.branchPageElement(uint16(i)) elem.pos = uint32(uintptr(unsafe.Pointer(\u0026amp;b[0])) - uintptr(unsafe.Pointer(elem))) elem.ksize = uint32(len(item.key)) elem.pgid = item.pgid _assert(elem.pgid != p.id, \u0026#34;write: circular dependency occurred\u0026#34;) } // If the length of key+value is larger than the max allocation size // then we need to reallocate the byte array pointer. // // See: https://github.com/boltdb/bolt/pull/335 klen, vlen := len(item.key), len(item.value) if len(b) \u0026lt; klen+vlen { b = (*[maxAllocSize]byte)(unsafe.Pointer(\u0026amp;b[0]))[:] } // Write data for the element to the end of the page. copy(b[0:], item.key) b = b[klen:] copy(b[0:], item.value) b = b[vlen:] } // DEBUG ONLY: n.dump() } bucket # // Bucket represents a collection of key/value pairs inside the database. type Bucket struct { *bucket tx *Tx // the associated transaction buckets map[string]*Bucket // subbucket cache page *page // inline page reference rootNode *node // materialized node for the root page. nodes map[pgid]*node // node cache // Sets the threshold for filling nodes when they split. By default, // the bucket will fill to 50% but it can be useful to increase this // amount if you know that your write workloads are mostly append-only. // // This is non-persisted across transactions so it must be set in every Tx. FillPercent float64 } // bucket represents the on-file representation of a bucket. // This is stored as the \u0026#34;value\u0026#34; of a bucket key. If the bucket is small enough, // then its root page can be stored inline in the \u0026#34;value\u0026#34;, after the bucket // header. In the case of inline buckets, the \u0026#34;root\u0026#34; will be 0. type bucket struct { root pgid // page id of the bucket\u0026#39;s root-level page sequence uint64 // monotonically incrementing, used by NextSequence() } "},{"id":32,"href":"/docs/Java/Cleaner/","title":"Cleaner 类","section":"Java","content":" 参考文献 # https://openjdk.org/jeps/421 https://inside.java/2022/05/25/clean-cleaner/ https://docs.oracle.com/javase/9/docs/api/java/lang/ref/Cleaner.html "},{"id":33,"href":"/docs/Java/JDBC/","title":"JDBC","section":"Java","content":" JDBC # 本教程使用 MySQL 数据库。\n主要参考：https://docs.oracle.com/javase/tutorial/jdbc/basics/index.html\n建立连接 # 数据源可以是数据库管理系统 (DBMS)、传统文件系统或其他带有相应 JDBC 驱动的数据源。通常，JDBC 使用以下两种类之一来连接目标数据源：\nDriverManager：用于将应用程序连接到通过数据库 URL 指定的数据源。当此类首次尝试建立连接时，它会自动加载类路径中找到的任何 JDBC 4.0 驱动程序。必须手动加载任何 4.0 版本之前的 JDBC 驱动程序。 DataSource：相比于 DriverManager，更推荐使用此接口，因为它允许应用程序对底层数据源的细节保持透明。DataSource 对象的属性被设置为表示特定的数据源。 使用 DriverManager 类 # String url = \u0026#34;jdbc:mysql://localhost:3306/db\u0026#34;; String username = \u0026#34;root\u0026#34;, password = \u0026#34;0987654321\u0026#34;; Connection conn = DriverManager.getConnection(url, username, password); 使用 JDBC 处理 SQL 语句 # 新建一个 user 表，如下图所示：\n使用 conn 对象创建 Statement，使用 stmt 执行 SQL 语句。\nResultSet 保存了执行 SQL 语句的结果，可以遍历保存的结果。\nString query = \u0026#34;SELECT * FROM `user`;\u0026#34;; try (Statement stmt = conn.createStatement()) { ResultSet rs = stmt.executeQuery(query); while (rs.next()) { int id = rs.getInt(1); String name = rs.getString(2); int age = rs.getInt(3); String email = rs.getString(4); System.out.printf(\u0026#34;id: %d, name: %s, age: %d, email: %s.\\n\u0026#34;, id, name, age, email); } } 使用 PreparedStatements # 如果需要多次执行一个 Statement 对象，使用 PreparedStatement 对象可以减少执行时间。\nPreparedStatement 对象的主要特点是，与 Statement 对象不同，它在创建时就指定了一个SQL语句。这样做的优势在于，在大多数情况下，这个 SQL 语句会立即发送到 DBMS（数据库管理系统），并在那儿编译。\n因此，PreparedStatement 对象不仅包含一个 SQL 语句，还包含一个已经预编译的 SQL 语句。这意味着，当执行 PreparedStatement 时，DBMS 可以直接运行预编译的 SQL 语句，而无需先编译它。\n可以将 PreparedStatement 对象用于没有参数的 SQL 语句，但更可能用于处理带参数的 SQL 语句。使用带参数的 SQL 语句的优势在于，可以使用相同的语句并在每次执行时为其提供不同的值。\n然而，PreparedStatement 最重要的优势是，它有助于防止 SQL 注入攻击。PreparedStatement 始终将客户端提供的数据视为参数的内容，而不是 SQL 语句的一部分。\nString query = \u0026#34;INSERT INTO `user` (name, age, email) VALUES (?, ?, ?)\u0026#34;; try (PreparedStatement ps = conn.prepareStatement(query)) { ps.setString(1, \u0026#34;Ile\u0026#34;); ps.setInt(2, 20); ps.setString(3, \u0026#34;ile@baomidou.com\u0026#34;); ps.executeUpdate(); } 事务处理 # 使用之前，需要通过 conn.setAutoCommit(false); 关闭事务自动提交。\n使用 commit() 提交事务，rollback() 回滚事务。\nString url = \u0026#34;jdbc:mysql://localhost:3306/db\u0026#34;; String username = \u0026#34;root\u0026#34;, password = \u0026#34;0987654321\u0026#34;; Connection conn = DriverManager.getConnection(url, username, password); conn.setAutoCommit(false); String query = \u0026#34;INSERT INTO `user` (name, age, email) VALUES (?, ?, ?)\u0026#34;; try (PreparedStatement ps = conn.prepareStatement(query)) { ps.setString(1, \u0026#34;Ile\u0026#34;); ps.setInt(2, 20); ps.setString(3, \u0026#34;ile@baomidou.com\u0026#34;); ps.executeUpdate(); conn.commit(); } catch (SQLException e) { conn.rollback(); } "},{"id":34,"href":"/docs/JVM/loading-linking-initializing/","title":"JVM 加载-链接-初始化","section":"JVM","content":" JVM 加载-链接-初始化 # 类加载过程 # 加载（loads） # 加载（loads）是查找具有特定名称的类或接口类型的二进制表示，并从该二进制表示创建类或接口的过程。加载过程如下：\n通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区（Method Area）的运行时数据结构。 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口。 类加载链接的目的就是在 JVM 中创建相应的类结构\n启动类加载器之外，其他的类加载器都是 java.lang.ClassLoader 的子类\n-verbose:class 参数可用于打印类加载的先后顺序\n链接（links） # 链接（links）是获取类或接口，并将其组合到 Java 虚拟机的运行时状态以便执行的过程。\n初始化（initializes） # 类或接口的初始化（initializes）包括执行类或接口初始化方法 \u0026lt;clinit\u0026gt;。\n类加载器（class loader） # 启动类加载器（bootstrap class loader）由 C++ 实现，\n除了启动类加载器之外，其它的类加载器都是 java.lang.ClassLoader 的子类，因此有对应的 Java 对象。这些类加载器需要先由另一个类加载器，比如说启动类加载器，加载至 Java 虚拟机中，方能执行类加载。\n双亲委派模型 # JDK 9 前 # 启动类加载器（Bootstrap Class Loader）：用于加载 扩展类加载器（Extension Class Loader）: 应用程序类加载器（Application Class Loader）: 可输出 BootstrapClassLoader 可加载的类。\nURLClassPath bootstrapClassPath = Launcher.getBootstrapClassPath(); for (URL url : bootstrapClassPath.getURLs()) { System.out.println(url.getFile()); } ${JAVA_HOME}/lib/resources.jar ${JAVA_HOME}/lib/rt.jar ${JAVA_HOME}/lib/sunrsasign.jar ${JAVA_HOME}/lib/jsse.jar ${JAVA_HOME}/lib/jce.jar ${JAVA_HOME}/lib/charsets.jar ${JAVA_HOME}/lib/jfr.jar ${JAVA_HOME}/classes JDK 9 后 # "},{"id":35,"href":"/docs/Java/MethodHandles/","title":"MethodHandles","section":"Java","content":" MethodHandles # 翻译自： https://dev.java/learn/introduction_to_method_handles/\n什么是方法句柄（What are method handles） # 方法句柄是一种用于查找和调用方法的低级机制。与反射一样，方法句柄也提供了调用方法、调用构造函数以及访问字段的手段。\n那么，方法句柄究竟什么是呢？它是对底层方法、构造函数或字段的可调用引用。方法句柄允许在一个简单的指向方法的引用之上进行一系列操作，这些操作包括插入或重新排列参数、转换返回值等。\n让我们深入探讨一下方法句柄能够提供什么功能以及我们如何有效地使用它们。\n访问检查（Access checking） # 方法句柄的访问检查与反射的执行方式是不同的。使用反射时，每次调用都会对调用者进行访问检查。而对于方法句柄，访问检查只在方法句柄创建时进行。\n需要注意的是，如果在能够访问非公共成员的上下文中创建了方法句柄，那么当该方法句柄被传递到外部时，可以通过方法句柄访问非公共成员。\n因此，非公共成员可能会被不应有访问权限的代码访问。开发者有责任将此类方法句柄限制在其创建的上下文内。另外，可以直接使用合适的查找对象来创建具有访问限制的方法句柄。\n方法句柄查找（Method handle lookup） # 要创建方法句柄，我们首先需要创建一个 LookUp 对象，此为创建方法句柄的工厂。根据 Lookup 对象本身或方法句柄的使用方式，我们可以决定是否需要限制其访问级别。\n例如，如果我们创建了一个指向私有方法的方法句柄，并且该方法句柄可以从外部访问，那么该私有方法也就可以被外部访问（译者注：现在，外部代码可以直接调用原本受保护的私有方法，从而破坏了方法的私有性）。\n通常我们希望避免这种情况。一种办法是将 Lookup 对象和方法句柄设为私有。另一种方法是使用 MethodHandles.publicLookup 方法创建 Lookup 对象，这样它只能查找公共类的公共成员（译者注：未导出的包，或受保护或私有的类和成员不会被搜索到）：\nMethodHandles.Lookup publicLookup = MethodHandles.publicLookup(); 如果我们打算将 Lookup 对象和方法句柄设为私有，那么访问私有和受保护的成员是安全的（外部无法访问私有的方法句柄）：\nMethodHandles.Lookup lookup = MethodHandles.lookup(); 方法类型（Method type） # 要查找方法句柄，我们还需要提供方法或字段的类型信息。方法的类型信息通过 MethodType 类表示。为了实例化一个 MethodType 对象，需要提供函数返回类型作为第一个形参，后跟函数所有实参类型:\nMethodType methodType = MethodType.methodType(int.class /* the method returns integer */, String.class /* and accepts a single String argument*/); 有了 Lookup 和 MethodType 实例后，我们就可以查找方法句柄了。\n对于实例方法，我们应该使用 Lookup.findVirtual。\n对于静态方法，我们应该使用 Lookup.findStatic。\n这两种方法都接收以下参数：方法所在的 Class，表示方法名称的 String，以及一个 MethodType。\n在下面的示例中，我们使用 Lookup.findVirtual 方法查找一个实例方法 String.replace，该方法接收两个 char 参数并返回一个 String：\nMethodHandles.Lookup lookup = MethodHandles.lookup(); MethodType replaceMethodType = MethodType.methodType(String.class, char.class, char.class); MethodHandle replaceMethodHandle = lookup.findVirtual(String.class, \u0026#34;replace\u0026#34;, replaceMethodType); 在下一个示例中，我们使用 Lookup.findStatic 来查找一个静态方法 String.valueOf，该方法接收一个 Object 参数并返回一个 String：\nMethodType valueOfMethodType = MethodType.methodType(String.class, Object.class); MethodHandle valueOfMethodHandle = lookup.findStatic(String.class, \u0026#34;valueOf\u0026#34;, valueOfMethodType); 类似地，我们可以使用 Lookup.findConstructor 方法来查找指向任何构造函数的方法句柄。\n最后，当我们获得了一个方法句柄时，我们可以用此调用引用的方法。\n调用方法句柄（Method handle invocation） # 可以通过多种方式调用方法句柄引用的方法。\n所有调用的方法最终都会汇集到一个方法上： MethodHandle.invokeExact。正如方法名称所示，提供给 invokeExact 方法的参数必须严格匹配方法句柄的类型。\n例如，如果我们调用 String.replace 方法，参数必须严格对应于：返回类型为 String 和两个 char 参数：\nMethodType replaceMethodType = MethodType.methodType(String.class, char.class, char.class); MethodHandle replaceMethodHandle = lookup.findVirtual(String.class, \u0026#34;replace\u0026#34;, replaceMethodType); String result = (String) replaceMethodHandle.invokeExact(\u0026#34;dummy\u0026#34;, \u0026#39;d\u0026#39;, \u0026#39;m\u0026#39;); MethodHandle.invoke 更为宽松。它尝试获取一个具有调整类型的新方法句柄，使其严格匹配提供的参数的类型。然后，使用 invokeExact 调用已调整的方法句柄。\nString result = (String) replaceMethodHandle.invoke((Object)\u0026#34;dummy\u0026#34;, (Object)\u0026#39;d\u0026#39;, (Object)\u0026#39;m\u0026#39;); // would fail with `invokeExact` 另一种调用方法句柄的替代方法是使用 MethodHandle.invokeWithArguments。这种方法调用的结果等同于 invoke，区别在于此方法允许你将所有参数打包成一个 Object 类型的数组或 List，然后传递给方法。。\n该方法的一个有趣特性是，如果提供的参数数量超过了实际的数量，所有多出的参数将被压缩到最后一个参数中，并将其视为一个数组。\n访问属性（Accessing fields） # 下边的代码示例演示了如何创建对字段的读取或写入的方法句柄：\n对于实例字段（Instance Fields），可以使用 findGetter 和 findSetter 方法。\n对于静态字段（Static Fields），可以使用 findStaticGetter 和 findStaticSetter 方法。\n在创建访问属性的方法句柄时，不需要提供 MethodType 实例，需要提供字段的类型。\n静态字段 # 例如，假设我们在 Example 类中有一个静态字段 magic：\nprivate static String magic = \u0026#34;initial value static field\u0026#34;; 假设我们已经创建了一个 Lookup 对象：\nMethodHandles.Lookup lookup = MethodHandles.lookup(); 我们可以简单地创建 setter 和 getter 方法句柄，并分别调用它们：\nMethodHandle setterStaticMethodHandle = lookup.findStaticSetter(Example.class, \u0026#34;magic\u0026#34;, String.class); MethodHandle getterStaticMethodHandle = lookup.findStaticGetter(Example.class, \u0026#34;magic\u0026#34;, String.class); setterStaticMethodHandle.invoke(\u0026#34;new value static field\u0026#34;); String staticFieldResult = (String) getterStaticMethodHandle.invoke(); // staticFieldResult == `new value static field` 实例字段 # 在 Example 类中有一个名为 abc 的实例字段：\nprivate String abc = \u0026#34;initial value\u0026#34;; 类似地，我们可以为读取和写入实例字段创建方法句柄：\nMethodHandle setterMethodHandle = lookup.findSetter(Example.class, \u0026#34;abc\u0026#34;, String.class); MethodHandle getterMethodHandle = lookup.findGetter(Example.class, \u0026#34;abc\u0026#34;, String.class); 要使用实例字段的 setter 和 getter 方法句柄，必须获取字段所属类的实例：\nExample example = new Example(); 然后，为我们的 setter 和 getter 的调用提供 Example 的实例：\nsetterMethodHandle.invoke(example, \u0026#34;new value\u0026#34;); String result = (String) getterMethodHandle.invoke(example); // result == `new value` 虽然可以使用方法句柄读取和写入字段值，但这并不常见。对于字段，更适合使用 VarHandle，可以使用 findVarHandle 和 findStaticVarHandle 方法创建。\n处理数组（Working with arrays） # MethodHandles 类提供了一些预设方法句柄的方法。其中包括操作数组的方法句柄。创建这些方法句柄不需要访问检查，因此不需要 Lookup 对象。\n我们使用 arrayConstructor 创建一个包含 5 个元素的 String 数组：\nMethodHandle arrayConstructor = MethodHandles.arrayConstructor(String[].class); String[] arr = (String[]) arrayConstructor.invoke(5); 要修改单个元素，我们可以使用 arrayElementSetter，使用该方法需要提供要操作数组的引用、索引和新值：\nMethodHandle elementSetter = MethodHandles.arrayElementSetter(String[].class); elementSetter.invoke(arr, 4, \u0026#34;test\u0026#34;); 要读取单个元素的值，我们应该使用 arrayElementGetter 方法句柄，需要提供目标数组和索引：\nMethodHandle elementGetter = MethodHandles.arrayElementGetter(String[].class); String element = (String) elementGetter.invoke(arr, 4); // element == \u0026#34;test\u0026#34; 还可以使用 arrayLength 提供的方法句柄获取数组的长度：\nMethodHandle arrayLength = MethodHandles.arrayLength(String[].class); int length = (int) arrayLength.invoke(arr); // length == 5 异常处理（Exception handling） # invokeExact 和 invoke 都会抛出 Throwable，因此对底层方法可抛出的异常没有任何限制。调用方法句柄的方法必须明确抛出 Throwable 或捕获它。\nMethodHandles 中有一些方法可以使异常处理变得更加简单。让我们看几个示例。\ncatch wrapper # MethodHandles.catchException 方法可以将给定的方法句柄包装在提供的异常处理方法句柄中。\n假设我们有一个执行某些业务逻辑的方法 problematicMethod，以及一个处理 IllegalArgumentException 异常的方法 exceptionHandler。\n异常处理程序方法必须返回与原始方法相同的类型。接收的第一个参数是我们感兴趣的 Throwable 类，第二个参数是原方法接收的参数：\npublic static int problematicMethod(String argument) throws IllegalArgumentException { if (\u0026#34;invalid\u0026#34;.equals(argument)) { throw new IllegalArgumentException(); } return 1; } public static int exceptionHandler(IllegalArgumentException e, String argument) { // log exception return 0; } 我们可以查找这两个方法的方法句柄，并将 problematicMethod 包装在 exceptionHandler 内。MethodHandle 在调用时会正确处理 IllegalArgumentException，如果出现其他异常，则会继续抛出。\nMethodHandles.Lookup lookup = MethodHandles.lookup(); MethodHandle methodHandle = lookup.findStatic(Example.class, \u0026#34;problematicMethod\u0026#34;, MethodType.methodType(int.class, String.class)); MethodHandle handler = lookup.findStatic(Example.class, \u0026#34;exceptionHandler\u0026#34;, MethodType.methodType(int.class, IllegalArgumentException.class, String.class)); MethodHandle wrapped = MethodHandles.catchException(methodHandle, IllegalArgumentException.class, handler); System.out.println(wrapped.invoke(\u0026#34;valid\u0026#34;)); // outputs \u0026#34;1\u0026#34; System.out.println(wrapped.invoke(\u0026#34;invalid\u0026#34;)); // outputs \u0026#34;0\u0026#34; finally wrapper # MethodHandles.tryFinally 方法的工作方式与 catch wrapper 类似，但它不是一个异常处理程序，而是在目标方法周围添加了一个 try-finally 块。\n假设我们有一个包含清理逻辑的方法 cleanupMethod。该方法的返回类型必须与被包装的目标方法返回类型相同。此外，方法参数需要接收一个 Throwable，然后是来自目标方法的结果值，然后是所有参数。\npublic static int cleanupMethod(Throwable e, int result, String argument) { System.out.println(\u0026#34;inside finally block\u0026#34;); return result; } 我们可以将前面示例中的方法句柄包装在 try-finally 块中，如下所示：\nMethodHandle cleanupMethod = lookup.findStatic(Example.class, \u0026#34;cleanupMethod\u0026#34;, MethodType.methodType(int.class, Throwable.class, int.class, String.class)); MethodHandle wrappedWithFinally = MethodHandles.tryFinally(methodHandle, cleanupMethod); System.out.println(wrappedWithFinally.invoke(\u0026#34;valid\u0026#34;)); // outputs \u0026#34;inside finally block\u0026#34; and \u0026#34;1\u0026#34; System.out.println(wrappedWithFinally.invoke(\u0026#34;invalid\u0026#34;)); // outputs \u0026#34;inside finally block\u0026#34; and throws java.lang.IllegalArgumentException 方法句柄转换（Method handle transformations） # 正如前面的例子所示，方法句柄可以进行封装，封装后会拥有比指向底层方法更多的行为。\n我们可以获取适配器方法句柄，包装目标方法句柄以添加某些行为，如：参数重排序、预先插入或过滤返回值。\n类型转换 # 方法句柄的类型可以使用 asType 方法转换为新类型。如果不可能转换为此类型，将收到 WrongMethodTypeException 异常。\n请记住，当我们应用转换时，实际上我们有两个方法句柄，其中原始的方法句柄被封装在一些额外的逻辑中。在这种情况下，封装器会接收参数，并尝试将它们转换为与原始方法句柄的参数相匹配的类型。一旦原始方法句柄完成其工作并返回结果，封装器将尝试将这个结果转换为指定的类型。\n假设我们有一个 test 方法，接收一个 Object 并返回一个 String。我们可以将这样一个方法适应为接收更具体的参数类型，如 String：\nMethodHandle targetMethodHandle = lookup.findStatic(Example.class, \u0026#34;test\u0026#34;, MethodType.methodType(String.class, Object.class)); MethodHandle adapter = targetMethodHandle.asType( MethodType.methodType(String.class, String.class)); String originalResult = (String) targetMethodHandle.invoke(111); // works String adapterResult = (String) adapter.invoke(\u0026#34;aaaaaa\u0026#34;); // works adapterResult = (String) adapter.invoke(111); // fails 事实上，每次我们在 MethodHandle 上调用 invoke 时，首先发生的是一次 asType 调用。invoke 接收并返回对象，然后尝试将这些对象转换为更具体的类型。这些具体的类型来自我们的代码，即我们作为参数传递的确切值和我们将返回值转换成的类型。一旦类型成功转换，就会调用 invokeExact 方法来处理这些具体类型。\n重新排列参数 # 要获取一个带有重新排列参数的适配器方法句柄，我们可以使用 MethodHandles.permuteArguments。\n首先，我们有一个接受不同类型参数的 test 方法：\npublic static void test(int v1, String v2, long v3, boolean v4) { System.out.println(v1 + v2 + v3 + v4); } 查找一个指向 test 方法的方法句柄：\nMethodHandle targetMethodHandle = lookup.findStatic(Example.class, \u0026#34;test\u0026#34;, MethodType.methodType(void.class, int.class, String.class, long.class, boolean.class)); permuteArguments 方法会接收下边参数：\n目标方法句柄，在我们的例子中指向 test 方法。 新的 MethodType，其中所有参数以所需的方式重新排序。 一个指定参数新顺序的索引数组。 MethodHandle reversedArguments = MethodHandles.permuteArguments(targetMethodHandle, MethodType.methodType(void.class, boolean.class, long.class, String.class, int.class), 3, 2, 1, 0); reversedArguments.invoke(false, 1L, \u0026#34;str\u0026#34;, 123); // outputs: \u0026#34;123str1false\u0026#34; 插入参数 # MethodHandles.insertArguments 方法提供了一个带有一个或多个绑定参数的 MethodHandle。\n例如，让我们再次查看前面示例中的方法句柄：\nMethodHandle targetMethodHandle = lookup.findStatic(Example.class, \u0026#34;test\u0026#34;, MethodType.methodType(void.class, int.class, String.class, long.class, boolean.class)); 我们可以轻松地获取一个预先带有 String 和 long 参数绑定的适配器 MethodHandle：\nMethodHandle boundArguments = MethodHandles.insertArguments(targetMethodHandle, 1, \u0026#34;new\u0026#34;, 3L); 要调用生成的方法句柄，我们只需要提供未预先填充的参数：\nboundArguments.invoke(1, true); // outputs: \u0026#34;1new3true\u0026#34; 如果我们尝试传递已经预填充的参数，此方法会抛出 WrongMethodTypeException 异常。\n过滤参数 # 我们可以使用 MethodHandles.filterArguments 在调用目标方法句柄之前对参数进行转换。\n为使用此方法，我们需要提供一下参数：\n目标方法句柄。 要转换的第一个参数的位置。 用于每个参数转换的方法句柄。 如果某些参数不需要转换，可以传递 null 跳过。如果我们只需要转换其中的一部分参数，也可以完全跳过其余参数。\n让我们重用上一节中的方法句柄，并在调用之前过滤其中的一些参数。\nMethodHandle targetMethodHandle = lookup.findStatic(Example.class, \u0026#34;test\u0026#34;, MethodType.methodType(void.class, int.class, String.class, long.class, boolean.class)); 然后我们创建一个方法，通过对 original 取反进行转换：\nprivate static boolean negate(boolean original) { return !original; } 额外构造一个方法，通过增加给定的整数值进行转换：\nprivate static int increment(int original) { return ++original; } 我们可以为这些转换方法获取方法句柄：\nMethodHandle negate = lookup.findStatic(Example.class, \u0026#34;negate\u0026#34;, MethodType.methodType(boolean.class, boolean.class)); MethodHandle increment = lookup.findStatic(Example.class, \u0026#34;increment\u0026#34;, MethodType.methodType(int.class, int.class)); 使用它们来获得一个可以进行参数过滤的方法句柄：\n// applies filter \u0026#39;increment\u0026#39; to argument at index 0, \u0026#39;negate\u0026#39; to the last argument, // and passes the result to \u0026#39;targetMethodHandle\u0026#39; MethodHandle withFilters = MethodHandles.filterArguments(targetMethodHandle, 0, increment, null, null, negate); withFilters.invoke(3, \u0026#34;abc\u0026#34;, 5L, false); // outputs \u0026#34;4abc5true\u0026#34; 折叠参数 # 当我们想要在调用 MethodHandle 之前对一个或多个参数进行预处理时，我们可以使用 MethodHandles.foldArguments，并提供一个组合方法的方法句柄，该方法将接受从任意首选位置开始的参数。\n假设我们有一个 target 方法：\nprivate static void target(int ignored, int sum, int a, int b) { System.out.printf(\u0026#34;%d + %d equals %d and %d is ignored%n\u0026#34;, a, b, sum, ignored); } 使用 foldArguments，我们可以预处理其参数的一个子集，并将结果值插入为另一个参数，然后继续执行 target 方法。\n在我们的示例中，我们有参数 int a，int b 在最后。我们可以预处理任意数量的参数，但它们都必须在最后。假设我们想要计算 a 和 b 这两个值的和，因此让我们创建一个用于此目的的方法：\nprivate static int sum(int a, int b) { return a + b; } 结果值将被插入到目标方法中的一个参数。它必须是我们将要折叠的参数之前的参数，所以在我们的示例中是参数 int sum。\n用于折叠结果的参数不能位于其他位置。如果目标方法需要接受与此折叠逻辑无关的更多参数，则它们必须全部放在最前面。\n让我们创建方法句柄并看看如何将它们组合在一起：\nMethodHandle targetMethodHandle = lookup.findStatic(Example.class, \u0026#34;target\u0026#34;, MethodType.methodType(void.class, int.class, int.class, int.class, int.class)); MethodHandle combinerMethodHandle = lookup.findStatic(Example.class, \u0026#34;sum\u0026#34;, MethodType.methodType(int.class, int.class, int.class)); MethodHandle preProcessedArguments = MethodHandles.foldArguments(targetMethodHandle, 1, combinerMethodHandle); foldArguments 方法接受：\nMethodHandle target: 目标方法的句柄，在我们的例子中为指向 target 方法的句柄。 int pos: 一个整数，指定折叠相关的参数的起始位置。在我们的例子中，sum 参数位于位置 1，因此我们传递了 1。如果跳过此参数，pos 将默认为 0。 MethodHandle combiner: 组合方法句柄，在我们的例子中为指向 sum 方法的句柄。 最后，我们可以调用生成的方法句柄，并传递除 sum 之外的所有参数，sum 将被预先计算：\npreProcessedArguments.invokeExact(10000, 1, 2); // outputs: \u0026#34;1 + 2 equals 3 and 10000 is ignored\u0026#34; 有可能组合方法处理值但不返回任何内容。在这种情况下，目标方法参数列表中不需要结果占位符。\n过滤返回值 # 与参数类似，我们可以使用一个适配器来对返回值进行转换。\n假设我们有一个返回 String 的方法，并且我们想将该方法返回的任何值传递到另一个方法中，该方法将字符 d 替换为 m 并将结果值大写。\n这是 getSomeString 方法的方法句柄，它始终返回值 \u0026quot;dummy\u0026quot;:\nMethodHandle getSomeString = lookup.findStatic(Example.class, \u0026#34;getSomeString\u0026#34;, MethodType.methodType(String.class)); 这是执行转换的 resultTransform 方法：\nprivate static String resultTransform(String value) { return value.replace(\u0026#39;d\u0026#39;, \u0026#39;m\u0026#39;).toUpperCase(); } 这是指向转换方法的方法句柄：\nMethodHandle resultTransform = lookup.findStatic(Example.class, \u0026#34;resultTransform\u0026#34;, MethodType.methodType(String.class, String.class)); 最后，这是两个方法句柄的组合，其中由 getSomeString 方法返回的结果提供给 resultTransform 方法并相应地进行修改：\nMethodHandle getSomeUppercaseString = MethodHandles.filterReturnValue(getSomeString, resultTransform); System.out.println(getSomeUppercaseString.invoke()); // outputs: \u0026#34;MUMMY\u0026#34; 方法句柄与反射（Method Handles vs Reflection API） # 方法句柄是在 JDK7 中引入的，作为协助编译器和语言运行时开发人员的工具。它们从未旨在取代反射。\n反射 提供了一些方法句柄无法做到的功能，即列出类成员并检查它们的属性。另一方面，方法句柄可以以反射无法实现的方式进行转换和操作。\n当涉及方法调用时，与访问检查和安全性有关的差异为：\n反射：在每次调用时会对每个调用者都执行访问检查。 方法句柄：仅在构建过程中进行访问检查。 上边的差异使得通过方法句柄调用比反射更快。然而，必须采取某些预防措施，以确保方法句柄不被传递到不应访问的代码中。\n您可以在 本教程 中了解更多关于反射的信息。\n反射和方法句柄之间的转换（Conversion between Reflection API and method handles） # Lookup 对象可以用于将反射对象转换为行为上等效的方法句柄，从而提供对底层类成员更直接和高效的访问。\n要创建指向给定 Method 的方法句柄（假设查找类具有执行此操作的权限），可以使用 unreflect。\n假设我们在 Example 类中有一个接受 String 参数并返回 String 的测试方法。使用反射，我们可以获得一个 Method 对象：\nMethod method = Example.class.getMethod(\u0026#34;test\u0026#34;, String.class); 借助于 Lookup 对象的帮助，我们可以使用 unreflect 方法传入 Method 对象以获取 MethodHandle：\nMethodHandles.Lookup lookup = MethodHandles.lookup(); MethodHandle methodHandle = lookup.unreflect(method); String result = (String) methodHandle.invoke(\u0026#34;something\u0026#34;); 类似地，给定一个 Field 对象，我们可以获得 getter 和 setter 方法句柄：\nField field = Example.class.getField(\u0026#34;magic\u0026#34;); MethodHandle setterMethodHandle = lookup.unreflectSetter(field); MethodHandle getterMethodHandle = lookup.unreflectGetter(field); setterMethodHandle.invoke(\u0026#34;something\u0026#34;); String result = (String) getterMethodHandle.invoke(); // result == \u0026#34;something\u0026#34; 还可以将 MethodHandle 转换为 Member，前提是没有对给定的 MethodHandle 执行任何转换。\n假设我们有一个直接指向方法的方法句柄。我们可以使用 MethodHandles.reflectAs 方法获取 Method 对象：\nMethod method = MethodHandles.reflectAs(Method.class, methodHandle); 对于 Field 对象也是类似的：\nField field = MethodHandles.reflectAs(Field.class, getterMethodHandle); // same result is achieved by reflecting `setterMethodHandle` 结论（Conclusion） # 在本教程中，我们深入了解了方法句柄机制，学会了如何高效地使用它。我们现在知道，方法句柄提供了一种高效调用方法的方式，但这种机制并不旨在取代反射。\n由于方法句柄采用不同的访问检查方法，方法句柄在方法调用方面具有性能优势。然而，由于访问仅在方法句柄创建时进行检查，因此传递方法句柄应格外谨慎。\n与反射不同，方法句柄不提供列出类成员和检查其属性的工具。另一方面，方法句柄允许我们将指向方法和字段的指针包装成更复杂的逻辑，如：参数和返回值的操作。\n"},{"id":36,"href":"/docs/Java/DynamicProxy/","title":"动态代理","section":"Java","content":" 动态代理 # 在 Java 动态代理机制中，InvocationHandler 接口和 Proxy 类是核心。\nProxy # Proxy 类主要使用 newProxyInstance() 静态方法生成代理对象。\npublic static Object newProxyInstance(ClassLoader loader, Class\u0026lt;?\u0026gt;[] interfaces, InvocationHandler h) { ... } 该方法主要有三个参数：\nloader：定义代理类的类加载器。 interfaces：代理类要实现的接口列表。 h：用于分发方法调用的调用处理器。 InvocationHandler # 当动态代理对象调用一个方法时，此方法的调用就会被转发到实现 InvocationHandler 接口类的 invoke 方法来调用。\npublic interface InvocationHandler { public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; } 该方法主要有三个参数：\nproxy：动态生成的代理类的实例。 method：代理类对象调用的方法。 args：调用 method 方法的参数。 通过 Proxy 类的 newProxyInstance() 创建的代理对象在调用方法的时候，实际会调用到实现 InvocationHandler 接口的类的 invoke() 方法。\n具体步骤 # TargetClass 类继承自 InterfaceA 和 InterfaceB 接口。\n如果想在 targetA() 和 targetB() 方法调用前后进行一些额外操作。\ninterface InterfaceA { void targetA(); } interface InterfaceB { void targetB(); } class TargetClass implements InterfaceA, InterfaceB { @Override public void targetA() { System.out.println(\u0026#34;Target A\u0026#34;); } @Override public void targetB() { System.out.println(\u0026#34;Target B\u0026#34;); } } 在 InvocationHandler 中的 invoke 方法中定义额外的操作。\nclass SimpleInvocationHandler implements InvocationHandler { private final Object target; public SimpleInvocationHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.printf(\u0026#34;Before invocation method %s\\n\u0026#34;, method.getName()); Object result = method.invoke(target, args); System.out.printf(\u0026#34;After invocation method %s\\n\u0026#34;, method.getName()); return result; } } 通过 Proxy.newProxyInstance 方法生成代理对象。\npublic static void main(String[] args) { System.setProperty(\u0026#34;jdk.proxy.ProxyGenerator.saveGeneratedFiles\u0026#34;, \u0026#34;true\u0026#34;); TargetClass target = new TargetClass(); SimpleInvocationHandler handler = new SimpleInvocationHandler(target); Object o = Proxy.newProxyInstance( TargetClass.class.getClassLoader(), new Class[]{InterfaceA.class, InterfaceB.class}, handler ); ((InterfaceA) o).targetA(); ((InterfaceB) o).targetB(); } 原理 # 生成的类会继承自 Proxy 类，实现调用 newInstance() 方法时传入的 interfaces 中的所有接口。\n被代理的类中的所有方法会被收集为 Method 方法。当通过代理对象调用方法时，会转发到传入的 InvocationHandler 中。\n传入到 h.invoke 中的参数分别为：\nthis：被代理对象实例。 m*：调用的具体方法。 args：调用方法传入的参数。 // // Source code recreated from a .class file by IntelliJ IDEA // (powered by FernFlower decompiler) // import java.lang.invoke.MethodHandles; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; final class $Proxy0 extends Proxy implements InterfaceA, InterfaceB { private static final Method m0; private static final Method m1; private static final Method m2; private static final Method m3; private static final Method m4; public $Proxy0(InvocationHandler var1) { super(var1); } public final int hashCode() { try { return (Integer)super.h.invoke(this, m0, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final boolean equals(Object var1) { try { return (Boolean)super.h.invoke(this, m1, new Object[]{var1}); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetA() { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetB() { try { super.h.invoke(this, m4, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { ClassLoader var0 = $Proxy0.class.getClassLoader(); try { m0 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;hashCode\u0026#34;); m1 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;equals\u0026#34;, Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0)); m2 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;toString\u0026#34;); m3 = Class.forName(\u0026#34;io.github.ileonli.InterfaceA\u0026#34;, false, var0).getMethod(\u0026#34;targetA\u0026#34;); m4 = Class.forName(\u0026#34;io.github.ileonli.InterfaceB\u0026#34;, false, var0).getMethod(\u0026#34;targetB\u0026#34;); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } } private static MethodHandles.Lookup proxyClassLookup(MethodHandles.Lookup var0) throws IllegalAccessException { if (var0.lookupClass() == Proxy.class \u0026amp;\u0026amp; var0.hasFullPrivilegeAccess()) { return MethodHandles.lookup(); } else { throw new IllegalAccessException(var0.toString()); } } } 该代码主要依靠下边两个主要的方法和类：\njava.lang.reflect.Proxy.ProxyBuilder#defineProxyClass\njava.lang.reflect.ProxyGenerator\nProxy 的缺点 # JDK 动态代理有一个最致命的问题是其只能代理实现了接口的类。\n我们对代码进行一些修改，TargetClass 继承了 SuperClass 类。\ninterface InterfaceA { void targetA(); } interface InterfaceB { void targetB(); } abstract class SuperClass { abstract void superClassFunc(); } class TargetClass extends SuperClass implements InterfaceA, InterfaceB { @Override public void targetA() { System.out.println(\u0026#34;Target A\u0026#34;); } @Override public void targetB() { System.out.println(\u0026#34;Target B\u0026#34;); } @Override void superClassFunc() { System.out.println(\u0026#34;Super Class Func\u0026#34;); } } class SimpleInvocationHandler implements InvocationHandler { private final Object target; public SimpleInvocationHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.printf(\u0026#34;Before invocation method %s\\n\u0026#34;, method.getName()); Object result = method.invoke(target, args); System.out.printf(\u0026#34;After invocation method %s\\n\u0026#34;, method.getName()); return result; } } 反编译生成的代码后发现此类只包含实现的接口中的方法。\nimport java.lang.invoke.MethodHandles; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; final class $Proxy0 extends Proxy implements InterfaceA, InterfaceB { private static final Method m0; private static final Method m1; private static final Method m2; private static final Method m3; private static final Method m4; public $Proxy0(InvocationHandler var1) { super(var1); } public final int hashCode() { try { return (Integer)super.h.invoke(this, m0, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final boolean equals(Object var1) { try { return (Boolean)super.h.invoke(this, m1, new Object[]{var1}); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetA() { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetB() { try { super.h.invoke(this, m4, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { ClassLoader var0 = $Proxy0.class.getClassLoader(); try { m0 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;hashCode\u0026#34;); m1 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;equals\u0026#34;, Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0)); m2 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;toString\u0026#34;); m3 = Class.forName(\u0026#34;io.github.ileonli.InterfaceA\u0026#34;, false, var0).getMethod(\u0026#34;targetA\u0026#34;); m4 = Class.forName(\u0026#34;io.github.ileonli.InterfaceB\u0026#34;, false, var0).getMethod(\u0026#34;targetB\u0026#34;); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(((Throwable)var2).getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(((Throwable)var3).getMessage()); } } private static MethodHandles.Lookup proxyClassLookup(MethodHandles.Lookup var0) throws IllegalAccessException { if (var0.lookupClass() == Proxy.class \u0026amp;\u0026amp; var0.hasFullPrivilegeAccess()) { return MethodHandles.lookup(); } else { throw new IllegalAccessException(var0.toString()); } } } "},{"id":37,"href":"/docs/Netty/encoder-and-decoder/","title":"编码器和解码器","section":"Netty","content":" 编码器和解码器 # 编码器：将消息转换为适合于传输的格式（通常是字节流）。 解码器：将网络字节流转换为应用程序的消息格式。 因此，编码器处理出站数据，而解码器处理入站数据。\n解码器 # 由于解码器是负责处理入站数据的，因此，解码器是 ChannelInboundHandler。\n解码器主要有下边两种：\n将字节解码为消息的 ByteToMessageDecoder 和 ReplayingDecoder。 将一种消息类型解码为另一种消息的 MessageToMessageDecoder。 ByteToMessageDecoder # ReplayingDecoder # ReplayingDecoder 扩展了 ByteToMessageDecoder 类，使得我们不必调用 readableBytes() 方法。它通过使用一个自定义的 ByteBuf 实现， ReplayingDecoderByteBuf，包装传入的 ByteBuf 实现了这一点，其将在内部执行该调用\nMessageToMessageDecoder # 编码器 # 编解码器类 # 这些类同时实现了 ChannelInboundHandler 和 ChannelOutboundHandler 接口。\nByteToMessageCodec # MessageToMessageCodec # CombinedChannelDuplexHandler # CombinedChannelDuplexHandler 可将 ChannelInboundHandler 和 ChannelOutboundHandler 结合在一起。\n"}]