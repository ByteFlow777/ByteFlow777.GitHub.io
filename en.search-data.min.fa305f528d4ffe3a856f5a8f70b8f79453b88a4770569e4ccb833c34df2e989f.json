[{"id":0,"href":"/docs/data-structure/avl-tree/","title":"AVL Tree","section":"Data structure","content":"AVL Tree AVL Tree 是平衡二叉树的一种  "},{"id":1,"href":"/docs/lab-report/MIT-6.830/lab1/","title":"Lab 1","section":"MIT 6.830","content":"Lab 1 Exercise 1 Exercise 1 需要我们完成以下文件的代码：\n src/java/simpledb/storage/TupleDesc.java src/java/simpledb/storage/Tuple.java  User 表如下所示：\nid(INT) name(STRING) age(INT)\r1 \u0026quot;张三\u0026quot; 12\r2 \u0026quot;李四\u0026quot; 22\r3 \u0026quot;王二\u0026quot; 54\rTuple.java 表示表中的某一行数据，如：User(1, \u0026ldquo;张三\u0026rdquo;, 12), User(2, \u0026ldquo;李四\u0026rdquo;, 22)\nTupleDesc.java 表示表中字段的类型和名称，如：User{id(INT), name(STRING), age(INT)}\nTupleDesc.java TupleDesc.java 中的静态内部类 TDItem 用于表示某字段的类型（Type fieldType）和名称（String fieldName）。\npublic static class TDItem implements Serializable {\rprivate static final long serialVersionUID = 1L;\r/**\r* The type of the field\r*/\rpublic final Type fieldType;\r/**\r* The name of the field\r*/\rpublic final String fieldName;\rpublic TDItem(Type t, String n) {\rthis.fieldName = n;\rthis.fieldType = t;\r}\rpublic String toString() {\rreturn fieldName + \u0026#34;(\u0026#34; + fieldType + \u0026#34;)\u0026#34;;\r}\r}\r一个表可能有多个字段，我们可以采用 TDItem[] 直接表示表中所有字段的类型和名称。\nTupleDesc 一共提供了两个构造函数：\n 指定字段类型和名称：TupleDesc(Type[] typeAr, String[] fieldAr) 仅指定字段类型，设为匿名名称：TupleDesc(Type[] typeAr)  具体构造函数的实现如下：\n// 匿名字段名称\rpublic static final String UNNAMED = \u0026#34;UNNAMED_FIELD_NAME\u0026#34;;\r// 提供类型和名称\rpublic TupleDesc(Type[] typeAr, String[] fieldAr) {\r// 一共有 n 列\r int n = typeAr.length;\rtdItems = new TDItem[n];\rfor (int i = 0; i \u0026lt; n; i++) {\r// 字段名可能为空，设为匿名\r String fieldName = fieldAr == null ? UNNAMED : fieldAr[i];\rtdItems[i] = new TDItem(typeAr[i], fieldName);\r}\r}\r// 仅提供类型，名称设为匿名\rpublic TupleDesc(Type[] typeAr) {\rthis(typeAr, null);\r}\r可以直接根据 TDItem[] 数组的长度直接获取字段长度。\npublic int numFields() {\rreturn tdItems.length;\r}\r获取第 i 个字段的类型/名称，如果不存在直接抛出 NoSuchElementException 异常。\npublic String getFieldName(int i) throws NoSuchElementException {\rif (i \u0026lt; 0 || i \u0026gt;= tdItems.length) {\rthrow new NoSuchElementException(\u0026#34;Index(\u0026#34; + i + \u0026#34;) out of bound.\u0026#34;);\r}\rreturn tdItems[i].fieldName;\r}\rpublic Type getFieldType(int i) throws NoSuchElementException {\rif (i \u0026lt; 0 || i \u0026gt;= tdItems.length) {\rthrow new NoSuchElementException(\u0026#34;Index(\u0026#34; + i + \u0026#34;) out of bound.\u0026#34;);\r}\rreturn tdItems[i].fieldType;\r}\r通过名称获取字段的索引位置，直接遍历一遍找到字段名相同的即可。\npublic int fieldNameToIndex(String name) throws NoSuchElementException {\rint n = tdItems.length;\rfor (int i = 0; i \u0026lt; n; i++) {\rString fieldName = tdItems[i].fieldName;\rif (fieldName.equals(name)) {\rreturn i;\r}\r}\rthrow new NoSuchElementException(\u0026#34;FieldName(\u0026#34; + name + \u0026#34;) is not exist.\u0026#34;);\r}\r获取字段类型的大小，直接遍历累加所有字段类型大小。\npublic int getSize() {\rint size = 0;\rfor (TDItem item : tdItems) {\r// 累加每列类型的大小\r size += item.fieldType.getLen();\r}\rreturn size;\r}\r合并两个 TupleDesc 为一个 TupleDesc。\npublic static TupleDesc merge(TupleDesc td1, TupleDesc td2) {\rint n1 = td1.numFields(), n2 = td2.numFields(), n = n1 + n2;\rType[] typeAr = new Type[n];\rString[] fieldAr = new String[n];\rint idx = 0;\rfor (int i = 0; i \u0026lt; n1; i++) {\rtypeAr[idx] = td1.getFieldType(i);\rfieldAr[idx] = td1.getFieldName(i);\ridx++;\r}\rfor (int i = 0; i \u0026lt; n2; i++) {\rtypeAr[idx] = td2.getFieldType(i);\rfieldAr[idx] = td2.getFieldName(i);\ridx++;\r}\rreturn new TupleDesc(typeAr, fieldAr);\r}\requals(), hashCode(), toString() 方法如下：\npublic boolean equals(Object o) {\rif (this == o) return true;\rif (o == null || getClass() != o.getClass()) return false;\rTupleDesc tupleDesc = (TupleDesc) o;\rreturn Arrays.equals(tdItems, tupleDesc.tdItems);\r}\rpublic int hashCode() {\rreturn Arrays.hashCode(tdItems);\r}\rpublic String toString() {\rStringBuilder sb = new StringBuilder();\rfor (TDItem item : tdItems) {\rsb.append(item.fieldType).append(\u0026#34;(\u0026#34;).append(item.fieldName).append(\u0026#34;)\u0026#34;);\r}\rreturn sb.toString();\r}\rTuple.java Tuple.java 类用于保存某一行的所有值，设置 Field[] 数组来保存具体的值。\n// 每个 Tuple 都包含一个 TupleDesc 引用\rprivate TupleDesc td;\r// 用于保存一行的所有值\rprivate final Field[] fields;\r// 表示 Tuple 在磁盘中的位置，会发生改变\rprivate RecordId rid;\rprivate static final long serialVersionUID = 1L;\rpublic Tuple(TupleDesc td) {\rthis.td = td;\rthis.fields = new Field[td.numFields()];\r}\r数据库通过以下两个方法修改和获取某一行第 i 个字段的值。\npublic void setField(int i, Field f) {\rif (i \u0026lt; 0 || i \u0026gt;= td.numFields()) {\rthrow new IllegalArgumentException(\u0026#34;Index(\u0026#34; + i + \u0026#34;) out of bound.\u0026#34;);\r}\rfields[i] = f;\r}\rpublic Field getField(int i) {\rif (i \u0026lt; 0 || i \u0026gt;= td.numFields()) {\rthrow new IllegalArgumentException(\u0026#34;Index(\u0026#34; + i + \u0026#34;) out of bound.\u0026#34;);\r}\rreturn fields[i];\r}\rtoString(), fields() 方法如下：\npublic String toString() {\rStringBuilder sb = new StringBuilder();\rfor (Field field : fields) {\rsb.append(field).append(\u0026#39;\\t\u0026#39;);\r}\r// remove last \\t\r sb.setLength(sb.length() - 1);\rreturn sb.toString();\r}\rpublic Iterator\u0026lt;Field\u0026gt; fields() {\rreturn Arrays.stream(fields).iterator();\r}\rExercise 2 Exercise 2 需要我们完成以下文件的代码：\n src/java/simpledb/common/Catalog.java  Catalog 用于存储数据库的源信息（meta-data），如：数据库中的所有表信息、索引和模式等。 可以通过 Database.getCatalog() 获取到全局的单例 Catalog 实例。\nCatalog.java 通过新建一个静态内部类 Table 用于保存表信息，当前数据库中的所有表既可以通过 List\u0026lt;Table\u0026gt; 保存。\npublic static class Table {\rDbFile file;\rString name;\rString pkeyField;\rpublic Table(DbFile file, String name, String pkeyField) {\rthis.file = file;\rthis.name = name;\rthis.pkeyField = pkeyField;\r}\r}\rCatalog.java 构造器如下，仅需要初始化用于保存表的 List 即可。\npublic Catalog() {\rtables = new ArrayList\u0026lt;\u0026gt;();\r}\r当添加新的表时，表名或者 id 可能重复，我们需要用新的表替换掉旧的表。\npublic void addTable(DbFile file, String name, String pkeyField) {\rtables.removeIf(e -\u0026gt; e.name.equals(name) || e.file.getId() == file.getId());\rtables.add(new Table(file, name, pkeyField));\r}\r其他功能实现比较简单，仅需遍历查找到具体的值即可，可以通过 Map 缓存表名或 id 加快查找的速度。\npublic int getTableId(String name) throws NoSuchElementException {\rfor (Table table : tables) {\rif (table.name.equals(name)) {\rreturn table.file.getId();\r}\r}\rthrow new NoSuchElementException(\u0026#34;Name(\u0026#34; + name + \u0026#34;) is not exist.\u0026#34;);\r}\rpublic TupleDesc getTupleDesc(int tableid) throws NoSuchElementException {\rreturn getDatabaseFile(tableid).getTupleDesc();\r}\rpublic DbFile getDatabaseFile(int tableid) throws NoSuchElementException {\rfor (Table table : tables) {\rif (table.file.getId() == tableid) {\rreturn table.file;\r}\r}\rthrow new NoSuchElementException(\u0026#34;tableid(\u0026#34; + tableid + \u0026#34;) is not exist.\u0026#34;);\r}\rpublic String getPrimaryKey(int tableid) {\rfor (Table table : tables) {\rif (table.file.getId() == tableid) {\rreturn table.pkeyField;\r}\r}\rthrow new NoSuchElementException(\u0026#34;tableid(\u0026#34; + tableid + \u0026#34;) is not exist.\u0026#34;);\r}\rpublic Iterator\u0026lt;Integer\u0026gt; tableIdIterator() {\rreturn tables.stream().map(e -\u0026gt; e.file.getId()).iterator();\r}\rpublic String getTableName(int id) {\rfor (Table table : tables) {\rif (table.file.getId() == id) {\rreturn table.name;\r}\r}\rthrow new NoSuchElementException(\u0026#34;id(\u0026#34; + id + \u0026#34;) is not exist.\u0026#34;);\r}\rpublic void clear() {\rtables.clear();\r}\rExercise 3 Exercise 3 需要我们完成以下文件的代码：\n src/java/simpledb/storage/BufferPool.java  BufferPool 是对数据库中 Page 的缓存，数据库对文件中 Page 的所有读、写操作都会经过 BufferPool 获取 Page。\nLRU 的具体实现可以参考： LRU 缓存\npackage simpledb.storage;\rimport java.util.HashMap;\rpublic class LRUCache\u0026lt;K, V\u0026gt; {\rclass Node {\rK key;\rV val;\rNode prev, next;\rpublic Node() {\r}\rpublic Node(K key, V val) {\rthis.key = key;\rthis.val = val;\r}\r}\rprivate final Node head, tail;\rprivate final HashMap\u0026lt;K, Node\u0026gt; cache;\rprivate final int maxSize;\rpublic LRUCache(int maxSize) {\rthis.maxSize = maxSize;\rthis.cache = new HashMap\u0026lt;\u0026gt;(maxSize);\rhead = new Node();\rtail = new Node();\rhead.next = tail;\rtail.prev = head;\r}\rprivate void remove(Node node) {\rnode.prev.next = node.next;\rnode.next.prev = node.prev;\r}\rprivate Node removeTail() {\rNode node = tail.prev;\rif (node != head)\rremove(node);\rreturn node;\r}\rprivate void insertToHead(Node node) {\rhead.next.prev = node;\rnode.next = head.next;\rnode.prev = head;\rhead.next = node;\r}\rprivate void moveToHead(Node node) {\rremove(node);\rinsertToHead(node);\r}\rpublic V get(K k) {\rNode node = cache.get(k);\rif (node == null) return null;\rmoveToHead(node);\rreturn node.val;\r}\rpublic void put(K k, V v) {\rNode node = cache.get(k);\rif (node != null) {\rnode.val = v;\rmoveToHead(node);\r} else {\rif (cache.size() == maxSize) {\rNode removedNode = removeTail();\rcache.remove(removedNode.key);\r}\rNode newNode = new Node(k, v);\rcache.put(k, newNode);\rinsertToHead(newNode);\r}\r}\r}\rBufferPool.java 类的构造器如下：\nprivate final int numPages;\rprivate final LRUCache\u0026lt;PageId, Page\u0026gt; cache;\rpublic BufferPool(int numPages) {\rthis.numPages = numPages;\rcache = new LRUCache\u0026lt;\u0026gt;(numPages);\r}\rExercise 3 仅需要我们初步实现 getPage 方法，简单实现如下：\npublic Page getPage(TransactionId tid, PageId pid, Permissions perm)\rthrows TransactionAbortedException, DbException {\rPage page = cache.get(pid);\rif (page == null) {\rpage = Database.getCatalog().\rgetDatabaseFile(pid.getTableId()).readPage(pid);\rcache.put(pid, page);\r}\rreturn page;\r}\rExercise 4 Exercise 4 需要我们完成以下文件的代码：\n src/java/simpledb/storage/HeapPageId.java src/java/simpledb/storage/RecordId.java src/java/simpledb/storage/HeapPage.java  HeapPageId.java HeapPageId.java 用于唯一标识一个 Page， 通过所在表的 id（tableId）和 Page Number（pgNo）即可唯一确定一个 Page 文件。\nRecordId.java RecordId.java 用于唯一标识一个 Tuple， 通过所在 Page 的 id（pid）和 Tuple Number（tupleno）即可唯一确定一个 Tuple 。\nHeapPage.java HeapPage.java 用于具体存储 Tuple 到文件中， HeapPage 文件根据 Tuple 大小被划分为多个 slot，一个 slot 可以存储一个 Tuple 。 我们需要使用位图记录哪些 slot 是正在使用或未使用。原代码中已经提供 byte[] header 来供我们实现位图功能。\n计算一个 Page 可以存放多少个 Tuple，计算公式在构造器的注释中给出。\nprivate int getNumTuples() {\rreturn (int) Math.floor((BufferPool.getPageSize() * 8) / (td.getSize() * 8 + 1));\r}\r计算需要多大长度的 byte 数组用于保存位图。\nprivate int getHeaderSize() {\rreturn (int) Math.ceil(getNumTuples() / 8);\r}\r计算该 Page 有多少个空的 slot，只需遍历所有的 slot，查看是否正在使用。\n优化：可以额外使用一个变量记录已经使用的 slot 数量，则 未使用的 slot 数量 = slot 总数 - 正在使用的 slot 数量\npublic int getNumEmptySlots() {\r// 不可以直接遍历 header，因为 numSlots \u0026lt;= header.length * 8\r // 可能会遍历到永远不会用到的位置\r int cnt = 0;\rfor (int i = 0; i \u0026lt; numSlots; i++) {\rif (!isSlotUsed(i)) {\rcnt++;\r}\r}\rreturn cnt;\r}\r通过位图计算某个 slot 是否正在被使用中。\npublic boolean isSlotUsed(int i) {\r// i / 8 确定位于 header 的索引位置 n\r // i % 8 确定位于 header[n] 的第几个二进制位\r return ((header[i / 8] \u0026gt;\u0026gt; (i % 8)) \u0026amp; 1) == 1;\r}\r通过迭代器迭代当前 Page 中的 Tuple，此处需要去除未使用的 slot。\npublic Iterator\u0026lt;Tuple\u0026gt; iterator() {\rreturn new Iterator\u0026lt;\u0026gt;() {\rprivate int idx = 0, cnt = 0;\r// 已经使用的 slot 数量\r private final int usedSlotNum = getNumTuples() - getNumEmptySlots();\r@Override\rpublic boolean hasNext() {\rreturn cnt \u0026lt; usedSlotNum;\r}\r@Override\rpublic Tuple next() {\rwhile (!isSlotUsed(idx)) {\ridx++;\r}\rcnt++;\rreturn tuples[idx++];\r}\r};\r}\r"},{"id":2,"href":"/docs/data-structure/log-structured-merge-tree/","title":"LSM Tree","section":"Data structure","content":"LSM Tree "},{"id":3,"href":"/docs/data-structure/skip-list/","title":"Skip List","section":"Data structure","content":"SkipList "},{"id":4,"href":"/docs/data-structure/sorted-string-table/","title":"SSTable","section":"Data structure","content":"SSTable "},{"id":5,"href":"/docs/distributed-system/basic-theory-of-distributed-system/","title":"分布式系统基本理论","section":"Distributed System","content":"分布式系统基本理论 拜占庭将军问题 拜占庭将军问题（Byzantine Generals Problem）是 Leslie Lamport 在论文 The Byzantine Generals Problem 中提出，是对分布式系统中面临问题的抽象描述。  CAP CAP 定理  BASE ACID 一致性 "},{"id":6,"href":"/docs/distributed-system/consensus-algorithm/","title":"分布式共识算法","section":"Distributed System","content":"分布式一致性算法 Raft 算法是 Stanford University 的 Diego Ongaro 的博士论文，是分布式一致性算法的一种，相比于 Paxos 算法更易于理解，使用该算法的项目有：TiKV, etcd, CockroachDB 等\n官方地址：https://raft.github.io/\n 时间 (Terms) 分布式系统中节点的时间是不可靠的，如不采取特殊硬件，节点与节点之间时间是存在一定的误差。如果采用时间作为判断操作的先后顺序，即使是很细微的误差仍然会导致误判。因此 Raft 把时间划分为不同的 terms（任期），term 类似于逻辑时钟，可以用于判断事件发生的先后顺序。\n如果当前节点接收到较大 term 节点的请求，则说明当前节点已经落后于请求的节点，需要转为 Follower 状态，并把当前 term 更新为较大的 term。\n 角色 (states) Raft 中的节点始终处于 Follower | Candidate | Leader 三种状态之一，不同状态之间根据不同的触发条件进行相互转换。\n  跟随者 (Follower) ：当节点启动后，此时节点为 Follower 状态，在一定时间内（300~500ms）如果没有收到来自 Leader 的心跳包，此时称为选举超时（election timeout），当前节点则会转为 Candidate 状态 候选者 (Candidate) ：当转为 Candidate 状态后，Candidate 节点会先投自己，然后向集群中的其它节点（不包含自己）发送投票请求，请求获取投票。如果集群中超过一半的节点同意该投票请求，该 Candidate 节点就会转为Leader 状态 领导者 (Leader) ：当节点转为 Leader 状态后，会定时给集群中的所有节点发送心跳包，维护其 Leader 状态。Leader 节点会处理来自 clients 的所有请求，当集群中处于其它状态的节点接收到来自 clients 的请求后，会转发给 Leader 进行处理  保证一致性 Raft 把保证一致性问题分为三个相对独立的子问题：\n 选举 (Leader Election) ：当集群中的 Leader 宕机后，保证选举出一个新的 Leader 日志复制 (Log replication) ：当 Leader 接收到 clients 的日志请求后，需保证复制到集群中的所有节点 安全性 (Safety) ：需要采用一些额外的规则来保证运行正确  全局状态   一些需要保存的重要状态，分为持久化保存，非持久化保存和仅 Leader 节点非持久化保存\n 持久化保存  currentTerm : 当前节点的 term，初始化为 0 ，每开启一轮新的选举 currentTerm++ voteFor : 当前 term 已投票的节点的 ID。当为 None 时说明当前 term 无投票，可以对验证过的 Candidate 节点进行投票 log[] : 用于当前节点保存 Log Entry，索引下标从 1 开始  非持久化保存 当一条日志被提交（commit）后，意味着该条日志已经复制到集群中的大部分节点中，此时就可以把应用（apply）到状态机中，永远满足：lastApplied \u0026lt;= commitIndex。\n// apply 的流程\rfor (int i = lastApplied; i \u0026lt;= commitIndex; i++) {\rapply(log[i]); // apply to state machine\r lastApplied++;\r}\r commitIndex : 已经提交的 Log Entry 中最大的 Index lastApplied : 已经 apply 到状态机中的 Log Entry 中的最大 Index  仅 Leader 节点 利用数组保存集群节点的状态，len(nextIndex[]) = len(matchIndex[]) = len(集群节点)，下标保存就是对应节点信息，nextIndex[0] 和 matchIndex[0] 表示集群中的第 0 个节点状态，nextIndex[1] 和 matchIndex[1] 表示集群中的第 1 个节点，以此类推。\n如果 Leader 节点通过 AppendEntries RPC 复制 Log Entry 到 Follower 节点成功后，nextIndex[ID] += len(entries); matchIndex[ID] += len(entries);\n当复制完成后，可以对 matchIndex[] 进行排序，中位数就是已经复制到大多数节点的 Log Entry 的 index，即可以用于更新 commitIndex。\n当 matchIndex = {1, 5, 5, 7, 9};\r中位数为 5，集群中 matchIndex[i] \u0026lt;= 5 的节点个数为 3 个\rlen(matchIndex)/2 \u0026lt; 3，即集群中的大多数节点的 matchIndex 都大于等于 5\r每次选举成功后，Leader 节点需要重新初始化下边的状态\n  nextIndex[] : 下次给对应 server 发送日志中的第一个 Log Entry 的 index，初始为 Leader 节点最后一个 Log Entry 的 index + 1。当发送的日志与 Follower 节点的日志冲突时，则会回退 nextIndex[id]--\n  matchIndex[] : 对应的 server 已经复制完成的 Log Entry 的 index，初始为 0\n  选举 当节点启动后，节点为 Follower 状态，如果在一定时间内（300~500ms），没有接收到集群中 Leader 发送的有效的心跳包，此时称为 election timeout。\n当节点选举超时后，则会转为 Candidate 状态。首先会先投自己一票，然后发起选举请求，并发的向集群中的其它节点发起 RequestVote RPC 请求，请求获取集群中其它节点的投票，如果 获取到的投票数 \u0026gt; len(集群节点) / 2 则代表集群一半以上的节点同意了该投票请求，该节点即可变为集群中的 Leader，处理来自 clients 的所有请求。\n选举超时说明集群中无 term 大于当前节点并处于 Leader 状态的节点，但集群中可能存在 term 小于当前节点，但处于 Leader 状态的节点。当节点收到 term 较大节点发送的 RPC 请求后，则说明该节点已经滞后于较大 term 的节点，此时较小 term 的节点会转为 Follower 状态并更新当前 term 为较大节点的 term。\nRequestVote RPC 请求   请求投票 RPC 请求：该请求会用于 Candidate 节点获取 Follower 节点的投票\n RequestVote Arguments lastLogIndex 和 lastLogTerm 用于保证当选 Leader 的节点包含集群中已被提交的所有 Log Entry。\n term : Candidate 节点的 term，用于后续投票者判断 Candidate 节点是否滞后。  Candidate's term \u0026gt;= currentTerm : 当前节点在该 term 任期如果没有投过其它节点，把 voteFor 设为 Candidate 节点的 ID，代表当前轮已经投过了，在该 term 任期中不会再投其它节点 Candidate's term \u0026lt; currentTerm : Candidate 节点滞后与当前节点，拒绝其投票请求   candidateId : Candidate 节点的 ID 编号，用于投票者设置该 term 任期内投票的节点，即设置 voteFor = candidateID lastLogIndex : 当前 Candidate 节点最后一条 Log Entry 的 index lastLogTerm : 当前 Candidate 节点最后一条 Log Entry 的 term  RequestVote Response  term : 当前 Follower 节点的 term，用于 Candidate 节点判断自己是否滞后与该 Follower 节点。如果 Follower's term \u0026gt; currentTerm，则该 Candidate 节点转为 Follower 状态 voteGranted : Follower 节点同意该 Candidate 节点的投票请求  日志复制   日志状态机 (State Machine) : 采用多个节点保存同一份 Log Entry，即使一个节点宕机，其它节点仍然可以提供服务\n 当接收到 clients 的请求后，整个流程如下：\n 当 Leader 节点接收到来自 clients 的需要 apply 到状态机中 Log Entry 请求后，则把 Log Entry 添加到自身的 Log 中，随后通过 AppendEntries RPC 并发的向集群中的其他节点发送请求 当 Follower 节点添加 Log Entry 到自身的 Log 中后，会返回 AppendEntries Response 响应，Leader 节点通过 success 是否为真来判断该节点是否成功保存到该 Follower 节点中 如果一半以上的节点保存该 Log Entry 到自身 Log 中，Leader 节点就会更新本身的 committedIndex 为该 Log Entry 的 Index，下一次发送 AppendEntry RPC 请求时，Follower 节点会根据 leaderCommit 来提交该 Log Entry 和之前未提交的 Log Entry，随后 apply 到状态机中，并返回执行结果给 clients 如果某个 Follower 节点宕机了，或者由于网络丢包导致 RPC 请求没有送到节点中，则 Leader 会一直重试发送该请求  Raft 保证一旦一条 Log Entry 被 committed 后，该条 Log Entry 会被永久存储。即使节点宕机恢复后，恢复后该条日志仍然存在。而来自 clients 请求中的 Log Entry 不需要立即持久化存储，因为 clients 的每条请求会设置一定的超时时间，如果节点宕机导致该 Log Entry 丢失，该条请求就会超时，clients 节点只需重新发送该请求即可。\nRaft 使用 AppendEntries RPC 请求作为日志复制的载体，只有 Leader 节点才会发送 AppendEntries RPC 请求。通常设置 30ms 发送一次 AppendEntries RPC 请求。如发送频率过高，则会导致发送 RPC 请求消耗过高；如发送频率过低，会导致节点之间信息同步过慢。\n根据 entries[] 是否为空，分为两种用途的 RPC 请求：\n 当 entries[] 为空时：该 RPC 请求作为 Leader 发送的 heartbeat，维护其 Leader 状态 当 entries[] 不为空时：该请求会携带 Log Entry，用于 Follower 节点保存 Log 到状态机中。在两次 RPC 请求过程中可能会有多条 Log 请求，因此可以放到一次 RPC 请求中发送。携带 Log 的 RPC 请求也可以作为 heartbeat 使用  AppendEntries RPC 请求   日志添加 RPC 请求：用于 Leader 节点发送 heartbeat 或日志复制请求\n AppendEntries Request prevLogIndex 和 prevLogTerm 是 Follower 节点用来检查自身 Log Entry 是否和 Leader 节点的 Log Entry 一致。如果当前 Follower 节点保存的最后一条 Log Entry 的 index 和 term 与 prevLogIndex 和 prevLogTerm 一致，则说明没有冲突，直接把新的 Log Entry 添加到 log[] 尾部即可。如果冲突，则直接拒绝该条 RPC 请求，设置 sucess 为 false。随后 Leader 节点会进行回退，把 nextIndex[ID]--。下次就会发送前一条 Log Entry，直到 Leader 节点和 Follower 节点 Log Entry 不冲突为止。\n如果 Follower 节点保存的有 index 为 prevLogIndex 的 Log Entry，并且保存有大于 index 的节点，则强制删除 index 大于 prevLogIndex 后的所有 Log Entry。\n是本次 RPC 请求中的的 entries[0] 位置的 Log Entry 的前一个位于 log[] 中的 LogEntry 的 index 和 term。\n term : 当前节点的 term，用于 Follower 节点判断是否是过期的 Leader 节点。  Leader's term \u0026gt;= currentTerm : 当前节点在该 term 任期如果没有投过其它节点，把 voteFor 设为 Candidate 节点的 ID，代表当前轮已经投过了，在该 term 任期中不会再投其它节点 Leader's term \u0026lt; currentTerm : Candidate 节点滞后与当前节点，拒绝其投票请求   leaderId : Candidate 节点可以保存 leaderId，当 clients 发送请求给 Follower 节点后，Follower 节点可以通过把 clients 发到为 leaderId 的节点 prevLogIndex : prevLogIndex = nextIndex[ID] - 1 prevLogTerm : prevLogTerm = log[prevLogIndex].term entries[] : entries = log[nextIndex[ID]:len(log)-1]，用于保存此次需要复制到 Follower 节点的 Log Entry，如果 len(entries) == 0 ，则用于 heartbeat leaderCommit : Leader 节点已提交 Log Entry 的最后一条的 Index。Follower 节点根据此索引来确定已经被提交的 Log Entry，进行提交  AppendEntries Response  term : Follower 节点当前的 term success : 当前 Follower 节点与 Leader 节点保存的 Log Entry 是否冲突  "},{"id":7,"href":"/docs/distributed-system/distributed-transaction/","title":"分布式事务处理","section":"Distributed System","content":"分布式事务处理 "},{"id":8,"href":"/docs/database-system/leveldb/","title":"LevelDB","section":"Database System","content":"LevelDB "}]