[{"id":0,"href":"/docs/data-structure/avl-tree/","title":"AVL Tree","section":"Data structure","content":" AVL Tree # "},{"id":1,"href":"/docs/lab-report/MIT-6.830/lab1/","title":"Lab 1","section":"MIT 6.830","content":" Lab 1 # Exercise 1 # Exercise 1 需要我们完成以下文件的代码：\nsrc/java/simpledb/storage/TupleDesc.java src/java/simpledb/storage/Tuple.java User 表如下所示：\nid(INT) name(STRING) age(INT)\r1 \u0026#34;张三\u0026#34; 12\r2 \u0026#34;李四\u0026#34; 22\r3 \u0026#34;王二\u0026#34; 54 Tuple.java 表示表中的某一行数据，如：User(1, \u0026ldquo;张三\u0026rdquo;, 12), User(2, \u0026ldquo;李四\u0026rdquo;, 22)\nTupleDesc.java 表示表中字段的类型和名称，如：User{id(INT), name(STRING), age(INT)}\nTupleDesc.java # TupleDesc.java 中的静态内部类 TDItem 用于表示某字段的类型（Type fieldType）和名称（String fieldName）。\npublic static class TDItem implements Serializable { private static final long serialVersionUID = 1L; /** * The type of the field */ public final Type fieldType; /** * The name of the field */ public final String fieldName; public TDItem(Type t, String n) { this.fieldName = n; this.fieldType = t; } public String toString() { return fieldName + \u0026#34;(\u0026#34; + fieldType + \u0026#34;)\u0026#34;; } } 一个表可能有多个字段，我们可以采用 TDItem[] 直接表示表中所有字段的类型和名称。\nTupleDesc 一共提供了两个构造函数：\n指定字段类型和名称：TupleDesc(Type[] typeAr, String[] fieldAr) 仅指定字段类型，设为匿名名称：TupleDesc(Type[] typeAr) 具体构造函数的实现如下：\n// 匿名字段名称 public static final String UNNAMED = \u0026#34;UNNAMED_FIELD_NAME\u0026#34;; // 提供类型和名称 public TupleDesc(Type[] typeAr, String[] fieldAr) { // 一共有 n 列 int n = typeAr.length; tdItems = new TDItem[n]; for (int i = 0; i \u0026lt; n; i++) { // 字段名可能为空，设为匿名 String fieldName = fieldAr == null ? UNNAMED : fieldAr[i]; tdItems[i] = new TDItem(typeAr[i], fieldName); } } // 仅提供类型，名称设为匿名 public TupleDesc(Type[] typeAr) { this(typeAr, null); } 可以直接根据 TDItem[] 数组的长度直接获取字段长度。\npublic int numFields() { return tdItems.length; } 获取第 i 个字段的类型/名称，如果不存在直接抛出 NoSuchElementException 异常。\npublic String getFieldName(int i) throws NoSuchElementException { if (i \u0026lt; 0 || i \u0026gt;= tdItems.length) { throw new NoSuchElementException(\u0026#34;Index(\u0026#34; + i + \u0026#34;) out of bound.\u0026#34;); } return tdItems[i].fieldName; } public Type getFieldType(int i) throws NoSuchElementException { if (i \u0026lt; 0 || i \u0026gt;= tdItems.length) { throw new NoSuchElementException(\u0026#34;Index(\u0026#34; + i + \u0026#34;) out of bound.\u0026#34;); } return tdItems[i].fieldType; } 通过名称获取字段的索引位置，直接遍历一遍找到字段名相同的即可。\npublic int fieldNameToIndex(String name) throws NoSuchElementException { int n = tdItems.length; for (int i = 0; i \u0026lt; n; i++) { String fieldName = tdItems[i].fieldName; if (fieldName.equals(name)) { return i; } } throw new NoSuchElementException(\u0026#34;FieldName(\u0026#34; + name + \u0026#34;) is not exist.\u0026#34;); } 获取字段类型的大小，直接遍历累加所有字段类型大小。\npublic int getSize() { int size = 0; for (TDItem item : tdItems) { // 累加每列类型的大小 size += item.fieldType.getLen(); } return size; } 合并两个 TupleDesc 为一个 TupleDesc。\npublic static TupleDesc merge(TupleDesc td1, TupleDesc td2) { int n1 = td1.numFields(), n2 = td2.numFields(), n = n1 + n2; Type[] typeAr = new Type[n]; String[] fieldAr = new String[n]; int idx = 0; for (int i = 0; i \u0026lt; n1; i++) { typeAr[idx] = td1.getFieldType(i); fieldAr[idx] = td1.getFieldName(i); idx++; } for (int i = 0; i \u0026lt; n2; i++) { typeAr[idx] = td2.getFieldType(i); fieldAr[idx] = td2.getFieldName(i); idx++; } return new TupleDesc(typeAr, fieldAr); } equals(), hashCode(), toString() 方法如下：\npublic boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; TupleDesc tupleDesc = (TupleDesc) o; return Arrays.equals(tdItems, tupleDesc.tdItems); } public int hashCode() { return Arrays.hashCode(tdItems); } public String toString() { StringBuilder sb = new StringBuilder(); for (TDItem item : tdItems) { sb.append(item.fieldType).append(\u0026#34;(\u0026#34;).append(item.fieldName).append(\u0026#34;)\u0026#34;); } return sb.toString(); } Tuple.java # Tuple.java 类用于保存某一行的所有值，设置 Field[] 数组来保存具体的值。\n// 每个 Tuple 都包含一个 TupleDesc 引用 private TupleDesc td; // 用于保存一行的所有值 private final Field[] fields; // 表示 Tuple 在磁盘中的位置，会发生改变 private RecordId rid; private static final long serialVersionUID = 1L; public Tuple(TupleDesc td) { this.td = td; this.fields = new Field[td.numFields()]; } 数据库通过以下两个方法修改和获取某一行第 i 个字段的值。\npublic void setField(int i, Field f) { if (i \u0026lt; 0 || i \u0026gt;= td.numFields()) { throw new IllegalArgumentException(\u0026#34;Index(\u0026#34; + i + \u0026#34;) out of bound.\u0026#34;); } fields[i] = f; } public Field getField(int i) { if (i \u0026lt; 0 || i \u0026gt;= td.numFields()) { throw new IllegalArgumentException(\u0026#34;Index(\u0026#34; + i + \u0026#34;) out of bound.\u0026#34;); } return fields[i]; } toString(), fields() 方法如下：\npublic String toString() { StringBuilder sb = new StringBuilder(); for (Field field : fields) { sb.append(field).append(\u0026#39;\\t\u0026#39;); } // remove last \\t sb.setLength(sb.length() - 1); return sb.toString(); } public Iterator\u0026lt;Field\u0026gt; fields() { return Arrays.stream(fields).iterator(); } Exercise 2 # Exercise 2 需要我们完成以下文件的代码：\nsrc/java/simpledb/common/Catalog.java Catalog 用于存储数据库的源信息（meta-data），如：数据库中的所有表信息、索引和模式等。 可以通过 Database.getCatalog() 获取到全局的单例 Catalog 实例。\nCatalog.java # 通过新建一个静态内部类 Table 用于保存表信息，当前数据库中的所有表既可以通过 List\u0026lt;Table\u0026gt; 保存。\npublic static class Table { DbFile file; String name; String pkeyField; public Table(DbFile file, String name, String pkeyField) { this.file = file; this.name = name; this.pkeyField = pkeyField; } } Catalog.java 构造器如下，仅需要初始化用于保存表的 List 即可。\npublic Catalog() { tables = new ArrayList\u0026lt;\u0026gt;(); } 当添加新的表时，表名或者 id 可能重复，我们需要用新的表替换掉旧的表。\npublic void addTable(DbFile file, String name, String pkeyField) { tables.removeIf(e -\u0026gt; e.name.equals(name) || e.file.getId() == file.getId()); tables.add(new Table(file, name, pkeyField)); } 其他功能实现比较简单，仅需遍历查找到具体的值即可，可以通过 Map 缓存表名或 id 加快查找的速度。\npublic int getTableId(String name) throws NoSuchElementException { for (Table table : tables) { if (table.name.equals(name)) { return table.file.getId(); } } throw new NoSuchElementException(\u0026#34;Name(\u0026#34; + name + \u0026#34;) is not exist.\u0026#34;); } public TupleDesc getTupleDesc(int tableid) throws NoSuchElementException { return getDatabaseFile(tableid).getTupleDesc(); } public DbFile getDatabaseFile(int tableid) throws NoSuchElementException { for (Table table : tables) { if (table.file.getId() == tableid) { return table.file; } } throw new NoSuchElementException(\u0026#34;tableid(\u0026#34; + tableid + \u0026#34;) is not exist.\u0026#34;); } public String getPrimaryKey(int tableid) { for (Table table : tables) { if (table.file.getId() == tableid) { return table.pkeyField; } } throw new NoSuchElementException(\u0026#34;tableid(\u0026#34; + tableid + \u0026#34;) is not exist.\u0026#34;); } public Iterator\u0026lt;Integer\u0026gt; tableIdIterator() { return tables.stream().map(e -\u0026gt; e.file.getId()).iterator(); } public String getTableName(int id) { for (Table table : tables) { if (table.file.getId() == id) { return table.name; } } throw new NoSuchElementException(\u0026#34;id(\u0026#34; + id + \u0026#34;) is not exist.\u0026#34;); } public void clear() { tables.clear(); } Exercise 3 # Exercise 3 需要我们完成以下文件的代码：\nsrc/java/simpledb/storage/BufferPool.java BufferPool 是对数据库中 Page 的缓存，数据库对文件中 Page 的所有读、写操作都会经过 BufferPool 获取 Page。\nLRU 的具体实现可以参考： LRU 缓存\npackage simpledb.storage; import java.util.HashMap; public class LRUCache\u0026lt;K, V\u0026gt; { class Node { K key; V val; Node prev, next; public Node() { } public Node(K key, V val) { this.key = key; this.val = val; } } private final Node head, tail; private final HashMap\u0026lt;K, Node\u0026gt; cache; private final int maxSize; public LRUCache(int maxSize) { this.maxSize = maxSize; this.cache = new HashMap\u0026lt;\u0026gt;(maxSize); head = new Node(); tail = new Node(); head.next = tail; tail.prev = head; } private void remove(Node node) { node.prev.next = node.next; node.next.prev = node.prev; } private Node removeTail() { Node node = tail.prev; if (node != head) remove(node); return node; } private void insertToHead(Node node) { head.next.prev = node; node.next = head.next; node.prev = head; head.next = node; } private void moveToHead(Node node) { remove(node); insertToHead(node); } public V get(K k) { Node node = cache.get(k); if (node == null) return null; moveToHead(node); return node.val; } public void put(K k, V v) { Node node = cache.get(k); if (node != null) { node.val = v; moveToHead(node); } else { if (cache.size() == maxSize) { Node removedNode = removeTail(); cache.remove(removedNode.key); } Node newNode = new Node(k, v); cache.put(k, newNode); insertToHead(newNode); } } } BufferPool.java 类的构造器如下：\nprivate final int numPages; private final LRUCache\u0026lt;PageId, Page\u0026gt; cache; public BufferPool(int numPages) { this.numPages = numPages; cache = new LRUCache\u0026lt;\u0026gt;(numPages); } Exercise 3 仅需要我们初步实现 getPage 方法，简单实现如下：\npublic Page getPage(TransactionId tid, PageId pid, Permissions perm) throws TransactionAbortedException, DbException { Page page = cache.get(pid); if (page == null) { page = Database.getCatalog(). getDatabaseFile(pid.getTableId()).readPage(pid); cache.put(pid, page); } return page; } Exercise 4 # Exercise 4 需要我们完成以下文件的代码：\nsrc/java/simpledb/storage/HeapPageId.java src/java/simpledb/storage/RecordId.java src/java/simpledb/storage/HeapPage.java HeapPageId.java # HeapPageId.java 用于唯一标识一个 Page， 通过所在表的 id（tableId）和 Page Number（pgNo）即可唯一确定一个 Page 文件。\nRecordId.java # RecordId.java 用于唯一标识一个 Tuple， 通过所在 Page 的 id（pid）和 Tuple Number（tupleno）即可唯一确定一个 Tuple 。\nHeapPage.java # HeapPage.java 用于具体存储 Tuple 到文件中， HeapPage 文件根据 Tuple 大小被划分为多个 slot，一个 slot 可以存储一个 Tuple 。 我们需要使用位图记录哪些 slot 是正在使用或未使用。原代码中已经提供 byte[] header 来供我们实现位图功能。\n计算一个 Page 可以存放多少个 Tuple，计算公式在构造器的注释中给出。\nprivate int getNumTuples() { return (int) Math.floor((BufferPool.getPageSize() * 8) / (td.getSize() * 8 + 1)); } 计算需要多大长度的 byte 数组用于保存位图。\nprivate int getHeaderSize() { return (int) Math.ceil(getNumTuples() / 8); } 计算该 Page 有多少个空的 slot，只需遍历所有的 slot，查看是否正在使用。\n优化：可以额外使用一个变量记录已经使用的 slot 数量，则 未使用的 slot 数量 = slot 总数 - 正在使用的 slot 数量\npublic int getNumEmptySlots() { // 不可以直接遍历 header，因为 numSlots \u0026lt;= header.length * 8 // 可能会遍历到永远不会用到的位置 int cnt = 0; for (int i = 0; i \u0026lt; numSlots; i++) { if (!isSlotUsed(i)) { cnt++; } } return cnt; } 通过位图计算某个 slot 是否正在被使用中。\npublic boolean isSlotUsed(int i) { // i / 8 确定位于 header 的索引位置 n // i % 8 确定位于 header[n] 的第几个二进制位 return ((header[i / 8] \u0026gt;\u0026gt; (i % 8)) \u0026amp; 1) == 1; } 通过迭代器迭代当前 Page 中的 Tuple，此处需要去除未使用的 slot。\npublic Iterator\u0026lt;Tuple\u0026gt; iterator() { return new Iterator\u0026lt;\u0026gt;() { private int idx = 0, cnt = 0; // 已经使用的 slot 数量 private final int usedSlotNum = getNumTuples() - getNumEmptySlots(); @Override public boolean hasNext() { return cnt \u0026lt; usedSlotNum; } @Override public Tuple next() { while (!isSlotUsed(idx)) { idx++; } cnt++; return tuples[idx++]; } }; } "},{"id":2,"href":"/docs/data-structure/log-structured-merge-tree/","title":"LSM Tree","section":"Data structure","content":" LSM Tree # "},{"id":3,"href":"/docs/data-structure/skip-list/","title":"Skip List","section":"Data structure","content":" SkipList # "},{"id":4,"href":"/docs/data-structure/sorted-string-table/","title":"SSTable","section":"Data structure","content":" SSTable # "},{"id":5,"href":"/docs/distributed-system/basic-theory-of-distributed-system/","title":"分布式系统基本理论","section":"Distributed System","content":" 分布式系统基本理论 # 拜占庭将军问题 # 拜占庭将军问题（Byzantine Generals Problem）是 Leslie Lamport 在论文 The Byzantine Generals Problem 中提出，是对分布式系统中面临问题的抽象描述。 CAP # CAP 定理 BASE # ACID # 一致性 # "},{"id":6,"href":"/docs/distributed-system/consensus-algorithm/","title":"分布式共识算法","section":"Distributed System","content":" 分布式一致性算法 # Raft 算法是 Stanford University 的 Diego Ongaro 的博士论文，是分布式一致性算法的一种，相比于 Paxos 算法更易于理解，使用该算法的项目有：TiKV, etcd, CockroachDB 等\n官方地址：https://raft.github.io/\n时间 (Terms) # 分布式系统中节点的时间是不可靠的，如不采取特殊硬件，节点与节点之间时间是存在一定的误差。如果采用时间作为判断操作的先后顺序，即使是很细微的误差仍然会导致误判。因此 Raft 把时间划分为不同的 terms（任期），term 类似于逻辑时钟，可以用于判断事件发生的先后顺序。\n如果当前节点接收到较大 term 节点的请求，则说明当前节点已经落后于请求的节点，需要转为 Follower 状态，并把当前 term 更新为较大的 term。\n角色 (states) # Raft 中的节点始终处于 Follower | Candidate | Leader 三种状态之一，不同状态之间根据不同的触发条件进行相互转换。\n跟随者 (Follower) ：当节点启动后，此时节点为 Follower 状态，在一定时间内（300~500ms）如果没有收到来自 Leader 的心跳包，此时称为选举超时（election timeout），当前节点则会转为 Candidate 状态 候选者 (Candidate) ：当转为 Candidate 状态后，Candidate 节点会先投自己，然后向集群中的其它节点（不包含自己）发送投票请求，请求获取投票。如果集群中超过一半的节点同意该投票请求，该 Candidate 节点就会转为Leader 状态 领导者 (Leader) ：当节点转为 Leader 状态后，会定时给集群中的所有节点发送心跳包，维护其 Leader 状态。Leader 节点会处理来自 clients 的所有请求，当集群中处于其它状态的节点接收到来自 clients 的请求后，会转发给 Leader 进行处理 保证一致性 # Raft 把保证一致性问题分为三个相对独立的子问题：\n选举 (Leader Election) ：当集群中的 Leader 宕机后，保证选举出一个新的 Leader 日志复制 (Log replication) ：当 Leader 接收到 clients 的日志请求后，需保证复制到集群中的所有节点 安全性 (Safety) ：需要采用一些额外的规则来保证运行正确 全局状态 # 一些需要保存的重要状态，分为持久化保存，非持久化保存和仅 Leader 节点非持久化保存\n持久化保存 # currentTerm : 当前节点的 term，初始化为 0 ，每开启一轮新的选举 currentTerm++ voteFor : 当前 term 已投票的节点的 ID。当为 None 时说明当前 term 无投票，可以对验证过的 Candidate 节点进行投票 log[] : 用于当前节点保存 Log Entry，索引下标从 1 开始 非持久化保存 # 当一条日志被提交（commit）后，意味着该条日志已经复制到集群中的大部分节点中，此时就可以把应用（apply）到状态机中，永远满足：lastApplied \u0026lt;= commitIndex。\n// apply 的流程 for (int i = lastApplied; i \u0026lt;= commitIndex; i++) { apply(log[i]); // apply to state machine lastApplied++; } commitIndex : 已经提交的 Log Entry 中最大的 Index lastApplied : 已经 apply 到状态机中的 Log Entry 中的最大 Index 仅 Leader 节点 # 利用数组保存集群节点的状态，len(nextIndex[]) = len(matchIndex[]) = len(集群节点)，下标保存就是对应节点信息，nextIndex[0] 和 matchIndex[0] 表示集群中的第 0 个节点状态，nextIndex[1] 和 matchIndex[1] 表示集群中的第 1 个节点，以此类推。\n如果 Leader 节点通过 AppendEntries RPC 复制 Log Entry 到 Follower 节点成功后，nextIndex[ID] += len(entries); matchIndex[ID] += len(entries);\n当复制完成后，可以对 matchIndex[] 进行排序，中位数就是已经复制到大多数节点的 Log Entry 的 index，即可以用于更新 commitIndex。\n当 matchIndex = {1, 5, 5, 7, 9};\r中位数为 5，集群中 matchIndex[i] \u0026lt;= 5 的节点个数为 3 个\rlen(matchIndex)/2 \u0026lt; 3，即集群中的大多数节点的 matchIndex 都大于等于 5 每次选举成功后，Leader 节点需要重新初始化下边的状态\nnextIndex[] : 下次给对应 server 发送日志中的第一个 Log Entry 的 index，初始为 Leader 节点最后一个 Log Entry 的 index + 1。当发送的日志与 Follower 节点的日志冲突时，则会回退 nextIndex[id]--\nmatchIndex[] : 对应的 server 已经复制完成的 Log Entry 的 index，初始为 0\n选举 # 当节点启动后，节点为 Follower 状态，如果在一定时间内（300~500ms），没有接收到集群中 Leader 发送的有效的心跳包，此时称为 election timeout。\n当节点选举超时后，则会转为 Candidate 状态。首先会先投自己一票，然后发起选举请求，并发的向集群中的其它节点发起 RequestVote RPC 请求，请求获取集群中其它节点的投票，如果 获取到的投票数 \u0026gt; len(集群节点) / 2 则代表集群一半以上的节点同意了该投票请求，该节点即可变为集群中的 Leader，处理来自 clients 的所有请求。\n选举超时说明集群中无 term 大于当前节点并处于 Leader 状态的节点，但集群中可能存在 term 小于当前节点，但处于 Leader 状态的节点。当节点收到 term 较大节点发送的 RPC 请求后，则说明该节点已经滞后于较大 term 的节点，此时较小 term 的节点会转为 Follower 状态并更新当前 term 为较大节点的 term。\nRequestVote RPC 请求 # 请求投票 RPC 请求：该请求会用于 Candidate 节点获取 Follower 节点的投票\nRequestVote Arguments # lastLogIndex 和 lastLogTerm 用于保证当选 Leader 的节点包含集群中已被提交的所有 Log Entry。\nterm : Candidate 节点的 term，用于后续投票者判断 Candidate 节点是否滞后。 Candidate's term \u0026gt;= currentTerm : 当前节点在该 term 任期如果没有投过其它节点，把 voteFor 设为 Candidate 节点的 ID，代表当前轮已经投过了，在该 term 任期中不会再投其它节点 Candidate's term \u0026lt; currentTerm : Candidate 节点滞后与当前节点，拒绝其投票请求 candidateId : Candidate 节点的 ID 编号，用于投票者设置该 term 任期内投票的节点，即设置 voteFor = candidateID lastLogIndex : 当前 Candidate 节点最后一条 Log Entry 的 index lastLogTerm : 当前 Candidate 节点最后一条 Log Entry 的 term RequestVote Response # term : 当前 Follower 节点的 term，用于 Candidate 节点判断自己是否滞后与该 Follower 节点。如果 Follower's term \u0026gt; currentTerm，则该 Candidate 节点转为 Follower 状态 voteGranted : Follower 节点同意该 Candidate 节点的投票请求 日志复制 # 日志状态机 (State Machine) : 采用多个节点保存同一份 Log Entry，即使一个节点宕机，其它节点仍然可以提供服务\n当接收到 clients 的请求后，整个流程如下：\n当 Leader 节点接收到来自 clients 的需要 apply 到状态机中 Log Entry 请求后，则把 Log Entry 添加到自身的 Log 中，随后通过 AppendEntries RPC 并发的向集群中的其他节点发送请求 当 Follower 节点添加 Log Entry 到自身的 Log 中后，会返回 AppendEntries Response 响应，Leader 节点通过 success 是否为真来判断该节点是否成功保存到该 Follower 节点中 如果一半以上的节点保存该 Log Entry 到自身 Log 中，Leader 节点就会更新本身的 committedIndex 为该 Log Entry 的 Index，下一次发送 AppendEntry RPC 请求时，Follower 节点会根据 leaderCommit 来提交该 Log Entry 和之前未提交的 Log Entry，随后 apply 到状态机中，并返回执行结果给 clients 如果某个 Follower 节点宕机了，或者由于网络丢包导致 RPC 请求没有送到节点中，则 Leader 会一直重试发送该请求 Raft 保证一旦一条 Log Entry 被 committed 后，该条 Log Entry 会被永久存储。即使节点宕机恢复后，恢复后该条日志仍然存在。而来自 clients 请求中的 Log Entry 不需要立即持久化存储，因为 clients 的每条请求会设置一定的超时时间，如果节点宕机导致该 Log Entry 丢失，该条请求就会超时，clients 节点只需重新发送该请求即可。\nRaft 使用 AppendEntries RPC 请求作为日志复制的载体，只有 Leader 节点才会发送 AppendEntries RPC 请求。通常设置 30ms 发送一次 AppendEntries RPC 请求。如发送频率过高，则会导致发送 RPC 请求消耗过高；如发送频率过低，会导致节点之间信息同步过慢。\n根据 entries[] 是否为空，分为两种用途的 RPC 请求：\n当 entries[] 为空时：该 RPC 请求作为 Leader 发送的 heartbeat，维护其 Leader 状态 当 entries[] 不为空时：该请求会携带 Log Entry，用于 Follower 节点保存 Log 到状态机中。在两次 RPC 请求过程中可能会有多条 Log 请求，因此可以放到一次 RPC 请求中发送。携带 Log 的 RPC 请求也可以作为 heartbeat 使用 AppendEntries RPC 请求 # 日志添加 RPC 请求：用于 Leader 节点发送 heartbeat 或日志复制请求\nAppendEntries Request # prevLogIndex 和 prevLogTerm 是 Follower 节点用来检查自身 Log Entry 是否和 Leader 节点的 Log Entry 一致。如果当前 Follower 节点保存的最后一条 Log Entry 的 index 和 term 与 prevLogIndex 和 prevLogTerm 一致，则说明没有冲突，直接把新的 Log Entry 添加到 log[] 尾部即可。如果冲突，则直接拒绝该条 RPC 请求，设置 sucess 为 false。随后 Leader 节点会进行回退，把 nextIndex[ID]--。下次就会发送前一条 Log Entry，直到 Leader 节点和 Follower 节点 Log Entry 不冲突为止。\n如果 Follower 节点保存的有 index 为 prevLogIndex 的 Log Entry，并且保存有大于 index 的节点，则强制删除 index 大于 prevLogIndex 后的所有 Log Entry。\n是本次 RPC 请求中的的 entries[0] 位置的 Log Entry 的前一个位于 log[] 中的 LogEntry 的 index 和 term。\nterm : 当前节点的 term，用于 Follower 节点判断是否是过期的 Leader 节点。 Leader's term \u0026gt;= currentTerm : 当前节点在该 term 任期如果没有投过其它节点，把 voteFor 设为 Candidate 节点的 ID，代表当前轮已经投过了，在该 term 任期中不会再投其它节点 Leader's term \u0026lt; currentTerm : Candidate 节点滞后与当前节点，拒绝其投票请求 leaderId : Candidate 节点可以保存 leaderId，当 clients 发送请求给 Follower 节点后，Follower 节点可以通过把 clients 发到为 leaderId 的节点 prevLogIndex : prevLogIndex = nextIndex[ID] - 1 prevLogTerm : prevLogTerm = log[prevLogIndex].term entries[] : entries = log[nextIndex[ID]:len(log)-1]，用于保存此次需要复制到 Follower 节点的 Log Entry，如果 len(entries) == 0 ，则用于 heartbeat leaderCommit : Leader 节点已提交 Log Entry 的最后一条的 Index。Follower 节点根据此索引来确定已经被提交的 Log Entry，进行提交 AppendEntries Response # term : Follower 节点当前的 term success : 当前 Follower 节点与 Leader 节点保存的 Log Entry 是否冲突 "},{"id":7,"href":"/docs/distributed-system/distributed-transaction/","title":"分布式事务处理","section":"Distributed System","content":" 分布式事务处理 # "},{"id":8,"href":"/docs/java/Java-Collections-Framework/","title":"Java Collections Framework","section":"Java","content":" Java Collections # Java Collections Framework 包含了众多关键的类，如：List, Set Collection 接口 # java.util.Collection 接口 RandomAccess 接口 # java.util.RandomAccess 用于指示 List 是否支持快速随机查找（fast random access） // java.util.RandomAccess public interface RandomAccess { } 该接口中并无任何方法，仅仅用作标记作用，用于指示实现该接口的 List 是否支持快速查找，所有支持快速随机查找的 List 都应该实现该接口。\n// 快速随机查找 for (int i=0, n=list.size(); i \u0026lt; n; i++) list.get(i); // 非快速随机查找，迭代器查找 for (Iterator i=list.iterator(); i.hasNext(); ) i.next(); 可以通过 instanceof 判断 List 是否实现了 RandomAccess 接口。对于支持快速随机查找的 List 可以采取快速遍历，用于提升性能。\nCollections#binarySearch 通过判断 List 是否实现了 RandomAccess 接口，采取不同的遍历方式。\n// java.util.Collections#binarySearch public static \u0026lt;T\u0026gt; int binarySearch(List\u0026lt;? extends Comparable\u0026lt;? super T\u0026gt;\u0026gt; list, T key) { if (list instanceof RandomAccess || list.size()\u0026lt;BINARYSEARCH_THRESHOLD) return Collections.indexedBinarySearch(list, key); else return Collections.iteratorBinarySearch(list, key); } 当我们遍历 List 的时候可以先判断是否实现了 RandomAccess 接口，尽量采取快速随机查找提升性能。\nList 接口 # Set 接口 # ArrayList # "},{"id":9,"href":"/docs/database-system/leveldb/","title":"LevelDB","section":"Database System","content":" LevelDB # "},{"id":10,"href":"/docs/java/Thinking-in-Java/","title":"Thinking in Java","section":"Java","content":" Thinking in Java # Thinking in Java 记录了对于 Java 设计与实现的思考 接口默认方法 # Java 8 允许我们在接口中定义默认方法，只需在接口方法前加上 default 并提供方法体即可。\npublic interface Body { // 刚出生的婴儿只会：吃，睡 void eat(); void sleep(); // 随着婴儿成长，学会了：走，说话 // 为了保持兼容性，采用 default 方法 default void walk() { walk... } default void speak() { speak... } } 默认方法允许在现存的接口中添加新的功能，并保持兼容性。\nJava 8 加入此功能的最主要原因是为了支持 lambda 功能，在接口中新增 lambda 方法，并保持兼容性。\n接口冲突 # 非 default 方法冲突 # 当接口同时提供了同名的非 default 方法，直接重写即可。\ninterface ReadBook { void closeBook(); } interface WriteBook { void closeBook(); } class Book implements ReadBook, WriteBook { @Override public void closeBook() { } } 当接口方法参数不同时，需要实现所有参数不同的方法。\ninterface ReadBook { void closeBook(String name); } interface WriteBook { void closeBook(); } class Book implements ReadBook, WriteBook { @Override public void closeBook() { } @Override public void closeBook(String name) { } } default 方法 # 需要实现 WriteBook 的非 default closeBook() 方法，此时 Book 类具有重载的 closeBook() 和 closeBook(String name) 方法。\ninterface ReadBook { default void closeBook(String name) { } } interface WriteBook { void closeBook(); } class Book implements ReadBook, WriteBook { @Override public void closeBook() { } } 当有两个 default 方法时，Book 需要在方法选择调用接口的 default 方法。\ninterface ReadBook { default void closeBook() { } } interface WriteBook { default void closeBook() { } } class Book implements ReadBook, WriteBook { @Override public void closeBook() { ReadBook.super.closeBook(); WriteBook.super.closeBook(); } } "}]