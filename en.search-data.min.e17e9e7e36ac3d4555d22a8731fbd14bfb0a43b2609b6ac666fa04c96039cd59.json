[{"id":0,"href":"/docs/JVM/ByteCode/ClassFile/","title":"Class 文件结构","section":"字节码","content":" Class 文件结构 # 前言 # 任何一个 class 文件都会对应一个类或接口，但并不是所有的类和接口都有对应的 class 文件（如：动态生成的类）。\n// Main.java public class Main { public static class InnerClass { } public static void main(String[] args) { } } 当执行 $javac Main.java 命令后，会生成 Main.class 和 Main$InnerClass.class 两个 class 文件。\nclass 文件由 8-bit 字节流组成。16-bit 和 32-bit 分别由 2 个和 4 个连续的 8-bit 组成。多字节数据使用大端（bit-endian）序保存。\n使用 u1、u2 和 u4 分别表示 1 字节、2 字节和 4 字节。\nNames # 二进制类和接口名称 # 在 Java 虚拟机中，类和接口的名称使用二进制名称格式表示。此格式与源代码中的类名表示略有不同。\n类名和接口名：二进制名称使用斜杠（/）而不是点（.）来分隔包和类的名称。例如，java.lang.Object 的二进制名称是 java/lang/Object。 内部类：对于内部类，二进制名称中使用美元符号（$）来分隔外部类和内部类的名称。例如，OuterClass.InnerClass 的二进制名称是 OuterClass$InnerClass。 二进制名称的使用场景 # 字节码指令：\n在字节码指令中，类和接口的引用通常使用二进制名称。例如，L 类型签名前缀后跟随二进制名称，如 Ljava/lang/Object; 表示 java.lang.Object。 类文件格式：\n在类文件的常量池中，类和接口的名称存储为二进制名称形式。例如，CONSTANT_Class_info 结构中引用的名称是二进制名称。 示例 # 普通类：\n源代码名称：com.example.MyClass 二进制名称：com/example/MyClass 内部类：\n源代码名称：com.example.OuterClass.InnerClass 二进制名称：com/example/OuterClass$InnerClass ClassFile # ClassFile { u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count]; } magic # magic 用于标识 class 文件的魔法数字，值为：0xCAFEBABE。\nminor_version, major_version # minor_version 和 major_version 分别表示 class 文件的次版本和主版本。使用主次版本一起表示 class 文件的版本，格式为：major_version.minor_version。\n每次发布新版本的 Java SE 都会有新的 major_version，反映重大变更和新特性引入。主版本内的 minor_version 通常用来指示类文件格式的次要更新和改进。\n高 major_version 的 JVM 可以支持低 major_version 的类文件。\nClass File Versions 可以查看所有 Java SE 对应的主版本。\nconstant_pool_count, constant_pool # 常量池是一个包含多种结构的表，用于表示类文件结构及其子结构中引用的各种字符串常量、类和接口名称、字段名称以及其他常量。\nconstant_pool_count 为常量池中条目（entry）的数量加 1。constant_pool 表的索引为：1 至 constant_pool_count - 1。\naccess_flags # 访问标志 (access_flags) 是用于表示类或接口的访问权限和属性的标志掩码。每个标志位表示特定的访问权限或属性。\n下表为 JDK 21 的类访问和属性修饰符：\nFlag Name Value Interpretation ACC_PUBLIC 0x0001 Declared public; may be accessed from outside its package. ACC_FINAL 0x0010 Declared final; no subclasses allowed. ACC_SUPER 0x0020 Treat superclass methods specially when invoked by the invokespecial instruction. ACC_INTERFACE 0x0200 Is an interface, not a class. ACC_ABSTRACT 0x0400 Declared abstract; must not be instantiated. ACC_SYNTHETIC 0x1000 Declared synthetic; not present in the source code. ACC_ANNOTATION 0x2000 Declared as an annotation interface. ACC_ENUM 0x4000 Declared as an enum class. ACC_MODULE 0x8000 Is a module, not a class or interface. this_class # this_class 项目必须是一个有效的常量池索引。该索引指向的常量池条目必须是一个 CONSTANT_Class_info 结构，表示由该类文件定义的类或接口。\nsuper_class # super_class 用于表示当前类或接口的父类，该索引指向常量池中的条目。\n对于类 # 如果 super_class 非 0，该索引指向的常量池条目必须是一个 CONSTANT_Class_info 结构，表示由该类文件定义的类或接口。 如果 super_class 为 0，表示该类为 Object。唯一一个没有直接父类的类。 对于接口 # 对于接口来说，super_class 始终为指向常量池条目的合法索引。所有接口的父类都为 Object 类。\n// Interface.java public interface Interface { } 使用 $javap -v Interface.class 反编译后的部分结果。\n// Interface.class public interface io.github.ileonli.Interface minor version: 0 major version: 65 flags: (0x0601) ACC_PUBLIC, ACC_INTERFACE, ACC_ABSTRACT this_class: #1 // io/github/ileonli/Interface super_class: #3 // java/lang/Object interfaces: 0, fields: 0, methods: 0, attributes: 1 Constant pool: #1 = Class #2 // io/github/ileonli/Interface #2 = Utf8 io/github/ileonli/Interface #3 = Class #4 // java/lang/Object #4 = Utf8 java/lang/Object #5 = Utf8 SourceFile #6 = Utf8 Interface.java // Interface.java public interface Interface extends Cloneable { } 使用 $javap -v Interface.class 反编译后的部分结果。\n// Interface.class public interface io.github.ileonli.Interface extends java.lang.Cloneable minor version: 0 major version: 65 flags: (0x0601) ACC_PUBLIC, ACC_INTERFACE, ACC_ABSTRACT this_class: #1 // io/github/ileonli/Interface super_class: #3 // java/lang/Object interfaces: 1, fields: 0, methods: 0, attributes: 1 Constant pool: #1 = Class #2 // io/github/ileonli/Interface #2 = Utf8 io/github/ileonli/Interface #3 = Class #4 // java/lang/Object #4 = Utf8 java/lang/Object #5 = Class #6 // java/lang/Cloneable #6 = Utf8 java/lang/Cloneable #7 = Utf8 SourceFile #8 = Utf8 Interface.java interfaces_count, interfaces[] # "},{"id":1,"href":"/docs/ProGit/Git-%E5%9F%BA%E7%A1%80/","title":"Git 基础","section":"Pro Git","content":" Git 基础 # 获取 Git 仓库 # 有两种取得 Git 项目仓库的方法：\n将现有项目或目录下导入所有文件到 Git 中，可以使用 $ git init 命令。 从服务器克隆一个现有的 Git 仓库，使用 $ git clone \u0026lt;project url\u0026gt; 命令。 Git 生命周期 # 工作目录下的所有文件都处于两种状态之一：已跟踪和未跟踪。\n已跟踪：是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改、已修改或已放入暂存区。 未跟踪：工作目录中除已跟踪文件以外的所有其它文件都属于未跟踪文件，它们既不存在于上次快照的记录中，也没有放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态。\n编辑已跟踪的文件后（如：修改代码），Git 会将这些修改的文件标记为已修改文件。随后我们会逐步将修改过的文件加入暂存区中，然后提交暂存区中的所有文件。\n如此反复，使用 Git 的生命周期如下图所示：\n检查当前文件状态 # 如果需要查看文件处于的状态，可以使用 $ git status 命令。\n当我们对 $ git init 后的仓库使用此命令，可以看到下边的输出：\n$ git status On branch main No commits yet nothing to commit (create/copy files and use \u0026#34;git add\u0026#34; to track) 我们可以从上边输出中得到以下信息：\n当前的分支名称为 “main”。 所有已跟踪的文件自上次提交后未进行任何修改。 当前目录下没有处于未跟踪的文件。 现在，使用 echo 命令在项目下创建一个新的 README 文件。使用 $ git status 命令后，可以看到一个新的未跟踪文件：\n$ echo \u0026#39;My Project\u0026#39; \u0026gt; README $ git status On branch main No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) README nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) 从输出中可以看到 README 文件处于 Untracked files 下。Git 不会自动将未跟踪文件纳入跟踪范围，除非明确告之“我需要跟踪该文件”，\n跟踪新文件 # 使用命令 $ git add 开始跟踪一个文件。 所以，要跟踪 README 文件，可以运行：\n$ git add README 此时再次运行 $ git status 命令，可以看到 README 文件已被跟踪，并处于暂存状态：\n$ git status On branch main No commits yet Changes to be committed: (use \u0026#34;git rm --cached \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: README 在 Changes to be committed 下的文件处于已暂存状态。如果此时提交，那么该文件当前的版本将被保留在历史记录中。\n暂存已修改文件 # 如果修改了一个名为 CONTRIBUTING.md 的已被跟踪的文件，然后运行 git status 命令，会看到下面内容：\n$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: README Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: CONTRIBUTING.md 文件 CONTRIBUTING.md 出现在 Changes not staged for commit 这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。要暂存这次更新，需要运行 $ git add 命令。\n现在运行 $ git add CONTRIBUTING.md 将 CONTRIBUTING.md 文件放到暂存区，然后再看看 $ git status 的输出：\n$ git add CONTRIBUTING.md $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: CONTRIBUTING.md new file: README 现在两个文件都已暂存，下次提交时就会一并记录到仓库。假设此时，你想要在 CONTRIBUTING.md 里再加条注释，重新编辑保存后，准备提交这两个文件。\n不过且慢，再次运行 $ git status 看看：\n$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: CONTRIBUTING.md new file: README Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: CONTRIBUTING.md 可以看到 CONTRIBUTING.md 文件同时出现在暂存区和非暂存区。这是为什么？\n实际上 Git 只不过暂存了你运行 $ git add 命令时的版本，如果现在提交，CONTRIBUTING.md 的版本是你最后一次运行 $ git add 命令时的那个版本，而不是运行 $ git commit 时，在工作目录中的版本。\n所以，运行了 $ git add 之后又作了修订的文件，需要重新运行 $ git add 把最新版本重新暂存起来：\n$ git add CONTRIBUTING.md $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: CONTRIBUTING.md new file: README 提交更新 # 使用 $ git commit 前，一定要确保所有的修改已经 $ git add 过。\n$ git commit 这种方式会启动文本编辑器以便输入本次提交的说明。退出编辑器时，Git 会丢掉注释行，用你输入提交附带信息生成一次提交。\n# Please enter the commit message for your changes. Lines starting # with \u0026#39;#\u0026#39; will be ignored, and an empty message aborts the commit. # # On branch main # Changes to be committed: # modified: CONTRIBUTING.md # new file: README # 另外，你也可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行，如下所示：\n$ git commit -m \u0026#34;add: CONTRIBUTING.md and README\u0026#34; [main 34ae990] add: CONTRIBUTING.md and README 2 files changed, 2 insertions(+) create mode 100644 README 每一次运行提交操作，都是保存一次项目快照，以后可以回到这个状态，或者进行比较。\n跳过暂存区域 # 尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。\nGit 提供了一个跳过使用暂存区域的方式，只要在提交的时候，给 $ git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 $ git add 步骤。\n移除文件 # 要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。可以用 $ git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。\n如果只是简单地从工作目录中手工删除文件，运行 $ git status 时就会在 Changes not staged for commit 部分（未暂存清单）看到：\n$ rm README $ git status On branch main Changes not staged for commit: (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) deleted: README no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 然后再运行 $ git rm 记录此次移除文件的操作：\n$ git rm README rm \u0026#39;README\u0026#39; $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) deleted: README 下一次提交时，该文件就不再纳入版本管理了。\n如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f。这是一种安全特性，用于防止误删还没有添加到快照的数据，这样的数据不能被 Git 恢复。\n另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。换句话说，仍然文件保留在磁盘，但是并不想让 Git 继续跟踪。\n当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。\n为达到这一目的，可以使用 --cached 选项：\n$ git rm --cached README 状态简览 # 使用 $ git status -s 命令或 $ git status --short 命令可以获得一种更为紧凑的格式输出。\n忽略文件 # 有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。我们可以创建一个名为 .gitignore 文件，列出要忽略的文件。\n可以在 A collection of useful .gitignore templates 查看常用的模板。\n查看提交历史 # 在提交了若干更新，又或者克隆了某个项目之后，如果想回顾下历史提交记录。完成这个任务最简单而又有效的工具是 $ git log 命令。\n$ git log commit 6c669101bea2a6b2400f070f72f35f0866ea714a (HEAD -\u0026gt; main) Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:06:10 2024 +0800 add: README 查看已暂存和未暂存的修改 # 如果 $ git status 命令的输出对于你来说过于模糊，你想知道具体修改了什么地方，可以用 $ git diff 命令。\n撤消操作 # 修正提交 # 有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。此时，可以运行带有 --amend 选项的提交命令尝试重新提交：\n$ git commit --amend 我们有 3 个处于 Changes to be committed 状态的文件。\n$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: 1.txt modified: 2.txt modified: 3.txt 我们使用 $ git commit 提交其中的两个文件。\n$ git commit -m \u0026#34;change: 1.txt, 2.txt\u0026#34; 1.txt 2.txt [main 787cfc9] change: 1.txt, 2.txt 2 files changed, 2 insertions(+) $ git log commit 787cfc91428a9be730e97e103b00e2bfe59e671c (HEAD -\u0026gt; main) Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:40:12 2024 +0800 change: 1.txt, 2.txt commit 984668dbca2b4d3dbf40aad117122bd737a735db Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:37:31 2024 +0800 add 1.txt, 2.txt and 3.txt 此时，发现 3.txt 忘记提交了，此时我们可以使用 $ git commit 再次提交，但此时会多出一次提交记录。\n我们可以使用 $ git commit --amend 提交暂存区中的文件，以及修改提交信息。\n$ git commit --amend [main 71cfcbd] change: 1.txt, 2.txt and 3.txt Date: Sun Aug 4 16:40:12 2024 +0800 3 files changed, 3 insertions(+) 通过查看 git log，此时只有一次修改的记录，上一个修改记录被覆盖掉了。\n$ git log commit 82911668c9d16c8c85e636ecc7d4cd717d0ab9f0 (HEAD -\u0026gt; main) Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:40:12 2024 +0800 change: 1.txt, 2.txt and 3.txt commit 984668dbca2b4d3dbf40aad117122bd737a735db Author: Leon Li \u0026lt;imleonli@outlook.com\u0026gt; Date: Sun Aug 4 16:37:31 2024 +0800 add 1.txt, 2.txt and 3.txt 取消暂存的文件 # 已经修改了两个文件并且想要将它们作为两次独立的修改提交，但是却意外地输入了 $ git add * 暂存了它们两个。如何只取消暂存两个中的一个呢？\n$ git status On branch main Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: 1.txt modified: 2.txt no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 我们可以使用 $ git restore --staged 将文件从暂存区移除，但保留工作区中的更改。\n$ git restore --staged 2.txt (base) leon@Inspiron7590:~/Projects/demo$ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: 1.txt Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: 2.txt 撤消对文件的修改 # 如果你并不想保留对文件的修改怎么办？你该如何方便地撤消修改,将它还原成上次提交时的样子（或者刚克隆完的样子，或者刚把它放入工作目录时的样子）？\n$ git status On branch main Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: README no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 我们可以直接使用 $ git restore 命令。可以看到 README 文件的修改已被撤销。\n$ git restore README $ git status On branch main nothing to commit, working tree clean "},{"id":2,"href":"/docs/system-programming/network-byte-order/","title":"网络字节序","section":"Linux 网络编程","content":" 网络字节序 # 大小端 # 不同架构的 CPU 中，4 字节整数 1 在内存中存储的方式是不同的。\n大端序（big endian）：最高位有效字节存储在低内存地址，而最低位有效字节存储在高内存地址。 小端序（little endian）：最高位有效字节存储在高内存地址，而最低位有效字节存储在低内存地址。 对于一个 4 字节整数 0x01020304，大小端序存储方式分别如下：\n地址: 0 1 2 3 （大端序保存） 01 02 03 04 地址: 0 1 2 3 （小端序保存） 04 03 02 01 可以使用下边的方法判断机器的字节序：\n通过 endian.h 提供的 BYTE_ORDER 宏。 #include \u0026lt;endian.h\u0026gt; bool big_endian() { return BYTE_ORDER == BIG_ENDIAN; } bool little_endian() { return BYTE_ORDER == LITTLE_ENDIAN; } 将 uint16_t 类型的数字转为 char *，通过高字节和低字节进行判断。 bool big_endian() { uint16_t val = 0x0102; return ((char *) (\u0026amp;val))[0] == 0x01; } bool little_endian() { uint16_t val = 0x0102; return ((char *) (\u0026amp;val))[1] == 0x01; } 和方法 2 类似，利用的是 union 相同的内存位置存储不同的数据类型。 union endian { uint16_t val; char bytes[2]; }; bool big_endian() { union endian en{}; en.val = 0x0102; return en.bytes[0] == 0x01; } bool little_endian() { union endian en{}; en.val = 0x0102; return en.bytes[0] == 0x02; } 为什么有两种不同的字节序？\n大端序是人类最熟悉的读写方法，从左向右处理。\n小端序更利于计算机处理，因为计算都是从低位开始的，先处理低位字节，效率比较高。\n网络字节序 # 如果通信双方采用不同的架构，收发数据后进行解析时会发生问题。如：大端序机器 A 发送 0x01020304 到小端序机器 B 时，B 以小端序方式解析该数字为 0x04030201。\n为解决上边问题，网络传输数据时，通信双方需要约定统一方式，把此约定叫做网络字节序（network byte order）。\n网络字节序规定使用大端序，大多数网络协议（例如 TCP/IP 协议族）规定了网络字节序采用大端序。\n因此，小端序发送数据时，需要先转为大端序。\n字节序转换 # 下边函数用于字节序的相互转换：\n#include \u0026lt;arpa/inet.h\u0026gt; uint32_t htonl(uint32_t hostlong); uint16_t htons(uint16_t hostshort); uint32_t ntohl(uint32_t netlong); uint16_t ntohs(uint16_t netshort); 函数名中的 h 表示主机（host）字节序，n 表示网络（network）字节序；s 表示 short 类型，l 表示 long 类型。\n"},{"id":3,"href":"/docs/Netty/ByteBuf/","title":"ByteBuf","section":"Netty","content":" ByteBuf # 基本结构 # +-------------------+------------------+------------------+-------------+ | discardable bytes | readable bytes | writable bytes | ... | | | (CONTENT) | | | +-------------------+------------------+------------------+-------------+ | | | | | 0 \u0026lt;= readerIndex \u0026lt;= writerIndex \u0026lt;= capacity maxCapacity 相关操作 # 有些方法会返回 this，以支持链式调用。\n容量 # ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); int capacity = buf.capacity();// 获取当前的容量 int maxCapacity = buf.maxCapacity();// 支持的最大容量，通常为 Integer.MAX_VALUE int readableBytes = buf.readableBytes();// writerIndex - readerIndex int writableBytes = buf.writableBytes();// capacity - writerIndex boolean readable; readable = buf.isReadable(8);// isReadable(int), writerIndex - readerIndex \u0026gt;= size readable = buf.isReadable();// 相当于 isReadable(1) boolean writable; writable = buf.isWritable(8); // isWritable(int), capacity - writerIndex \u0026gt;= size writable = buf.isWritable(); // 相当于 isWritable(1) int maxWritableBytes = buf.maxWritableBytes();// maxCapacity - writerIndex 读写 # readType() 用于读取 Type 类型的数据，writeType() 用于写入 Type 类型的值。\n与 readType() 类似的有 getType()，与 writeType() 类似的有 setType()。唯一的区别是 getType() 和 setType() 不会改变读写指针，而 readType() 和 writeType()会改变读写指针。\nByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); boolean booleanV = true; buf.writeBoolean(booleanV); // 8-bit buf.readBoolean(); byte byteV = 0; buf.writeByte(byteV); // 8-bit buf.readByte(); short shortV = 0; buf.writeShort(shortV); // 16-bit buf.readShort(); int mediumV = 0; buf.writeMedium(mediumV); // 24-bit buf.readMedium(); int intV = 0; buf.writeInt(intV); // 32-bit buf.readInt(); long longV = 0; buf.writeLong(longV); // 64-bit buf.readLong(); char charV = 0; buf.writeChar(charV); // 8-bit buf.readChar(); float floatV = 0; buf.writeFloat(floatV); // 32-bit buf.readFloat(); double doubleV = 0.0; buf.writeDouble(doubleV); // 64-bit buf.readDouble(); byte[] bytes = new byte[]{0, 1, 2, 3, 4, 5, 6}; // 等价于 buf.writeBytes(bytes, 0, bytes.length) buf.writeBytes(bytes); // 从 `bytes` 的 `srcIndex` 处读取`length` 字节，写入到 `buf` buf.writeBytes(bytes, 1, 3); byte[] bytesDestination = new byte[8]; buf.readBytes(bytesDestination); ByteBuf originalBuf = ByteBufAllocator.DEFAULT.buffer(); // 等价于 buf.writeBytes(originalBuf, originalBuf.readableBytes()) buf.writeBytes(originalBuf); // 等价于 buf.writeBytes(originalBuf, originalBuf.readerIndex(), 3); buf.writeBytes(originalBuf, 3); // 从 `originalBuf` 的 `srcIndex` 处读取`length` 字节，写入到 `buf` buf.writeBytes(originalBuf, 1, 3); ByteBuf bufDestination = ByteBufAllocator.DEFAULT.buffer(); buf.readBytes(bufDestination); 派生 # duplicate() slice() slice(int, int) readSlice(int) retainedDuplicate() retainedSlice() retainedSlice(int, int) readRetainedSlice(int) 读写指针 # ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); int readerIndex = buf.readerIndex(); // 获取当前读指针位置 int writerIndex = buf.writerIndex(); // 获取当前写指针位置 buf.readerIndex(0); // readerIndex(int)，设置读指针位置 buf.writerIndex(0); // writerIndex(int)，设置写指针位置 buf.markReaderIndex(); // 记录当前读指针位置 // do something buf.resetReaderIndex(); // 恢复到之前 mark 的读指针位置 buf.markWriterIndex(); // 记录当前写指针位置 // do something buf.resetWriterIndex(); // 恢复到之前 mark 的写指针位置 丢弃字节 # ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(); System.out.println(buf); // PooledUnsafeDirectByteBuf(ridx: 0, widx: 0, cap: 256) for (int i = 0; i \u0026lt; 16; i++) { buf.writeInt(i); } for (int i = 0; i \u0026lt; 8; i++) { buf.readInt(); } System.out.println(buf); // PooledUnsafeDirectByteBuf(ridx: 32, widx: 64, cap: 256) buf.discardReadBytes(); System.out.println(buf); // PooledUnsafeDirectByteBuf(ridx: 0, widx: 32, cap: 256) 调用 discardReadBytes() 丢弃 0 ~ readerIndex 之间的字节。将 readerIndex 和 writerIndex 之间的字节移动到第 0 个索引，并将 readerIndex 和 writerIndex 分别设置为 0 和 oldWriterIndex - oldReaderIndex。\nBEFORE discardReadBytes() +-------------------+------------------+------------------+ | discardable bytes | readable bytes | writable bytes | +-------------------+------------------+------------------+ | | | | 0 \u0026lt;= readerIndex \u0026lt;= writerIndex \u0026lt;= capacity AFTER discardReadBytes() +------------------+--------------------------------------+ | readable bytes | writable bytes (got more space) | +------------------+--------------------------------------+ | | | readerIndex (0) \u0026lt;= writerIndex (decreased) \u0026lt;= capacity 也可以调用 clear() 方法，当调用后会直接将 readerIndex 和 writerIndex 同时设为 0。\nBEFORE clear() +-------------------+------------------+------------------+ | discardable bytes | readable bytes | writable bytes | +-------------------+------------------+------------------+ | | | | 0 \u0026lt;= readerIndex \u0026lt;= writerIndex \u0026lt;= capacity AFTER clear() +---------------------------------------------------------+ | writable bytes (got more space) | +---------------------------------------------------------+ | | 0 = readerIndex = writerIndex \u0026lt;= capacity ByteBufHolder # ByteBufHolder 可用于封装 ByteBuf 数据，可用于存储消息对象。\n分类 # Heap 和 Direct # Heap 底层使用 byte[]。\nDirect 底层使用 java.nio.ByteBuffer。\nPooled 和 Unpooled # 池化和非池化的区别，Netty 维护者（Norman Maurer）的 回答：\nThe difference is that with unpooled Netty will allocate a new buffer everytime you call ByteBufAllocator.buffer which comes with some overhead, especially with direct buffers. When you use pooled Netty will try to pool the buffers and so minimize the overhead of allocation and releasing of buffers. Safe 和 Unsafe # Unsafe 的 ByteBuf 会使用 sun.misc.Unsafe 直接申请内存。\nAbstractByteBuf # AbstractByteBuf 是 buffer 的基本骨架，提供了基本的操作。\n类中共有 4 个 *Index 和 1 个指定最大容量的字段 maxCapacity。\nint readerIndex; int writerIndex; private int markedReaderIndex; private int markedWriterIndex; private int maxCapacity; readerIndex 和 writerIndex 分别指定当前读入和写入的位置，当调用 read* 和 write* 方法时会修改位置，而 get* 和 set* 方法不会。\nmarkedReaderIndex 和 markedWriterIndex 用于标注当前的位置，默认值为 0。调用 markReaderIndex() 和 markWriterIndex() 方法用于标记当前读入和写入的位置。\n当调用 resetReaderIndex() 和 resetWriterIndex() 方法时，会将当前的 readerIndex 和 writerIndex 设置为 markedReaderIndex 和 markedWriterIndex。\npublic ByteBuf resetReaderIndex() { readerIndex(markedReaderIndex); return this; } public ByteBuf resetWriterIndex() { writerIndex(markedWriterIndex); return this; } 可读可写只需要判断 writerIndex 和 readerIndex 的相对位置即可。\npublic boolean isReadable() { return writerIndex \u0026gt; readerIndex; } public boolean isWritable() { return capacity() \u0026gt; writerIndex; } public int readableBytes() { return writerIndex - readerIndex; } public int writableBytes() { return capacity() - writerIndex; } ByteBufAllocator # 继承关系 # 默认 Allocator # ByteBufAllocator 类中的 DEFAULT 指定 Netty 使用的 Allocator。\npublic interface ByteBufAllocator { ByteBufAllocator DEFAULT = ByteBufUtil.DEFAULT_ALLOCATOR; } ByteBufUtil 类通过获取系统变量确认默认的 ByteBufAllocator，默认使用 PooledByteBufAllocator 类。\n可以通过 java -Dio.netty.allocator.type: {unpooled|pooled} 指定。\npublic final class ByteBufUtil { ... static final ByteBufAllocator DEFAULT_ALLOCATOR; static { String allocType = SystemPropertyUtil.get( \u0026#34;io.netty.allocator.type\u0026#34;, PlatformDependent.isAndroid() ? \u0026#34;unpooled\u0026#34; : \u0026#34;pooled\u0026#34;); allocType = allocType.toLowerCase(Locale.US).trim(); ByteBufAllocator alloc; if (\u0026#34;unpooled\u0026#34;.equals(allocType)) { alloc = UnpooledByteBufAllocator.DEFAULT; logger.debug(\u0026#34;-Dio.netty.allocator.type: {}\u0026#34;, allocType); } else if (\u0026#34;pooled\u0026#34;.equals(allocType)) { alloc = PooledByteBufAllocator.DEFAULT; logger.debug(\u0026#34;-Dio.netty.allocator.type: {}\u0026#34;, allocType); } else { alloc = PooledByteBufAllocator.DEFAULT; logger.debug(\u0026#34;-Dio.netty.allocator.type: pooled (unknown: {})\u0026#34;, allocType); } DEFAULT_ALLOCATOR = alloc; } ... } 内存回收 # Netty 使用引用计数方法对 ByteBuf 进行回收。实现 ReferenceCounted 的实例开始时的引用计数为 1，只要引用计数大于 0，就能保证对象不会被释放。当引用计数减少到 0 时，该实例就会被释放。\nUnpooledHeapByteBuf 使用的是 JVM 内存，只需等 GC 回收即可。 UnpooledDirectByteBuf 使用了直接内存， 扩容逻辑 # 当向 ByteBuf 写入数据，而容量不足时（writerIndex \u0026gt; capacity()），会自动进行扩容。\n每次调用 write*() 时，方法内部会调用 ensureWritable0() 确保有足够的空间。\n调用 ensureWritable0() 时会传入 minWritableBytes 参数，确保有足够的字节数，调用 writeLong() 时，会被设为 8。\npublic abstract class AbstractByteBuf extends ByteBuf { ... public ByteBuf writeInt(int value) { ensureWritable0(4); _setInt(writerIndex, value); writerIndex += 4; return this; } ... } ensureWritable0 # ensureWritable0() 进行扩容的代码如下：\n获取当前的写入索引（writerIndex），并计算目标容量（targetCapacity），即当前写入索引加上要写入的最小字节数。 使用非短路逻辑与运算符（\u0026amp;）来检查目标容量是否在合理范围内。这里选择使用非短路逻辑与运算符是为了减少分支，因为该代码段通常是一个热点路径，并且目标容量很少会溢出。如果目标容量在合理范围内，则表示缓冲区已经有足够的空间，直接返回。 如果启用了边界检查（checkBounds），并且目标容量小于 0 或者大于最大容量（maxCapacity），则抛出索引越界异常。 如果目标容量不在合理范围内，需要增加缓冲区的容量。首先，调用 maxFastWritableBytes() 方法获取一个快速可写入的字节数，然后根据这个字节数和传入的最小可写入字节数来计算新的容量。如果快速可写入字节数大于等于传入的最小可写入字节数，则新容量直接设定为当前写入索引加上快速可写入字节数，否则通过调用 calculateNewCapacity 方法来计算新容量。 通过调用 capacity(newCapacity) 方法来调整缓冲区的容量，确保其足够可写入。 public abstract class AbstractByteBuf extends ByteBuf { ... final void ensureWritable0(int minWritableBytes) { final int writerIndex = writerIndex(); final int targetCapacity = writerIndex + minWritableBytes; // using non-short-circuit \u0026amp; to reduce branching - this is a hot path and targetCapacity should rarely overflow if (targetCapacity \u0026gt;= 0 \u0026amp; targetCapacity \u0026lt;= capacity()) { ensureAccessible(); return; } if (checkBounds \u0026amp;\u0026amp; (targetCapacity \u0026lt; 0 || targetCapacity \u0026gt; maxCapacity)) { ensureAccessible(); throw new IndexOutOfBoundsException(String.format( \u0026#34;writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s\u0026#34;, writerIndex, minWritableBytes, maxCapacity, this)); } // Normalize the target capacity to the power of 2. final int fastWritable = maxFastWritableBytes(); int newCapacity = fastWritable \u0026gt;= minWritableBytes ? writerIndex + fastWritable : alloc().calculateNewCapacity(targetCapacity, maxCapacity); // Adjust to the new capacity. capacity(newCapacity); } ... } calculateNewCapacity # calculateNewCapacity 计算新的容量时的思路总结如下：\nminNewCapacity 参数为最小申请的容量，检查传入的 minNewCapacity 参数是否为非负数，如果不是，则抛出异常。 检查 minNewCapacity 是否超过了最大容量 maxCapacity，如果超过了，则抛出异常。 设定一个阈值 threshold，表示页面大小为 4 MiB。 minNewCapacity 等于阈值 threshold，则直接返回阈值，不再需要进行容量的调整。 minNewCapacity 大于阈值 threshold，则按照阈值为单位递增容量。在这种情况下，新容量的计算方式不再是简单的翻倍增加，而是以阈值为单位递增。 minNewCapacity 小于等于阈值 threshold 时，则将 minNewCapacity 设置为大于等于 64 的最接近的 2 的幂，以确保足够的容量同时尽量减小内存的浪费。 返回新容量和最大容量中较小的一个值，以确保新容量不会超过最大容量限制。 public abstract class AbstractByteBufAllocator implements ByteBufAllocator { ... public int calculateNewCapacity(int minNewCapacity, int maxCapacity) { checkPositiveOrZero(minNewCapacity, \u0026#34;minNewCapacity\u0026#34;); if (minNewCapacity \u0026gt; maxCapacity) { throw new IllegalArgumentException(String.format( \u0026#34;minNewCapacity: %d (expected: not greater than maxCapacity(%d)\u0026#34;, minNewCapacity, maxCapacity)); } final int threshold = CALCULATE_THRESHOLD; // 4 MiB page if (minNewCapacity == threshold) { return threshold; } // If over threshold, do not double but just increase by threshold. if (minNewCapacity \u0026gt; threshold) { int newCapacity = minNewCapacity / threshold * threshold; if (newCapacity \u0026gt; maxCapacity - threshold) { newCapacity = maxCapacity; } else { newCapacity += threshold; } return newCapacity; } // 64 \u0026lt;= newCapacity is a power of 2 \u0026lt;= threshold final int newCapacity = MathUtil.findNextPositivePowerOfTwo(Math.max(minNewCapacity, 64)); return Math.min(newCapacity, maxCapacity); } ... } "},{"id":4,"href":"/docs/ProGit/Git-%E5%88%86%E6%94%AF/","title":"Git 分支","section":"Pro Git","content":" Git 分支 # 分支创建 # 使用 $ git branch 命令后，会在当前所在的提交对象上创建一个指针。此操作并不会直接切换到新创建的分支上。\n那么，Git 又是怎么知道当前在哪一个分支上呢？有一个名为 HEAD 的特殊指针，指向当前分支。\n$ git branch testing 分支切换 # 要切换到一个已存在的分支，需要使用 $ git switch 命令。\n$ git switch testing 这样 HEAD 就指向 testing 分支了。\n分支合并 # testing 分支提交 # $ touch 1.txt $ git commit -a -m \u0026#39;add: 1.txt\u0026#39; master 分支提交 # $ git switch master $ touch 2.txt $ git commit -a -m \u0026#39;add: 2.txt\u0026#39; 合并 # 使用 $ git merge 即可将 testing 分支中的内容合并到 master 分支中。\n$ git merge testing "},{"id":5,"href":"/docs/JVM/ByteCode/constant_pool/","title":"常量池","section":"字节码","content":" 常量池 # 常量池是一个表，所有的表项都有以下的格式。tag 表示表项的类型，info 用于表示 tag 类型所需要存储的信息。\ncp_info { u1 tag; u1 info[]; } 常量池索引是从 1 开始的，不是直接从 0 开始。如果需要表达“不引用任何一个常量池项目”的含义，可以把索引值设置为 0 来表示。\n为什么设计常量池？ # 复用 # 常量池允许在类文件中共享常量数据。例如，字符串常量、类名、方法名和字段名等。可以避免了在类文件中多次存储相同的常量，从而减少类文件的大小。\n下边的代码，通过 $javac Main.java 编译后，使用 $javap -v Main.class 进行反编译。\npublic class Main { public static void main(String[] args) { String str = \u0026#34;Hello World!\u0026#34;; System.out.println(str); System.out.println(\u0026#34;Hello World!\u0026#34;); } } public class io.github.ileonli.Main minor version: 0 major version: 65 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #21 // io/github/ileonli/Main super_class: #2 // java/lang/Object interfaces: 0, fields: 0, methods: 2, attributes: 1 Constant pool: #1 = Methodref #2.#3 // java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #2 = Class #4 // java/lang/Object #3 = NameAndType #5:#6 // \u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #4 = Utf8 java/lang/Object #5 = Utf8 \u0026lt;init\u0026gt; #6 = Utf8 ()V #7 = String #8 // Hello World! #8 = Utf8 Hello World! #9 = Fieldref #10.#11 // java/lang/System.out:Ljava/io/PrintStream; #10 = Class #12 // java/lang/System #11 = NameAndType #13:#14 // out:Ljava/io/PrintStream; #12 = Utf8 java/lang/System #13 = Utf8 out #14 = Utf8 Ljava/io/PrintStream; #15 = Methodref #16.#17 // java/io/PrintStream.println:(Ljava/lang/String;)V #16 = Class #18 // java/io/PrintStream #17 = NameAndType #19:#20 // println:(Ljava/lang/String;)V #18 = Utf8 java/io/PrintStream #19 = Utf8 println #20 = Utf8 (Ljava/lang/String;)V #21 = Class #22 // io/github/ileonli/Main #22 = Utf8 io/github/ileonli/Main #23 = Utf8 Code #24 = Utf8 LineNumberTable #25 = Utf8 main #26 = Utf8 ([Ljava/lang/String;)V #27 = Utf8 SourceFile #28 = Utf8 Main.java { public io.github.ileonli.Main(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return LineNumberTable: line 3: 0 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: (0x0009) ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=2, args_size=1 0: ldc #7 // String Hello World! 2: astore_1 3: getstatic #9 // Field java/lang/System.out:Ljava/io/PrintStream; 6: aload_1 7: invokevirtual #15 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 10: getstatic #9 // Field java/lang/System.out:Ljava/io/PrintStream; 13: ldc #7 // String Hello World! 15: invokevirtual #15 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 18: return LineNumberTable: line 5: 0 line 6: 3 line 7: 10 line 8: 18 } 从 class 文件的反编译结果可以看出 main 方法中有大量的复用：\n0: ldc #7 和 13: ldc #7 使用 #7 来代替 Hello World! 字符串。 3: getstatic #9 和 10: getstatic #9 使用 #9 来代替 java/lang/System.out:Ljava/io/PrintStream; 变量。 7: invokevirtual #15 和 15: invokevirtual #15 使用 #15 来代替 java/io/PrintStream.println:(Ljava/lang/String;)V 方法。 符号引用 # JVM 中的指令并不依赖于运行时类、接口、类实例或数组的布局。相反，指令通过常量池表中的符号信息进行引用。\n这意味着 JVM 指令在运行时操作时，不需要直接处理类或对象的内存布局，而是通过常量池中的符号来找到所需的类、方法、字段等信息。\n如我们有个类 Example，其中有个方法为 printMesssage。在编译后的 class 文件中，常量池会有以下条目：\nCONSTANT_Class_info：表示 Example 类。 CONSTANT_NameAndType_info：表示 printMessage 方法的名字和类型。 CONSTANT_Methodref_info：表示 Example 类中的 printMessage 方法。 public class Example { public void printMessage() { System.out.println(\u0026#34;Hello, World!\u0026#34;); } } 使用 $javap -v Example.class 反编译得到的结果。\nJVM 指令例如 invokevirtual 会使用这些常量池条目来确定具体要调用的方法，而不是直接引用方法在内存中的地址。\npublic class io.github.ileonli.Example minor version: 0 major version: 65 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #21 // io/github/ileonli/Example super_class: #2 // java/lang/Object interfaces: 0, fields: 0, methods: 2, attributes: 1 Constant pool: #1 = Methodref #2.#3 // java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #2 = Class #4 // java/lang/Object #3 = NameAndType #5:#6 // \u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #4 = Utf8 java/lang/Object #5 = Utf8 \u0026lt;init\u0026gt; #6 = Utf8 ()V #7 = Fieldref #8.#9 // java/lang/System.out:Ljava/io/PrintStream; #8 = Class #10 // java/lang/System #9 = NameAndType #11:#12 // out:Ljava/io/PrintStream; #10 = Utf8 java/lang/System #11 = Utf8 out #12 = Utf8 Ljava/io/PrintStream; #13 = String #14 // Hello, World! #14 = Utf8 Hello, World! #15 = Methodref #16.#17 // java/io/PrintStream.println:(Ljava/lang/String;)V #16 = Class #18 // java/io/PrintStream #17 = NameAndType #19:#20 // println:(Ljava/lang/String;)V #18 = Utf8 java/io/PrintStream #19 = Utf8 println #20 = Utf8 (Ljava/lang/String;)V #21 = Class #22 // io/github/ileonli/Example #22 = Utf8 io/github/ileonli/Example #23 = Utf8 Code #24 = Utf8 LineNumberTable #25 = Utf8 printMessage #26 = Utf8 SourceFile #27 = Utf8 Example.java { public io.github.ileonli.Example(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return LineNumberTable: line 3: 0 public void printMessage(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #13 // String Hello, World! 5: invokevirtual #15 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 5: 0 line 6: 8 } 常量池项目类型 # 常量池中的表项共有下边几种：\nConstant Kind Tag Class File Format Java SE CONSTANT_Utf8 1 45.3 1.0.2 CONSTANT_Integer 3 45.3 1.0.2 CONSTANT_Float 4 45.3 1.0.2 CONSTANT_Long 5 45.3 1.0.2 CONSTANT_Double 6 45.3 1.0.2 CONSTANT_Class 7 45.3 1.0.2 CONSTANT_String 8 45.3 1.0.2 CONSTANT_Fieldref 9 45.3 1.0.2 CONSTANT_Methodref 10 45.3 1.0.2 CONSTANT_InterfaceMethodref 11 45.3 1.0.2 CONSTANT_NameAndType 12 45.3 1.0.2 CONSTANT_MethodHandle 15 51.0 7 CONSTANT_MethodType 16 51.0 7 CONSTANT_Dynamic 17 55.0 11 CONSTANT_InvokeDynamic 18 51.0 7 CONSTANT_Module 19 53.0 9 CONSTANT_Package 20 53.0 9 CONSTANT_Class_info # CONSTANT_Class_info 用于表示一个类，或者一个接口。\nname_index 为指向常量池表项的索引，该表项必须为 CONSTANT_Utf8_info。\nCONSTANT_Class_info { u1 tag; u2 name_index; } "},{"id":6,"href":"/docs/system-programming/address-families/","title":"网络地址族","section":"Linux 网络编程","content":" 网络地址族 # 网络地址 # 网络地址分为 IPv4 和 IPv6，分别使用 sockaddr_in 和 sockaddr_in6 结构体表示。\nsockaddr_in # struct sockaddr_in { sa_family_t sin_family; /* address family: AF_INET */ in_port_t sin_port; /* port in network byte order */ struct in_addr sin_addr; /* internet address */ /* Pad to size of `struct sockaddr\u0026#39;. */ unsigned char sin_zero[8]; }; /* Internet address */ struct in_addr { uint32_t s_addr; /* address in network byte order */ }; sin_family：在 IPv4 中设为 AF_INET。 sin_port：网络字节序保存的端口（0～65535）。 sin_addr：网络字节序保存的 32 位 IP 地址信息。 sin_zero：使 sockaddr_in 和 sockaddr 结构体大小保持一致而插入的填充位，需手动设为 0。 https://man7.org/linux/man-pages/man7/ip.7.html\nsockaddr_in6 # struct sockaddr_in6 { sa_family_t sin6_family; /* AF_INET6 */ in_port_t sin6_port; /* port number */ uint32_t sin6_flowinfo; /* IPv6 flow information */ struct in6_addr sin6_addr; /* IPv6 address */ uint32_t sin6_scope_id; /* Scope ID (new in Linux 2.4) */ }; struct in6_addr { unsigned char s6_addr[16]; /* IPv6 address */ }; sin6_family：在 IPv6 中总设为 AF_INET6。 sin6_port：网络字节序保存的端口（0～65535）。 sin6_flowinfo：IPv6 流信息（不广泛使用）。 sin6_addr：表示 IPv6 地址的结构体，定义为 struct in6_addr。 sin6_scope_id：范围标识符（用于链路本地和站点本地地址）。 https://man7.org/linux/man-pages/man7/ipv6.7.html\nin_addr 和 in6_addr # in_addr # 我们比较熟悉的 IPv4 地址表示方法为点分十进制表示法，如：201.123.235.213。\n而 in_addr 结构体使用 uint32_t 保存 IPv4 地址，我们需要将字符串形式的 IPv4 地址转为 32 位整数表示。\ninet_addr 函数可用于转换，该函数在转换的同时会进行网络字节序的转换。\ninet_ntoa 函数则相反，将 in_addr 结构体转为字符串。\n注意：inet_ntoa 函数返回的是一个指向静态缓冲区的指针，最好将返回值拷贝到其它地方，以免被覆盖。\n#include \u0026lt;arpa/inet.h\u0026gt; in_addr_t inet_addr(const char *cp); char *inet_ntoa(struct in_addr in); 也可以使用 inet_aton 函数，该函数将结果直接保存到传入的 inp 结构体中。\n#include \u0026lt;arpa/inet.h\u0026gt; int inet_aton(const char *cp, struct in_addr *inp); in6_addr # sockaddr_in5 结构体中的 in6_addr 结构体包含一个 unsigned char 类型的成员 s6_addr，用于存储 128 位的 IPv6 地址。\ninet_pton 函数中的 af 参数必须为 AF_INET 和 AF_INET6，分别处理 IPv4 和 IPv6 协议。\n#include \u0026lt;arpa/inet.h\u0026gt; int inet_pton(int af, const char *restrict src, void *restrict dst); const char *inet_ntop(int af, const void *restrict src, char dst[restrict .size], socklen_t size); 网络地址初始化 # IPv4 # #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; int main() { const char *address = \u0026#34;211.123.211.168\u0026#34;; // IP 地址 const char *port = \u0026#34;7890\u0026#34;; // 端口 struct sockaddr_in addr; memset(\u0026amp;addr, 0, sizeof(addr)); addr.sin_family = AF_INET; // IPv4; addr.sin_addr.s_addr = inet_addr(address); // 设置 IP 地址 addr.sin_port = htons(atoi(port)); // 以网络字节序设置端口 } IPv6 # #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; int main() { const char *address = \u0026#34;2001:0db8:85a3:0000:0000:8a2e:0370:7334\u0026#34;; // IPv6 地址 const char *port = \u0026#34;7890\u0026#34;; // 端口 struct sockaddr_in6 addr; memset(\u0026amp;addr, 0, sizeof(addr)); addr.sin6_family = AF_INET6; // IPv6 inet_pton(AF_INET6, address, \u0026amp;addr.sin6_addr); // 设置 IP 地址 addr.sin6_port = htons(atoi(port)); // 以网络字节序设置端口 } 思考 # 为什么 sockaddr_in 和 sockaddr_in6 分别表示 IPv4 和 IPv6 协议，还要额外使用 sa_family_t 指定协议版本呢？\n因为 connect、bind、和 accept 函数第二个参数都接收 sockaddr 结构体。因此，需要使用 sa_family 用于区分不同版本的协议。通过使用通用的 sockaddr 结构体，该函数不仅可以处理 IPv4 和 IPv6 协议，还可处理其它协议。这样，就不需要为每种协议都提供对应的函数。\nstruct sockaddr { sa_family_t sa_family; /* Address family */ char sa_data[]; /* Socket address */ }; "},{"id":7,"href":"/docs/Netty/EventLoop/","title":"EventLoop","section":"Netty","content":" EventLoop # 一旦注册，将处理 Channel 的所有 I/O 操作。一个 EventLoop 实例通常会处理多个 Channel，但这可能取决于实现细节和内部机制。\nEventLoop 本质是一个单线程执行器，同时维护了一个 Selector。\nEventLoop 由 Thread 驱动，且不会更改\ntry (EventLoop loop = new DefaultEventLoop()) { for (int i = 0; i \u0026lt; 3; i++) { loop.submit(() -\u0026gt; { for (int j = 0; j \u0026lt; 16; j++) { System.out.print(j + \u0026#34; \u0026#34;); } System.out.println(); }); } } 使用 EventLoop 的定时调度功能。\ntry (EventLoop loop = new DefaultEventLoop()) { ScheduledFuture\u0026lt;?\u0026gt; future = loop.schedule( () -\u0026gt; LocalDateTime.now(), 3, TimeUnit.SECONDS); System.out.println(future.get()); } 如果（当前）调用线程正是支撑 EventLoop 的线程，那么所提交的代码块将会被（直接）执行。否则，EventLoop 将调度该任务以便稍后执行，并将它放入到内部队列中。当\n如果必须要进行阻塞调用或者执行长时间运行的任务，我们建议使用一个专门的 EventExecutor。\n继承关系 # OrderedEventExecutor # 用于标记 EventExecutor 将以有序（ordered） / 串行（serial）的方式处理提交的任务。\npublic interface OrderedEventExecutor extends EventExecutor { } EventLoopGroup # next() 方法用于获取该 EventLoopGroup 中的下一个 EventLoop。 register() 将 Channel 注册到该 EventLoopGroup 中，只可以注册一次。 public interface EventLoopGroup extends EventExecutorGroup { @Override EventLoop next(); ChannelFuture register(Channel channel); ChannelFuture register(ChannelPromise promise); @Deprecated ChannelFuture register(Channel channel, ChannelPromise promise); } EventExecutor # EventExecutor 是一个特殊的 EventExecutorGroup，它提供了一些方便的方法来查看线程是否在事件循环中执行。除此之外，它还扩展了 EventExecutorGroup 以允许一种通用的方式来访问方法。\nnext() 返回自身。 parent() 返回所属的 EventExecutorGroup，没有则返回 null。 inEventLoop() 返回当前执行线程是否是 EventLoop 所绑定的线程。 public interface EventExecutor extends EventExecutorGroup { @Override EventExecutor next(); EventExecutorGroup parent(); boolean inEventLoop(); boolean inEventLoop(Thread thread); \u0026lt;V\u0026gt; Promise\u0026lt;V\u0026gt; newPromise(); \u0026lt;V\u0026gt; ProgressivePromise\u0026lt;V\u0026gt; newProgressivePromise(); \u0026lt;V\u0026gt; Future\u0026lt;V\u0026gt; newSucceededFuture(V result); \u0026lt;V\u0026gt; Future\u0026lt;V\u0026gt; newFailedFuture(Throwable cause); } EventExecutorGroup # EventExecutorGroup 负责通过它的 next() 方法提供 EventExecutor。除此之外，还负责处理生命周期，允许以全局方式关闭它们。\npublic interface EventExecutorGroup extends ScheduledExecutorService, Iterable\u0026lt;EventExecutor\u0026gt; { boolean isShuttingDown(); Future\u0026lt;?\u0026gt; shutdownGracefully(); Future\u0026lt;?\u0026gt; shutdownGracefully(long quietPeriod, long timeout, TimeUnit unit); Future\u0026lt;?\u0026gt; terminationFuture(); @Override @Deprecated void shutdown(); @Override @Deprecated List\u0026lt;Runnable\u0026gt; shutdownNow(); EventExecutor next(); @Override Iterator\u0026lt;EventExecutor\u0026gt; iterator(); @Override Future\u0026lt;?\u0026gt; submit(Runnable task); @Override \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Runnable task, T result); @Override \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task); @Override ScheduledFuture\u0026lt;?\u0026gt; schedule(Runnable command, long delay, TimeUnit unit); @Override \u0026lt;V\u0026gt; ScheduledFuture\u0026lt;V\u0026gt; schedule(Callable\u0026lt;V\u0026gt; callable, long delay, TimeUnit unit); @Override ScheduledFuture\u0026lt;?\u0026gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit); @Override ScheduledFuture\u0026lt;?\u0026gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit); } ScheduledExecutorService # 继承自 java.util.concurrent.ScheduledExecutorService 类。\nEventLoop 主要实现 # EventLoopGroup defaultGroup = new DefaultEventLoopGroup(); EventLoopGroup nioGroup = new NioEventLoopGroup(); # public abstract class SingleThreadEventExecutor extends AbstractScheduledEventExecutor implements OrderedEventExecutor { ... private void execute(Runnable task, boolean immediate) { boolean inEventLoop = inEventLoop(); addTask(task); if (!inEventLoop) { startThread(); if (isShutdown()) { boolean reject = false; try { if (removeTask(task)) { reject = true; } } catch (UnsupportedOperationException e) { // The task queue does not support removal so the best thing we can do is to just move on and // hope we will be able to pick-up the task before its completely terminated. // In worst case we will log on termination. } if (reject) { reject(); } } } if (!addTaskWakesUp \u0026amp;\u0026amp; immediate) { wakeup(inEventLoop); } } ... } 处理 I/O 事件 # "},{"id":8,"href":"/docs/Netty/EventLoopGroup/","title":"EventLoopGroup","section":"Netty","content":" EventLoopGroup # "},{"id":9,"href":"/docs/system-programming/block-and-nonblock-io/","title":"（非）阻塞 I/O","section":"Linux 网络编程","content":" （非）阻塞 I/O 和 epoll（翻译） # 原文：https://eklitzke.org/blocking-io-nonblocking-io-and-epoll\n在这篇文章中，我想解释使用非阻塞 I/O 时会发生什么。我特别想说明的是:\n使用 fcntl 函数设置文件描述符的 O_NONBLOCK 时的语义。 非阻塞（nonblocking） I/O 与异步（asynchronous） I/O 的区别。 为什么非阻塞 I/O 经常与诸如 select、epoll 和 kqueue 等 I/O 多路复用器一起使用。 非阻塞模式如何与 epoll 中的边缘触发轮询交互。 阻塞模式 # 默认情况下，Unix 系统所有的文件描述符都以“阻塞模式”启动。这意味着像 read、write 或 connect 这样的 I/O 系统调用可能会阻塞。一个很容易理解的方法是当你从一个普通的基于 TTY 的程序中的 stdin 读取数据时会发生什么。如果你在 stdin上调用 read，那么你的程序将会阻塞，直到数据实际上可用，比如当用户实际上在键盘上键入字符时。具体来说，内核会将进程置于“睡眠”状态，直到 stdin 上的数据可用。其他类型的文件描述符也是如此。例如，如果你尝试从 TCP 套接字中读取数据，那么 read 调用将会阻塞，直到连接的另一端实际上发送数据。\n阻塞对于应该并发运行的程序来说是一个问题，因为被阻塞的进程会被挂起。解决这个问题有两种不同但互补的方式：\n非阻塞模式。 I/O 多路复用系统调用，例如 select 和 epoll。 这两种解决方案经常一起使用，但它们是解决这个问题的独立策略，通常两者都会被使用。接下来我们将会看到它们之间的区别以及为什么它们通常都会被同时使用。\n非阻塞模式 # 通过 fcntl 函数在文件描述符的标志集中添加 O_NONBLOCK，可以将文件描述符设置为“非阻塞模式”：\n/* set O_NONBLOCK on fd */ int flags = fcntl(fd, F_GETFL, 0); fcntl(fd, F_SETFL, flags | O_NONBLOCK); 从这一点开始，文件描述符被视为非阻塞的。当发生这种情况时，像 read 和 write 这样的 I/O 系统调用将返回 -1，并且 errno 将被设置为 EWOULDBLOCK。\n这很有趣，但单独使用实际上并不是那么有用。仅仅使用这种基本方法是没有有效方式同时在多个文件描述符上进行 I/O 的。例如，假设我们有两个文件描述符，并希望同时读取它们。这可以通过循环检查每个文件描述符是否有数据，然后在再次检查之前短暂休眠来实现：\nstruct timespec sleep_interval{.tv_sec = 0, .tv_nsec = 1000}; ssize_t nbytes; for (;;) { /* try fd1 */ if ((nbytes = read(fd1, buf, sizeof(buf))) \u0026lt; 0) { if (errno != EWOULDBLOCK) { perror(\u0026#34;read/fd1\u0026#34;); } } else { handle_data(buf, nbytes); } /* try fd2 */ if ((nbytes = read(fd2, buf, sizeof(buf))) \u0026lt; 0) { if (errno != EWOULDBLOCK) { perror(\u0026#34;read/fd2\u0026#34;); } } else { handle_data(buf, nbytes); } /* sleep for a bit; real version needs error checking! */ nanosleep(sleep_interval, NULL); } 这种方法确实有效，但存在很多缺点：\n当数据传入速度很慢时，程序会频繁而不必要地唤醒，这会浪费 CPU 资源。 当数据到达时，如果程序正在睡眠，可能不会立即读取数据，因此程序的延迟会很高。 使用这种模式处理大量文件描述符会变得繁琐。 为了解决这些问题，我们需要 I/O 多路复用。\nI/O 多路复用（select, epoll, kqueue） # 有几种I/O多路复用系统调用。例如，POSIX 定义的 select，Linux 上的 epoll 系列，以及 BSD 上的 kqueue 系列都是 I/O 多路复用的例子。它们在基本原理上都是相同的：它们让内核知道一组文件描述符上感兴趣的事件（通常是读事件和写事件），然后它们会阻塞，直到发生感兴趣的事件。例如，你可以告诉内核你只对文件描述符 X 上的读事件感兴趣，对文件描述符 Y 上的读和写事件都感兴趣，以及对文件描述符 Z 上的写事件感兴趣。\n这些 I/O 多路复用系统调用通常不关心文件描述符是处于阻塞模式还是非阻塞模式。你可以将所有的文件描述符都保留在阻塞模式下，它们仍然可以与 select 或 epoll 一起正常工作。如果你只对 select 或 epoll 返回的文件描述符调用 read 和 write，那么即使这些文件描述符处于阻塞模式，这些调用也不会阻塞。但有一个重要的例外，文件描述符的阻塞或非阻塞状态对于边缘触发轮询是重要的，下面会进一步解释。\n并发的多路复用方法是我所谓的“异步 I/O”。有时人们也会将这种方法称为“非阻塞 I/O”，我认为这是对系统编程层面中“非阻塞”含义的混淆。我建议将术语“非阻塞”保留用于指代文件描述符是否实际处于非阻塞模式。\nO_NONBLOCK 与 I/O 多路复用的交互方式 # 假设我们正在使用带有阻塞文件描述符的 select 编写一个简单的套接字服务器。为简单起见，在此示例中，我们只有要从中读取的文件描述符，这些文件描述符存储在 read_fds 中。事件循环的核心部分将调用 select，然后针对每个具有数据的文件描述符调用一次 read：\nssize_t nbytes; for (;;) { /* select call happens here */ if (select(FD_SETSIZE, \u0026amp;read_fds, NULL, NULL, NULL) \u0026lt; 0) { perror(\u0026#34;select\u0026#34;); exit(EXIT_FAILURE); } for (int i = 0; i \u0026lt; FD_SETSIZE; i++) { if (FD_ISSET(i, \u0026amp;read_fds)) { /* read call happens here */ if ((nbytes = read(i, buf, sizeof(buf))) \u0026gt;= 0) { handle_read(nbytes, buf); } else { /* real version needs to handle EINTR correctly */ perror(\u0026#34;read\u0026#34;); exit(EXIT_FAILURE); } } } } 这样做是有效的，而且完全没问题。但是，如果 buf 很小，而且有大量数据同时传输会发生什么？具体来说，假设 buf 是一个 1024 字节的缓冲区，但一次传输了 64KB 的数据。为了处理这个请求，我们将调用 select，然后调用 64 次 read。总共需要 128 次系统调用，这是相当多的。\n如果缓冲区大小太小，就必须调用很多次 read，这是无法避免的。但也许我们可以减少调用 select 的次数？在这个例子中，理想情况下我们只会调用一次 select。\n事实上，这是可能的，而且可以通过将文件描述符设置为非阻塞模式来实现。基本思想是你可以在一个循环中不断调用 read，直到它返回 EWOULDBLOCK 为止。实现如下所示：\nssize_t nbytes; for (;;) { /* select call happens here */ if (select(FD_SETSIZE, \u0026amp;read_fds, NULL, NULL, NULL) \u0026lt; 0) { perror(\u0026#34;select\u0026#34;); exit(EXIT_FAILURE); } for (int i = 0; i \u0026lt; FD_SETSIZE; i++) { if (FD_ISSET(i, \u0026amp;read_fds)) { /* NEW: loop until EWOULDBLOCK is encountered */ for (;;) { /* read call happens here */ nbytes = read(i, buf, sizeof(buf)); if (nbytes \u0026gt;= 0) { handle_read(nbytes, buf); } else { if (errno != EWOULDBLOCK) { /* real version needs to handle EINTR correctly */ perror(\u0026#34;read\u0026#34;); exit(EXIT_FAILURE); } break; } } } } } 在这个例子中（1024 字节缓冲区，传入 64KB 的数据），我们将进行 66 次系统调用：select 将被调用一次，read 将被调用 64 次而不会出错，read 将被调用并返回 EWOULDBLOCK 一次。这要比之前的例子好得多！这几乎是前一个例子的一半，这将显著提高性能和可伸缩性。\n这种方法的缺点是由于新的循环，至少会有一次额外的 read 调用，因为它被调用直到返回 EWOULDBLOCK。假设通常情况下读取缓冲区足够大，可以在一个 read 调用中读取所有传入的数据。那么在循环中，通常情况下会有三次系统调用而不是只有两次：select 等待数据，read 实际读取数据，然后再次调用 read 以获取 EWOULDBLOCK。\n边缘触发轮询（Edge-Triggered Polling） # 边缘触发轮询是非阻塞 I/O 的另一个重要用途，特别是在 epoll 系统调用中。这个系统调用有两种模式：水平触发和边缘触发。水平触发是一种更简单的编程模型，类似于经典的 select 系统调用。为了解释它们之间的区别，我们需要了解 epoll 在内核中的工作方式。\n假设你告诉内核你有兴趣使用 epoll 来监视某个文件描述符上的读事件。内核为每个文件描述符维护这些兴趣的列表。当数据到达文件描述符时，内核遍历兴趣列表，并唤醒每个在 epoll_wait 中被阻塞的进程，其中包含了该文件描述符在事件列表中。\n上述内容无论 epoll 处于哪种触发模式都会发生。水平触发和边缘触发轮询的区别在于调用 epoll_wait 时内核的行为。在水平触发模式中，内核将遍历兴趣列表中的每个文件描述符，以查看它是否已满足兴趣条件。例如，如果你在文件描述符 8 上注册了一个读事件，调用 epoll_wait 时内核将首先检查：文件描述符 8 是否已经有数据准备好读取？如果任何文件描述符匹配兴趣条件，则 epoll_wait 可以立即返回而不阻塞。\n相比之下，在边缘触发模式中，内核跳过这个检查，并在调用 epoll_wait 时立即将进程置于睡眠状态。这使得程序员必须完全负责，需要完全读取和写入每个文件描述符的所有数据，然后才能等待。\n边缘触发模式使得 epoll 成为时间复杂度为 O(1) 的 I/O 多路复用器：epoll_wait 调用会立即挂起，由于事先为每个文件描述符维护了一个列表，当新数据到达时，内核会在 O(1) 时间知道必须要唤醒的进程。\n以下是边缘触发和水平触发模式之间差异的更详细示例。假设你的读取缓冲区是 100 字节，而文件描述符上传入了 200 字节的数据。然后假设你只调用了一次 read，然后再次调用了 epoll_wait。仍然有 100 字节的数据准备好读取。在水平触发模式中，内核会注意到这一点，并通知进程应该再次调用 read。相比之下，在边缘触发模式中，内核将立即进入睡眠状态。如果另一侧正在期待响应（例如，发送的数据是某种 RPC），那么两侧将会“死锁”，因为服务器将等待客户端发送更多数据，但客户端将等待服务器发送响应。\n要使用边缘触发轮询，你必须将文件描述符设置为非阻塞模式。然后你必须每次调用 read 或 write 直到它们返回 EWOULDBLOCK 为止。如果你未能满足这些条件，你将错过内核的通知。但这样做有一个很大的好处：每次调用 epoll_wait 都会更有效率，这对于具有极高并发性的程序来说非常重要。如果你想了解更多细节，我强烈建议你阅读 epoll(7) 手册页。\n"},{"id":10,"href":"/docs/Netty/Channel/","title":"Channel","section":"Netty","content":" Channel # "},{"id":11,"href":"/docs/system-programming/multiplexing/","title":"I/O 多路复用","section":"Linux 网络编程","content":" I/O 多路复用 # I/O 复用可以使程序同时监听多个文件描述符。\nselect # select 函数允许程序监视多个文件描述符，直到一个或多个文件描述符“准备好”进行某类 I/O 操作。\nselect 成功时返回就绪文件描述符的总数，如果超时时间内没有任何文件描述符就绪，则返回 0。失败时返回 -1 并设置 errno。\n#include \u0026lt;sys/select.h\u0026gt; int select(int nfds, fd_set* readfds, fd_set* writefds, fd_set* exceptfds, struct timeval * timeout); 函数参数 # nfds：指定被监听的文件描述符的总数。这个参数应该被设置为三个集合中编号最高的文件描述符，再加 1，因为文件描述符是从 0 开始的。\nreadfds、writefds 和 exceptfds：分别指向可读、可写和异常事件对应的文件描述符集合。如果没有文件描述符要监听，则可以将对应的 fd_set 参数设为 NULL。\nfd_set 结构体仅包含一个数组，数组每一位标记一个文件描述符，最大容纳长度由 FD_SETSIZE 指定。\n/* fd_set for select and pselect. */ typedef struct { /* XPG4.2 requires this member name. Otherwise avoid the name from the global namespace. */ #ifdef __USE_XOPEN __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;fds_bits) #else __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;__fds_bits) #endif } fd_set; 为方便对此结构体进行操作，提供了以下几个宏函数对其进行操作，宏函数如下：\n为方便展示，对宏函数中的所有参数加上了类型\nFD_SET(fd, fdsetp)：将文件描述符 fd 添加到 fdset 指向的集合中。 FD_CLR(fd, fdsetp)：将文件描述符 fd 从 fdset 指向的集合中移除。 FD_ISSET(fd, fdsetp)：如果文件描述符 fd 是 fdset 指向的集合中的成员，则返回 true。 FD_ZERO(fdsetp)：将 fdset 指向的集合初始化为空。 timeval：用来设置 select 函数的超时时间，采用指针作为参数是因为内核将修改以告诉应用程序 select 等待了多久。\n如果 timeval 结构体中的 tv_sec 和 tv_usec 成员都传递 0，则 select 函数立即返回。如果传递 NULL，则一直阻塞，直到某个文件描述符就绪。\n/* A time value that is accurate to the nearest microsecond but also has a range of years. */ struct timeval { #ifdef __USE_TIME_BITS64 __time64_t tv_sec;\t/* Seconds. */ __suseconds64_t tv_usec;\t/* Microseconds. */ #else __time_t tv_sec;\t/* Seconds. */ __suseconds_t tv_usec;\t/* Microseconds. */ #endif }; 就绪条件 # 在网络编程中，下边情况下 socket 可读：\n在网络编程中，下边情况下 socket 可写：\nselect 函数能处理的异常情况只有一种：socket 上接收到带外数据。\n循环中使用 # 由于这些结构体会在调用中被修改，如果要在循环中重复调用 select 函数，我们必须保证每次都要重新初始化它们。\npoll # poll 函数和 select 函数调用返回值一致。\n#include \u0026lt;poll.h\u0026gt; int poll(struct pollfd *fds, nfds_t nfds, int timeout); 函数参数 # fds：需要 poll 函数检查的文件描述符，该参数为 pollfd 结构体数组。\npollfd 结构体中 fd 指定文件描述符；events 告诉 poll 函数需要监听哪些事件；revents 由内核对其进行修改，以通知应用程序 fd 上实际发生了哪些事件。\n位掩码 events 返回到revents 描述 POLLIN ● ● 可读取非高优先级的数据 POLLRDNORM ● ● 等同于POLLIN POLLRDBAND ● ● 可读取优先级数据（Linux 中不使用） POLLPRI ● ● 可读取高优先级数据 POLLRDHUP ● ● 对端套接字关闭 POLLOUT ● ● 普通数据可写 POLLWRNORM ● ● 等同于POLLOUT POLLWRBAND ● ● 优先级数据可写入 POLLERR ● 有错误发生 POLLHUP ● 出现挂断 POLLNVAL ● 文件描述符未打开 POLLMSG Linux 中不使用 struct pollfd { int fd; /* file descriptor */ short events; /* requested events */ short revents; /* returned events */ }; nfds：用于指定数组 fds 中元素的个数。\n/* Type used for the number of file descriptors. */ typedef unsigned long int nfds_t; timeout：指定 poll 的超时值，单位为毫秒。\n当 timeout 为 -1 时，poll 调用将一直阻塞，直到某个事件发生； 当 timeout 为 0 时，poll 调用将立即返回。 epoll # epoll 是 Linux 特有的 I/O 复用函数。epoll 需要使用额外的文件描述符，标识内核中的这个事件表，需要使用 epoll_create 函数创建，返回文件描述符。\nsize 是想要通过 epoll 来检查的文件描述符个数。该参数并不是一个上限，而是告诉内核应该如何为内部数据结构划分初始大小（从 Linux 2.6.8 版以来，size 参数被忽略不用，因为内核实现做了修改意味着该参数提供的信息已经不再需要了）。\n#include \u0026lt;sys/epoll.h\u0026gt; int epoll_create (int size); int epoll_create1 (int flags); epoll_ctl # epoll_ctl 函数能够修改由文件描述符 epfd 所代表的兴趣列表。\nint epoll_ctl (int epfd, int op, int fd, struct epoll_event *event); epfd 是调用 epoll_create 函数的返回值。\nop 用于操作操作类型。\n/* Valid opcodes ( \u0026#34;op\u0026#34; parameter ) to issue to epoll_ctl(). */ #define EPOLL_CTL_ADD 1\t/* Add a file descriptor to the interface. */ #define EPOLL_CTL_DEL 2\t/* Remove a file descriptor from the interface. */ #define EPOLL_CTL_MOD 3\t/* Change file descriptor epoll_event structure. */ events 是一个位掩码，指定了待检查描述符 fd 上感兴趣的事件集合。\nstruct epoll_event { uint32_t events;\t/* Epoll events */ epoll_data_t data; /* User data variable */ } data 当描述符 fd 就绪时，传递给调用者的信息。\ntypedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t; epoll_wait # 返回 epoll 实例中处于就绪态的文件描述符信息。单个 epoll_wait 函数调用能返回多个就绪态文件描述符的信息。\n调用成功后，epoll_wait 函数返回数组 events 元素个数。\nint epoll_wait (int epfd, struct epoll_event *events, int maxevents, int timeout); events 所指向的结构体数组中返回的是有关就绪态文件描述符的信息。\n数组 events 的空间由调用者负责申请，所包含的元素个数由参数 maxevents 指定。\ntimeout：指定 epoll 的超时值，单位为毫秒。\n当 timeout 为 -1 时，epoll 调用将一直阻塞，直到某个事件发生； 当 timeout 为 0 时，epoll 执行一次非阻塞式的检查，看兴趣列表中的文件描述符上产生了哪个事件。 当 timeout 大于 0 时，epoll 阻塞至多 timeout 毫秒，直到文件描述符上有事件发生，或者直到捕获到一个信号为止。 水平触发和边缘触发 # epoll 默认工作模式为水平触发，当往 epoll 内核事件表中注册一个文件描述符上的 EPOLLET 事件时，将以边缘触发模式工作。\nLT 模式（水平）：缓冲区剩余未读尽的数据会导致 epoll_wait 返回。直到新的事件满足才会触发。支持阻塞和非阻塞。\nET 模式（边缘）：缓冲区剩余未读尽的数据不会导致 epoll_wait 返回。必须设置为非阻塞。\n"},{"id":12,"href":"/docs/Netty/ChannelHandler/","title":"ChannelHandler","section":"Netty","content":" ChannelHandler # ChannelHandler 共分为两类，ChannelInboundHandler 和 ChannelOutboundHandler。\nChannelInboundHandler： ChannelOutboundHandler： 常用 # ChannelHandlerAdapter ChannelInboundHandlerAdapter ChannelOutboundHandlerAdapter ChannelDuplexHandler Pipeline 执行顺序 # Inbound 是从 ChannelPipeline 头到尾部，Outbound 是从 ChannelPipeline 尾到头部。\n生命周期 # handlerAdded new ChannelHandler() { @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception { } @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception { } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { } } ChannelInboundHandler # ChannelInboundHandlerAdapter # ChannelInboundHandlerAdapter 中的所有方法默认会调用 ctx.fireChannel*() 传递到下一个 Handler。\nChannelInboundHandlerAdapter 不会释放 ByteBuf。\nChannelOutboundHandler # 编码器和解码器 # "},{"id":13,"href":"/docs/system-programming/reactor-pattern/","title":"Reactor 模型","section":"Linux 网络编程","content":" Reactor 模型 # Reactor 模型中定义的三种角色：\nReactor：负责监听和分配事件，将I/O事件分派给对应的 Handler。新的事件包含连接建立就绪、读就绪、写就绪等。 Acceptor：处理客户端新连接，并分派请求到处理器链中。 Handler：将自身与事件绑定，执行非阻塞读/写任务，完成channel的读入，完成处理业务逻辑后，负责将结果写出channel。可用资源池来管理。 One Loop Per Thread # 参考文献 # https://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf https://gee.cs.oswego.edu/dl/cpjslides/nio.pdf "},{"id":14,"href":"/docs/system-programming/sockets/","title":"套接字（socket）","section":"Linux 网络编程","content":" 套接字（socket） # 网络编程即编写程序使两台联网的计算机相互交换数据。计算机之间会通过网线、路由器和交换机等设备连接在一起，我们无需直接操控硬件，而使用操作系统提供的套接字（socket）。\n基本函数 # socket # 为了使用套接字，可以使用 socket 函数，创建用于通信的端点（endpoint）。\n#include \u0026lt;sys/socket.h\u0026gt; int socket(int domain, int type, int protocol); 成功时会返回文件描述符，失败时会返回 -1。\nhttps://man7.org/linux/man-pages/man2/socket.2.html\nbind # 当使用 socket 函数创建套接字后，会存在于名称空间（地址族）中，但没有为其分配地址。bind 函数将 addr 指定的地址分配给文件描述符 sockfd 引用的套接字。\n服务器可以不先调用 bind() 而直接调用 listen()，此时会为该 socket 分配一个 INADDR_ANY IP 地址（0.0.0.0）和临时端口（可通过 getsockname() 获取 socket 的地址）。\n#include \u0026lt;sys/socket.h\u0026gt; int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 成功时返回 0，失败时返回 -1。\nhttps://man7.org/linux/man-pages/man2/bind.2.html\nlisten # listen 函数将文件描述符引用的 socket 标记为被动，该 socket 会被用来接受来自其它主动 socket 的连接。\n#include \u0026lt;sys/socket.h\u0026gt; int listen(int sockfd, int backlog); 成功时返回 0，失败时返回 -1。\nhttps://man7.org/linux/man-pages/man2/listen.2.html\naccept # 执行 accept 函数会创建一个新的 socket，此 socket 会与执行 connect 函数的 socket 进行连接。此函数调用返回值是已连接的 socket 的文件描述符。\n#include \u0026lt;sys/socket.h\u0026gt; int accept(int sockfd, struct sockaddr *_Nullable restrict addr, socklen_t *_Nullable restrict addrlen); 成功时会返回文件描述符，失败时会返回 -1。\nhttps://man7.org/linux/man-pages/man2/accept.2.html\nconnect # connect 函数将文件描述符 sockfd 引用的套接字连接到由 addr 指定的地址。\n#include \u0026lt;sys/socket.h\u0026gt; int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); https://man7.org/linux/man-pages/man2/connect.2.html\n套接字协议 # socket 函数（int socket(int domain, int type, int protocol)）有三个参数用于选择传输协议和方式。\n协议族（domain） # 所有的协议族可以点击 address_families 查看，主要的协议族分类如下：\n协议族 描述 AF_INET 使用 IPv4 地址 AF_INET6 使用 IPv6 地址 AF_UNIX 本地通信，用于同一台机器上的进程间通信 AF_PACKET 原始数据包捕获和注入，需要特殊权限 AF_NETLINK 用于 Linux 内核与用户空间进程之间的通信 AF_常量 和 PF_常量 的区别？\nAF 表示地址族（address family），PF 表示协议族（protocol family）。在一开始的时候，设计人员相信单个协议族可以支持多个地址族。但在实践中，没有哪一个协议族能够支持多个已经被定义的地址族，并且所有既有实现都将 PF_常量 定义成对应的 AF_常量 的同义词。\n数据传输方式（type） # 数据传输类型主要有以下两种：\n面向连接的套接字（SOCK_STREAM）：提供有序的、可靠的、双向的、基于连接的字节流。可以支持带外（ out-of-band）数据传输机制。 面向消息的套接字（SOCK_DGRAM）：支持数据报（无连接、最大长度固定的不可靠消息）。 协议（protocol） # 在给定的协议族中，通常只有一个协议存在以支持特定的套接字类型，在这种情况下，可以将 protocol 指定为 0。\n在大部分情况下，第三个参数传递 0 即可。然而，协议族下可能存在许多协议，在这种情况下，必须使用 protocol 指定一个特定的协议。\n"},{"id":15,"href":"/docs/system-programming/echo-server/","title":"echo 服务器","section":"Linux 网络编程","content":" echo 服务器 # 辅助函数 # panic 函数用于错误处理，当发生错误时，调用 exit 函数直接退出程序。\nvoid panic(const char *format, ...) { va_list args; va_start(args, format); vfprintf(stderr, format, args); va_end(args); exit(EXIT_FAILURE); } readn 和 writen 函数分别用于从 fd 处读和写 n 个字节。\nssize_t readn(int fd, const void *buf, size_t n) { ssize_t nread; while (nleft \u0026gt; 0) { if ((nread = read(fd, buf, nleft)) \u0026lt; 0) { if (nleft == n) { return -1; // error, return -1 } else { break; // error, return amount read so far } while (nleft \u0026gt; 0) { if ((nread = read(fd, buf, nleft)) \u0026lt; 0) { if (nleft == n) { return -1; // error, return -1 } else { } nleft -= nread; buf += nread; } return n - nleft; } ssize_t writen(int fd, const void *buf, size_t n) { size_t nleft = n; ssize_t nwritten; while (nleft \u0026gt; 0) { if ((nwritten = write(fd, buf, nleft)) \u0026lt; 0) { if (nleft == n) { return -1; } else { break; } } else if (nwritten == 0) { break; } nleft -= nwritten; buf += nwritten; } return n - nleft; } read_line 函数用于从用户处读取一行输入。\nchar *read_line() { char *line = NULL; size_t buf_size = 0; ssize_t n_bytes = getline(\u0026amp;line, \u0026amp;buf_size, stdin); if (n_bytes == -1) { fprintf(stderr, \u0026#34;error: reading input\\n\u0026#34;); } if (line[n_bytes - 1] == \u0026#39;\\n\u0026#39;) { line[n_bytes - 1] = \u0026#39;\\0\u0026#39;; } return line; } set_nonblocking 函数用于将 fd 设为非阻塞模式。\nint set_nonblocking(int fd) { int flags = fcntl(fd, F_GETFL, 0); if (flags == -1 || fcntl(fd, F_SETFL, flags | O_NONBLOCK) == -1) { return -1; } return 0; } create_sockaddr_in 函数用于创建 struct sockaddr_in 结构体。\nstruct sockaddr_in *create_sockaddr_in(const char *address, int port) { struct sockaddr_in *addr = malloc(sizeof(struct sockaddr_in)); addr-\u0026gt;sin_family = AF_INET; addr-\u0026gt;sin_addr.s_addr = inet_addr(address); addr-\u0026gt;sin_port = htons(port); return addr; } 对于 socket、bind、listen、accept 和 connect 函数，大部分使用都是一样的，对其进行封装。\nint Socket() { int fd = socket(AF_INET, SOCK_STREAM, 0); if (fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } return fd; } void Bind(int socket_fd, struct sockaddr_in *addr) { int ret = bind(socket_fd, (struct sockaddr *)(addr), sizeof(*addr)); if (ret == -1) { panic(\u0026#34;bind() error: %s\\n\u0026#34;, strerror(errno)); } } void Listen(int socket_fd) { int ret = listen(socket_fd, 16); if (ret == -1) { panic(\u0026#34;listen() error: %s\\n\u0026#34;, strerror(errno)); } } int Accept(int socket_fd, struct sockaddr_in *addr, socklen_t *addr_len) { int fd = accept(socket_fd, (struct sockaddr *)addr, addr_len); if (fd == -1) { panic(\u0026#34;accept() error: %s\\n\u0026#34;, strerror(errno)); } int ret = set_nonblocking(fd); if (ret == -1) { panic(\u0026#34;set_nonblocking error\\n\u0026#34;); } return fd; } void Connect(int socket_fd, struct sockaddr_in *addr) { int ret = connect(socket_fd, (struct sockaddr *)(addr), sizeof(*addr)); if (ret == -1) { panic(\u0026#34;connect() error: %s\\n\u0026#34;, strerror(errno)); } } 客户端 # 客户端读取一行用户的输入，将数据传给服务器，服务器将所有的字母大写后再传给客户端。\nvoid run_client(const char *remote_address, int remote_port) { int client_fd = Socket(); struct sockaddr_in *server_addr = create_sockaddr_in(remote_address, remote_port); Connect(client_fd, server_addr); for (;;) { char *input = read_line(); size_t input_len = strlen(input); char buf[input_len + 1]; if (input_len == 0) { goto out; } ssize_t sent_bytes = send(client_fd, input, input_len, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } ssize_t recv_bytes = recv(client_fd, buf, input_len, 0); if (recv_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } printf(\u0026#34;%s\\n\u0026#34;, buf); out: free(input); } } 为什么多路复用需要搭配非阻塞 # On Linux, select() may report a socket file descriptor as \u0026#34;ready for reading\u0026#34;, while nevertheless a subsequent read blocks. This could for example happen when data has arrived but upon examination has the wrong checksum and is discarded. There may be other circumstances in which a file descriptor is spuriously reported as ready. Thus it may be safer to use O_NONBLOCK on sockets that should not block. 参考链接： select\n普通版本 # #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; int used_for_cleanup_fd = -1; void panic(const char *format, ...) { va_list args; va_start(args, format); vfprintf(stderr, format, args); va_end(args); exit(EXIT_FAILURE); } void cleanup() { if (used_for_cleanup_fd != -1) close(used_for_cleanup_fd); } void run_client(const char *remote_address, int remote_port) { int ret; char buf[512]; int client_fd = socket(AF_INET, SOCK_STREAM, 0); if (client_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = client_fd; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(remote_address); server_addr.sin_port = htons(remote_port); ret = connect(client_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;connect() error: %s\\n\u0026#34;, strerror(errno)); } for (;;) { fgets(buf, sizeof(buf), stdin); buf[strcspn(buf, \u0026#34;\\n\u0026#34;)] = \u0026#39;\\0\u0026#39;; size_t buf_len = strlen(buf); if (buf_len == 0) { continue; } if (buf_len \u0026gt;= sizeof(buf) - 1) { panic(\u0026#34;input too long\\n\u0026#34;); } ssize_t sent_bytes = send(client_fd, buf, buf_len, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } ssize_t recv_bytes = recv(client_fd, buf, sizeof(buf), 0); if (recv_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } printf(\u0026#34;%s\\n\u0026#34;, buf); } } void run_server(const char *address, int port) { int ret; char buf[512]; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(address); server_addr.sin_port = htons(port); int server_fd = socket(AF_INET, SOCK_STREAM, 0); if (server_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = server_fd; ret = bind(server_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;bind() error: %s\\n\u0026#34;, strerror(errno)); } ret = listen(server_fd, 16); if (ret == -1) { panic(\u0026#34;listen() error: %s\\n\u0026#34;, strerror(errno)); } struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); for (;;) { int client_fd = accept(server_fd, (struct sockaddr *)(\u0026amp;client_addr), \u0026amp;client_addr_len); if (client_fd == -1) { panic(\u0026#34;accept() error: %s\\n\u0026#34;, strerror(errno)); } for (;;) { ssize_t read_bytes = recv(client_fd, buf, sizeof(buf), 0); if (read_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } if (read_bytes == 0) { close(client_fd); break; } for (ssize_t i = 0; i \u0026lt; read_bytes; i++) { buf[i] = (char)toupper((unsigned char)buf[i]); } ssize_t sent_bytes = send(client_fd, buf, read_bytes, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } } } } int main(int argc, char *argv[]) { if (argc \u0026lt; 4) { panic(\u0026#34;usage: \u0026lt;mode\u0026gt; \u0026lt;IP\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); } char *mode = argv[1]; char *address = argv[2]; int port = atoi(argv[3]); if (strncmp(mode, \u0026#34;client\u0026#34;, 6) == 0) run_client(address, port); if (strncmp(mode, \u0026#34;server\u0026#34;, 6) == 0) run_server(address, port); return 0; } select 版本 # #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;sys/select.h\u0026gt; #define MAX(a, b) a \u0026lt; b ? b : a int used_for_cleanup_fd = -1; void panic(const char *format, ...) { va_list args; va_start(args, format); vfprintf(stderr, format, args); va_end(args); exit(EXIT_FAILURE); } void cleanup() { if (used_for_cleanup_fd != -1) close(used_for_cleanup_fd); } void run_client(const char *remote_address, int remote_port) { int ret; char buf[512]; int client_fd = socket(AF_INET, SOCK_STREAM, 0); if (client_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = client_fd; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(remote_address); server_addr.sin_port = htons(remote_port); ret = connect(client_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;connect() error: %s\\n\u0026#34;, strerror(errno)); } for (;;) { fgets(buf, sizeof(buf), stdin); buf[strcspn(buf, \u0026#34;\\n\u0026#34;)] = \u0026#39;\\0\u0026#39;; size_t buf_len = strlen(buf); if (buf_len == 0) { continue; } if (buf_len \u0026gt;= sizeof(buf) - 1) { panic(\u0026#34;input too long\\n\u0026#34;); } ssize_t sent_bytes = send(client_fd, buf, buf_len, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } ssize_t recv_bytes = recv(client_fd, buf, sizeof(buf), 0); if (recv_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } printf(\u0026#34;%s\\n\u0026#34;, buf); } } void run_server(const char *address, int port) { int ret; char buf[512]; struct sockaddr_in server_addr; server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = inet_addr(address); server_addr.sin_port = htons(port); int server_fd = socket(AF_INET, SOCK_STREAM, 0); if (server_fd == -1) { panic(\u0026#34;socket() error: %s\\n\u0026#34;, strerror(errno)); } atexit(cleanup); used_for_cleanup_fd = server_fd; ret = bind(server_fd, (struct sockaddr *)(\u0026amp;server_addr), sizeof(server_addr)); if (ret == -1) { panic(\u0026#34;bind() error: %s\\n\u0026#34;, strerror(errno)); } ret = listen(server_fd, 16); if (ret == -1) { panic(\u0026#34;listen() error: %s\\n\u0026#34;, strerror(errno)); } struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); fd_set fds; FD_ZERO(\u0026amp;fds); FD_SET(server_fd, \u0026amp;fds); int max_fd = server_fd; for (;;) { fd_set rfds = fds; int retval = select(max_fd + 1, \u0026amp;rfds, NULL, NULL, NULL); if (retval == -1) { panic(\u0026#34;select() error: %s\\n\u0026#34;, strerror(errno)); } if (FD_ISSET(server_fd, \u0026amp;rfds)) { // new connection int client_fd = accept(server_fd, (struct sockaddr *)(\u0026amp;client_addr), \u0026amp;client_addr_len); if (client_fd == -1) { panic(\u0026#34;accept() error: %s\\n\u0026#34;, strerror(errno)); } FD_SET(client_fd, \u0026amp;fds); max_fd = MAX(max_fd, client_fd); if (retval == 1) continue; } for (int fd = server_fd + 1; fd \u0026lt;= max_fd; fd++) { if (FD_ISSET(fd, \u0026amp;rfds)) { ssize_t read_bytes = recv(fd, buf, sizeof(buf), 0); if (read_bytes == -1) { panic(\u0026#34;recv() error: %s\\n\u0026#34;, strerror(errno)); } if (read_bytes == 0) { FD_CLR(fd, \u0026amp;fds); close(fd); break; } for (ssize_t i = 0; i \u0026lt; read_bytes; i++) { buf[i] = (char)toupper((unsigned char)buf[i]); } ssize_t sent_bytes = send(fd, buf, read_bytes, 0); if (sent_bytes == -1) { panic(\u0026#34;send() error: %s\\n\u0026#34;, strerror(errno)); } } } } } int main(int argc, char *argv[]) { if (argc \u0026lt; 4) { panic(\u0026#34;usage: \u0026lt;mode\u0026gt; \u0026lt;IP\u0026gt; \u0026lt;port\u0026gt;\\n\u0026#34;); } char *mode = argv[1]; char *address = argv[2]; int port = atoi(argv[3]); if (strncmp(mode, \u0026#34;client\u0026#34;, 6) == 0) run_client(address, port); if (strncmp(mode, \u0026#34;server\u0026#34;, 6) == 0) run_server(address, port); return 0; } "},{"id":16,"href":"/docs/Java/Agent/","title":"Agent","section":"Java","content":" https://www.cnblogs.com/crazymakercircle/p/16635330.html\nhttps://docs.oracle.com/javase/8/docs/platform/jvmti/jvmti.html#whatIs\n"},{"id":17,"href":"/docs/JVM/AsmTools/","title":"AsmTools","section":"JVM","content":" AsmTools # AsmTools 官网： AsmTools\n编译 AsmTools # GitHub: AsmTools\nHow To Build AsmTools\n使用 # java -jar asmtools.jar jdis [option] [filename.class]\n参数 -g 可打印出更详细的信息。 "},{"id":18,"href":"/docs/Java/Cleaner/","title":"Cleaner 类","section":"Java","content":" 参考文献 # https://openjdk.org/jeps/421 https://inside.java/2022/05/25/clean-cleaner/ https://docs.oracle.com/javase/9/docs/api/java/lang/ref/Cleaner.html "},{"id":19,"href":"/docs/JVM/loading-linking-initializing/","title":"JVM 加载-链接-初始化","section":"JVM","content":" JVM 加载-链接-初始化 # 类加载过程 # 加载（loads） # 加载（loads）是查找具有特定名称的类或接口类型的二进制表示，并从该二进制表示创建类或接口的过程。加载过程如下：\n通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区（Method Area）的运行时数据结构。 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口。 类加载链接的目的就是在 JVM 中创建相应的类结构\n启动类加载器之外，其他的类加载器都是 java.lang.ClassLoader 的子类\n-verbose:class 参数可用于打印类加载的先后顺序\n链接（links） # 链接（links）是获取类或接口，并将其组合到 Java 虚拟机的运行时状态以便执行的过程。\n初始化（initializes） # 类或接口的初始化（initializes）包括执行类或接口初始化方法 \u0026lt;clinit\u0026gt;。\n类加载器（class loader） # 启动类加载器（bootstrap class loader）由 C++ 实现，\n除了启动类加载器之外，其它的类加载器都是 java.lang.ClassLoader 的子类，因此有对应的 Java 对象。这些类加载器需要先由另一个类加载器，比如说启动类加载器，加载至 Java 虚拟机中，方能执行类加载。\n双亲委派模型 # JDK 9 前 # 启动类加载器（Bootstrap Class Loader）：用于加载 扩展类加载器（Extension Class Loader）: 应用程序类加载器（Application Class Loader）: 可输出 BootstrapClassLoader 可加载的类。\nURLClassPath bootstrapClassPath = Launcher.getBootstrapClassPath(); for (URL url : bootstrapClassPath.getURLs()) { System.out.println(url.getFile()); } ${JAVA_HOME}/lib/resources.jar ${JAVA_HOME}/lib/rt.jar ${JAVA_HOME}/lib/sunrsasign.jar ${JAVA_HOME}/lib/jsse.jar ${JAVA_HOME}/lib/jce.jar ${JAVA_HOME}/lib/charsets.jar ${JAVA_HOME}/lib/jfr.jar ${JAVA_HOME}/classes JDK 9 后 # "},{"id":20,"href":"/docs/Java/DynamicProxy/","title":"动态代理","section":"Java","content":" 动态代理 # 在 Java 动态代理机制中，InvocationHandler 接口和 Proxy 类是核心。\nProxy # Proxy 类主要使用 newProxyInstance() 静态方法生成代理对象。\npublic static Object newProxyInstance(ClassLoader loader, Class\u0026lt;?\u0026gt;[] interfaces, InvocationHandler h) { ... } 该方法主要有三个参数：\nloader：定义代理类的类加载器。 interfaces：代理类要实现的接口列表。 h：用于分发方法调用的调用处理器。 InvocationHandler # 当动态代理对象调用一个方法时，此方法的调用就会被转发到实现 InvocationHandler 接口类的 invoke 方法来调用。\npublic interface InvocationHandler { public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; } 该方法主要有三个参数：\nproxy：动态生成的代理类的实例。 method：代理类对象调用的方法。 args：调用 method 方法的参数。 通过 Proxy 类的 newProxyInstance() 创建的代理对象在调用方法的时候，实际会调用到实现 InvocationHandler 接口的类的 invoke() 方法。\n具体步骤 # TargetClass 类继承自 InterfaceA 和 InterfaceB 接口。\n如果想在 targetA() 和 targetB() 方法调用前后进行一些额外操作。\ninterface InterfaceA { void targetA(); } interface InterfaceB { void targetB(); } class TargetClass implements InterfaceA, InterfaceB { @Override public void targetA() { System.out.println(\u0026#34;Target A\u0026#34;); } @Override public void targetB() { System.out.println(\u0026#34;Target B\u0026#34;); } } 在 InvocationHandler 中的 invoke 方法中定义额外的操作。\nclass SimpleInvocationHandler implements InvocationHandler { private final Object target; public SimpleInvocationHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.printf(\u0026#34;Before invocation method %s\\n\u0026#34;, method.getName()); Object result = method.invoke(target, args); System.out.printf(\u0026#34;After invocation method %s\\n\u0026#34;, method.getName()); return result; } } 通过 Proxy.newProxyInstance 方法生成代理对象。\npublic static void main(String[] args) { System.setProperty(\u0026#34;jdk.proxy.ProxyGenerator.saveGeneratedFiles\u0026#34;, \u0026#34;true\u0026#34;); TargetClass target = new TargetClass(); SimpleInvocationHandler handler = new SimpleInvocationHandler(target); Object o = Proxy.newProxyInstance( TargetClass.class.getClassLoader(), new Class[]{InterfaceA.class, InterfaceB.class}, handler ); ((InterfaceA) o).targetA(); ((InterfaceB) o).targetB(); } 原理 # 生成的类会继承自 Proxy 类，实现调用 newInstance() 方法时传入的 interfaces 中的所有接口。\n被代理的类中的所有方法会被收集为 Method 方法。当通过代理对象调用方法时，会转发到传入的 InvocationHandler 中。\n传入到 h.invoke 中的参数分别为：\nthis：被代理对象实例。 m*：调用的具体方法。 args：调用方法传入的参数。 // // Source code recreated from a .class file by IntelliJ IDEA // (powered by FernFlower decompiler) // import java.lang.invoke.MethodHandles; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; final class $Proxy0 extends Proxy implements InterfaceA, InterfaceB { private static final Method m0; private static final Method m1; private static final Method m2; private static final Method m3; private static final Method m4; public $Proxy0(InvocationHandler var1) { super(var1); } public final int hashCode() { try { return (Integer)super.h.invoke(this, m0, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final boolean equals(Object var1) { try { return (Boolean)super.h.invoke(this, m1, new Object[]{var1}); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetA() { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetB() { try { super.h.invoke(this, m4, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { ClassLoader var0 = $Proxy0.class.getClassLoader(); try { m0 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;hashCode\u0026#34;); m1 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;equals\u0026#34;, Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0)); m2 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;toString\u0026#34;); m3 = Class.forName(\u0026#34;io.github.ileonli.InterfaceA\u0026#34;, false, var0).getMethod(\u0026#34;targetA\u0026#34;); m4 = Class.forName(\u0026#34;io.github.ileonli.InterfaceB\u0026#34;, false, var0).getMethod(\u0026#34;targetB\u0026#34;); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } } private static MethodHandles.Lookup proxyClassLookup(MethodHandles.Lookup var0) throws IllegalAccessException { if (var0.lookupClass() == Proxy.class \u0026amp;\u0026amp; var0.hasFullPrivilegeAccess()) { return MethodHandles.lookup(); } else { throw new IllegalAccessException(var0.toString()); } } } 该代码主要依靠下边两个主要的方法和类：\njava.lang.reflect.Proxy.ProxyBuilder#defineProxyClass\njava.lang.reflect.ProxyGenerator\nProxy 的缺点 # JDK 动态代理有一个最致命的问题是其只能代理实现了接口的类。\n我们对代码进行一些修改，TargetClass 继承了 SuperClass 类。\ninterface InterfaceA { void targetA(); } interface InterfaceB { void targetB(); } abstract class SuperClass { abstract void superClassFunc(); } class TargetClass extends SuperClass implements InterfaceA, InterfaceB { @Override public void targetA() { System.out.println(\u0026#34;Target A\u0026#34;); } @Override public void targetB() { System.out.println(\u0026#34;Target B\u0026#34;); } @Override void superClassFunc() { System.out.println(\u0026#34;Super Class Func\u0026#34;); } } class SimpleInvocationHandler implements InvocationHandler { private final Object target; public SimpleInvocationHandler(Object target) { this.target = target; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.printf(\u0026#34;Before invocation method %s\\n\u0026#34;, method.getName()); Object result = method.invoke(target, args); System.out.printf(\u0026#34;After invocation method %s\\n\u0026#34;, method.getName()); return result; } } 反编译生成的代码后发现此类只包含实现的接口中的方法。\nimport java.lang.invoke.MethodHandles; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; final class $Proxy0 extends Proxy implements InterfaceA, InterfaceB { private static final Method m0; private static final Method m1; private static final Method m2; private static final Method m3; private static final Method m4; public $Proxy0(InvocationHandler var1) { super(var1); } public final int hashCode() { try { return (Integer)super.h.invoke(this, m0, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final boolean equals(Object var1) { try { return (Boolean)super.h.invoke(this, m1, new Object[]{var1}); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final String toString() { try { return (String)super.h.invoke(this, m2, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetA() { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final void targetB() { try { super.h.invoke(this, m4, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } static { ClassLoader var0 = $Proxy0.class.getClassLoader(); try { m0 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;hashCode\u0026#34;); m1 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;equals\u0026#34;, Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0)); m2 = Class.forName(\u0026#34;java.lang.Object\u0026#34;, false, var0).getMethod(\u0026#34;toString\u0026#34;); m3 = Class.forName(\u0026#34;io.github.ileonli.InterfaceA\u0026#34;, false, var0).getMethod(\u0026#34;targetA\u0026#34;); m4 = Class.forName(\u0026#34;io.github.ileonli.InterfaceB\u0026#34;, false, var0).getMethod(\u0026#34;targetB\u0026#34;); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(((Throwable)var2).getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(((Throwable)var3).getMessage()); } } private static MethodHandles.Lookup proxyClassLookup(MethodHandles.Lookup var0) throws IllegalAccessException { if (var0.lookupClass() == Proxy.class \u0026amp;\u0026amp; var0.hasFullPrivilegeAccess()) { return MethodHandles.lookup(); } else { throw new IllegalAccessException(var0.toString()); } } } "},{"id":21,"href":"/docs/Netty/encoder-and-decoder/","title":"编码器和解码器","section":"Netty","content":" 编码器和解码器 # 编码器：将消息转换为适合于传输的格式（通常是字节流）。 解码器：将网络字节流转换为应用程序的消息格式。 因此，编码器处理出站数据，而解码器处理入站数据。\n解码器 # 由于解码器是负责处理入站数据的，因此，解码器是 ChannelInboundHandler。\n解码器主要有下边两种：\n将字节解码为消息的 ByteToMessageDecoder 和 ReplayingDecoder。 将一种消息类型解码为另一种消息的 MessageToMessageDecoder。 ByteToMessageDecoder # ReplayingDecoder # ReplayingDecoder 扩展了 ByteToMessageDecoder 类，使得我们不必调用 readableBytes() 方法。它通过使用一个自定义的 ByteBuf 实现， ReplayingDecoderByteBuf，包装传入的 ByteBuf 实现了这一点，其将在内部执行该调用\nMessageToMessageDecoder # 编码器 # 编解码器类 # 这些类同时实现了 ChannelInboundHandler 和 ChannelOutboundHandler 接口。\nByteToMessageCodec # MessageToMessageCodec # CombinedChannelDuplexHandler # CombinedChannelDuplexHandler 可将 ChannelInboundHandler 和 ChannelOutboundHandler 结合在一起。\n"}]